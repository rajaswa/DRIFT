paper present termsciences portal deal implementation conceptual model use recent iso sixteen thousand, six hundred and forty-two standard terminological markup framework standard turn suitable concept model since allow organize original resources concepts associate various term give concept additional structure produce share conceptual relationships cross link resource result introduction semantic relations may initially miss
number serious reason convince increase amount researchers store relevant material center call language resource archive combine duty take care long term preservation well task give access material different user group access mean sense active interaction data make possible support integration new data new versions commentaries sort modern language resource archive adhere number basic principles fulfill requirements involve federations create joint language resource domains make even simple researchers access data paper make attempt formulate essential pillars language resource archive adhere
paper describe interdisciplinary approach bring together field corpus linguistics translation study present ongoing work creation corpus resource translation shift explicitly annotate translation shift denote departures formal correspondence source target text ie deviations occur translation process resource shift annotate systematic way make possible study phenomena need address machine translation output resemble human translation resource describe paper contain english source texts parliamentary proceed german translations shift annotation base predicate argument structure proceed two step first predicate arguments annotate monolingually straightforward manner correspond english german predicate arguments align whenever shift mainly grammatical semantic occur alignment tag accordingly
diagrammatic analogical iconic representations often contrast linguistic logical representations shape symbols arbitrary aim paper make case usefulness diagram inferential knowledge representation systems although commonly use diagram long time suffer reputation heuristic tool mere support intuition first part paper historical background pay tribute logicians psychologists computer scientists put end formal prejudice diagram second part discussion characteristics oppose linguistic form last part aim revive interest heterogeneous representation systems include linguistic diagrammatic representations
study different term extractors corpus biomedical domain reveal decrease performances apply highly technical texts difficulty impossibility customise new domains additional limitation paper propose use external terminologies influence generic linguistic data order augment quality extraction tool implement exploit testify term different step process chunk parse extraction term candidates experiment report show use method term candidates acquire higher level reliability describe extraction process involve endogenous disambiguation implement term extractor yatea
paper aim emphasize even relax hypothesis compositionality face many problems use interpret natural language texts rather fix problems within compositional framework believe radical change necessary propose another approach
paper concern understand plurals framework artificial intelligence emphasize role time construction collections evolution across time often crucial account paper contrast de dicto collection collection consider persist situations even members change de collection whose composition vary time express different criteria choice two interpretations de de dicto depend context enunciation
present new unique freely available parallel corpus contain european union eu document mostly legal nature available twenty official euanguages additional document available languages eu candidate countries corpus consist almost eight thousand document per language average size nearly nine million word per language pair wise paragraph alignment information produce two different aligners vanilla hunalign available one hundred and ninety language pair combinations texts manually classify accord eurovoc subject domains collection also use train test multi label classification algorithms keyword assignment software corpus encode xml accord text encode initiative guidelines due large number parallel texts many languages jrc acquis particularly suitable carry type cross language research well test benchmark text analysis software across different languages instance alignment sentence split term extraction
depann interactive annotation tool dependency treebanks provide graphical text base annotation interfaces tool aim semi automatic creation treebanks aid manual inspection correction automatically create parse make annotation process faster less error prone novel feature tool enable user view output several parsers basis create final tree save treebank depann use tiger xml xml base general encode format represent parser output save annotate treebank tool include automatic consistency checker sentence structure addition tool enable users build structure manually add comment annotations modify tagsets mark sentence revision
paper current dependencybased treebanks introduce analyze methods use build resources annotation scheme apply tool use pos taggers parsers annotation software discuss
available french resources evaluate linguistic model algorithms linguistic level morpho syntax either insufficient quantitative well qualitative point view freely accessible base fact freebank project intend create french corpora construct use manually revise output hybrid constraint grammar parser annotate several linguistic level structure morpho syntax syntax coreference objective make available line research purpose therefore focus use standard annotation scheme integration exist resources maintenance allow continuous enrichment annotations prior actual presentation prototype implement paper describe generic model organization deployment linguistic resource archive compliance various work currently conduct within international standardization initiatives tei iso tc thirty-seven sc four
great effort concern development fully integrate modular understand systems research focus problem unify exist linguistic formalisms cognitive process model situate constructional interpretation model one attempt model notion construction adapt order able mimic behavior production systems construction grammar approach establish model relations linguistic form mean mean constructions latter consider pair topologically structure space unstructured space way special kind production rule
montylingua integral part conceptnet currently largest commonsense knowledge base english text processor develop use python program language mit media lab main feature montylingua coverage aspects english text process raw input text semantic mean summary generation yet component montylingua loosely couple architectural code level enable individual components use independently substitute however review explore role montylingua recent research work utilize paper aim review use roles play montylingua components research work publish nineteen article october two thousand and four august two thousand and six observe diversify use montylingua many different areas generic domain specific although use text summarize component observe optimistic crucial role manage current trend information overload future research
paper propose new measure language development use network analyse inspire recent surge interest network study many real world systems children care takers speech data longitudinal study represent series network word form take nod collocation word link measure properties network size connectivity hub authority analyse etc allow us make quantitative comparison reveal different paths development example asynchrony development network size average degree suggest children simply classify early talkers late talkers one two measure children follow different paths multi dimensional space may develop faster one dimension slower another dimension network approach require little preprocessing word analyse sentence structure characteristics word usage emerge network independent grammatical presumptions show change two article roles important nod network reflect progress children syntactic development two article often start children network hubs later shift authorities authorities constantly adult network network analyse provide new approach study language development time language development also present rich area network theories explore
goal present paper provide systematic comprehensive study rational stochastic languages semiring k q q r r rational stochastic language probability distribution free monoid sigma rational k generate multiplicity automata parameters k study relations class rational stochastic languages rat k sigma define notion residual stochastic language use investigate properties several subclasses rational stochastic languages lastly study representation rational stochastic languages mean multiplicity automata
usually probabilistic automata probabilistic grammars crisp symbols input view formal model compute value paper first introduce probabilistic automata probabilistic grammars compute special word probabilistic framework word interpret probabilistic distributions possibility distributions set crisp symbols probabilistic condition establish retraction principle compute word compute value handle crisp input generalize extension principle compute word compute word handle arbitrary input principles show compute value compute word respectively implement compute special word compare transition probabilities two near input also examine analytical properties transition probability function generalize extensions moreover retractions generalize extensions show equivalence preserve finally clarify relationships among retractions generalize extensions extensions study recently qiu wang
present base class automata induce numeration system give algorithm give n th word language automaton expansion n induce numeration system feed automaton furthermore give algorithms reverse read expansion way combine automata automata properties
transcribe speech automatic speech recognition systems use statistical methods particularly hide markov model n gram model although techniques perform well lead efficient systems approach maximum possibilities seem thus necessary order outperform current result use additional information especially bind language however introduce knowledge must realize take account specificities speak language hesitations example robust possible misrecognized word document present state art research evaluate impact insertion linguistic information quality transcription
article investigate use probabilistic model unsupervised cluster text collections unsupervised cluster become basic module many intelligent text process applications information retrieval text classification information extraction model consider contribution consist mixture multinomial distributions word count component correspond different theme present contrast various estimation procedures apply supervise unsupervised contexts supervise learn work suggest criterion evaluate posterior odds new document statistically sound naive bay approach unsupervised context propose measure set systematic evaluation framework start examine expectation maximization algorithm basic tool inference discuss importance initialization influence feature smooth strategy size vocabulary thereby illustrate difficulties incur high dimensionality parameter space also propose heuristic algorithm base iterative vocabulary reduction solve problem use fact latent variables analytically integrate finally show gibbs sample algorithm tractable compare favorably basic expectation maximization approach
paper propose method adapt general parser link parser sublanguages focus parse texts biology main proposal use terminology identication analysis term order reduce complexity text parse several strategies explore finally combine among text normalization lexicon morpho guess module extensions grammar rule adaptation compare parse result adaptations
study adaptation link grammar parser biomedical sublanguage focus domain term find general parser lexicon use two biomedical corpora implement evaluate three approach address unknown word automatic lexicon expansion use morphological clue disambiguation use part speech tagger evaluate approach separately effect parse performance consider combinations approach addition forty-five increase parse efficiency find best approach incorporate information domain part speech tagger offer statistically signicant ten relative decrease error adapt parser available open source license http wwwitutufi biolg
aim paper propose method tag name entities ne use natural language process techniques beyond literal mean name entities frequently subject metonymy show limit current ne type hierarchies detail new proposal aim dynamically capture semantics entities context model analyze complex linguistic phenomena like metonymy know difficult natural language process crucial applications present implementation test use french ester corpus give significant result
question relate evolution language recently know impressive increase interest briscoe two thousand and two short paper aim question scientific status model relations attest data show one directly model non linguistic factor exogenous factor even play crucial role language evolution examine relation linguistic model attest language data well contribution cognitive linguistics
use answer set program inference base approach natural language semantics
present exploratory tool extract person name multilingual news collections match name variants refer person infer relationships people base co occurrence name relate news novel feature match name variants across languages write systems include name write greek cyrillic arabic write system due highly multilingual set use internal standard representation name representation match instead adopt traditional bilingual approach transliteration work part news analysis system newsexplorer cluster average twenty-five thousand news article per day detect relate news within across different languages
present text analysis tool set allow analysts various field sieve large collections multilingual news items quickly find information relevance give document collection tool set automatically cluster texts group similar article extract name place people organisations list user define specialist term find link cluster entities generate hyperlinks daily news analysis operate thousands article per day tool also learn relationships people entities fully functional prototype system allow users explore navigate multilingual document collections across languages time
automatic annotation document control vocabulary term descriptors conceptual thesaurus useful document index retrieval map texts onto thesaurus furthermore allow establish link similar document also substantial requirement semantic web paper present almost language independent system map document write different languages onto multilingual conceptual thesaurus eurovoc conceptual thesauri differ natural language thesauri consist relatively small control list word phrase rather abstract mean automatically identify thesaurus descriptors describe content document best develop statistical associative system train texts previously index manually addition describe large number empirically optimise parameters fully functional application present performance software accord human evaluation professional indexers
texts translations rich linguistic resource use train test statistics base machine translation systems many applications paper present work system identify translations similar document among large number candidates represent document content vector thesaurus term multilingual thesaurus measure semantic similarity vectors test different text type show system detect translations ninety-six precision large search space eight hundred and twenty document system tune ignore language specific similarities give similar document second language similarity score equivalent document language application also use detect cross lingual document plagiarism
paper present language independent approach control vocabulary keyword assignment use eurovoc thesaurus due multilingual nature eurovoc keywords document write one language display eleven official european union languages map document write different languages multilingual thesaurus furthermore allow cross language document comparison assignment control vocabulary thesaurus descriptors achieve apply statistical method use collection manually index document identify thesaurus descriptor large number lemmas statistically associate descriptor associate word use assignment procedure identify rank list eurovoc term likely good keywords give document paper also describe challenge task discuss achieve result fully functional prototype
highly multilingual multicultural environment european commission soon twenty official languages urgent need text analysis tool use minimal linguistic knowledge adapt many languages without much human effort present two information extraction tool already adapt various western eastern european languages one recognition date expressions text one detection geographical place name visualisation result geographical map evaluation performance produce satisfy result
propose simple efficient basic approach number multilingual cross lingual language technology applications limit usual two three languages apply relatively little effort larger set languages approach consist use exist multilingual linguistic resources thesauri nomenclatures gazetteers well exploit existence additional less language independent text items date currency expressions number name cognates map texts onto multilingual resources identify word token link texts different languages basic ingredients applications cross lingual document similarity calculation multilingual cluster categorisation cross lingual document retrieval tool provide cross lingual information access
present method recognise geographical reference free text tool must work various languages minimum language dependent resources except gazetteer main difficulty disambiguate place name distinguish place persons select likely place list homographic place name world wide system use number language independent clue heuristics disambiguate place name homographs final aim index texts countries cities mention automatically visualise information geographical map use various tool
present tool automatically recognise name try infer inter person relations order present associate people map base house name entity recognition tool apply cluster average fifteen thousand news article per day fifteen different languages build knowledge base allow extract statistical co occurrences persons visualise per person page various graph
present set multilingual text analysis tool help analysts field explore large document collections quickly order determine whether document contain information interest find relevant text passages automatic tool currently exist fully functional prototype expect particularly useful users repeatedly sieve large collections document download automatically internet propose system take whole document collection input first carry automatic analysis task name entity recognition geo cod cluster term extraction annotate texts generate meta information store meta information database system generate zoomable hyperlinked geographic map enhance information entities term find system use regular basis build historical database contain information name mention together name place users query database retrieve information extract past
repport concern automatic understand french iterative sentence ie sentence one single verb interpret less regular plurality events linguistic analysis propose along extension reichenbach theory several formal representations consider corpus eighteen thousand newspaper extract describe
multimedia text bioinformatics databases applications query sequence n consecutive symbols call n grams estimate number distinct n grams view size estimation problem view size estimate sample statistical assumptions desire unassuming algorithm universally valid accuracy bound relate work focus repeatedly hash data prohibitive large data source prove one pass one hash algorithm sufficient accurate estimate hash sufficiently independent reduce cost investigate recursive random hash algorithms show sufficiently independent practice compare run time exact count use suffix array show use hardly storage order magnitude faster approach extend one pass one hash computation n gram entropy iceberg count experiment use large collection english text gutenberg project well synthetic data
truth base entailments sufficient good comprehension nl fact deduce implicit information necessary understand text hand norm base entailments able reach goal idea behind development frame minsky seventy-five script schank seventy-seven schank seventy-nine seventy theories formalize enough adaptation new situations far obvious paper present reason system use norms causal reason process order find accident text describe
understand texts write natural language ln use knowledge norms domain norms allow infer implicit information text kind information general defeasible remain useful acceptable text contradict explicitly paper describe non monotonic reason system base norms car crash domain system infer accident textual description accident see specific norm violate predicate rule system stratify organize layer order obtain efficient reason
latent semantic analysis lsa widely use information retrieval method base bag word assumption however accord general conception syntax play role represent mean sentence thus enhance lsa part speech pos information capture context word occurrences appear theoretically feasible extension approach test empirically automatic essay grade system use lsa document similarity comparisons comparison several pos enhance lsa model report find show addition contextual information form pos tag raise accuracy lsa base score model one thousand and seventy-seven per cent
paper present case study concern challenge requirements pose next generation language resources realize overall model open distribute collaborative language infrastructure sort new paradigm require think emerge still evolve technology connect grid compute interest suitable one concrete realization vision give current limitations grid compute important test new environment basic language analysis tool order get feel potentialities possible limitations connect use nlp reason do experiment module linguistic miner ie extraction linguistic pattern restrict domain corpora
present technique automate verification abstract model multithreaded program provide fresh name generation name mobility unbounded control high level specification language adopt extension communication finite state machine local variables range infinite name domain call tdl program communication machine prove effective represent communication protocols well represent abstractions multithreaded software verification method propose base encode tdl program low level language base multiset rewrite constraints view extension petri net mean encode symbolic verification procedure develop low level language previous work apply tdl program furthermore encode allow us isolate decidable class verification problems tdl program still provide fresh name generation name mobility unbounded control syntactic restrictions fact define internal structure thread order obtain complete terminate method thread allow one local variable range infinite domain name
inspire pagerank hit hubs authorities algorithms web search propose structural rank approach ad hoc information retrieval reorder document initially retrieve set exploit asymmetric relationships specifically consider generation link indicate language model induce one document assign high probability text another take care prevent bias long document study number rank criteria base measure centrality graph form generation link show integrate centrality standard language model base retrieval quite effective improve precision top rank
present novel approach pseudo feedback base ad hoc retrieval use language model induce document cluster first treat pseudo feedback document produce response original query set pseudo query serve input retrieval process observe document return response pseudo query act pseudo query subsequent round arrive formulation pseudo query base retrieval iterative process experiment show several concrete instantiations idea apply conjunction techniques design heighten precision yield performance result rival number previously propose algorithms include standard language model approach use cluster base language model key contribute factor algorithms success
paper investigate concept digital city first functional analysis digital city make light modern study urbanism similarities virtual urban constructions point next semiotic perspective subject matter elaborate terminological basis introduce treat digital city self organize mean produce system intend support social spatial navigation explicit definition digital city formulate finally propose approach discuss conclusions give future work outline
give theoretical analysis empirical validation fundamental model whether conceptual formal surprise two tool scientific discovery often ignore contemporary study communication paper pursue ideas correct expand model approach linguistics otherwise inapplicable precisely widely apply general case hypermedia base communication b develop techniques empirical validation semiotic model nowadays routinely use explore fact conjecture internal mechanisms complex systems yet purely speculative basis study thus offer two experimentally test substantive contributions formal representation communication mutually orient behavior couple autonomous systems mathematical interpretation semiosis communication together offer concrete parsimonious understand diverse communication phenomena
investigate whether one determine transcripts yous congressional floor debate whether speeches represent support opposition propose legislation address problem exploit fact speeches occur part discussion allow us use source information regard relationships discourse segment whether give utterance indicate agreement opinion express another find incorporation information yield substantial improvements classify speeches isolation
present unsupervised learn algorithm mine large text corpora pattern express implicit semantic relations give input word pair xy unspecified semantic relations correspond output list pattern rank accord well pattern pi express relations x example give xostrich ybird two highest rank output pattern x largest x output pattern intend useful find pair relations support construction lexicons ontologies semantic network pattern sort pertinence pertinence pattern pi word pair xy expect relational similarity give pair typical pair pi algorithm empirically evaluate two task solve multiple choice sit word analogy question classify semantic relations noun modifier pair task algorithm achieve state art result perform significantly better several alternative pattern rank algorithms base tf idf
least two kinds similarity relational similarity correspondence relations contrast attributional similarity correspondence attribute two word high degree attributional similarity call synonyms two pair word high degree relational similarity say relations analogous example word pair masonstone analogous pair carpenterwood paper introduce latent relational analysis lra method measure relational similarity lra potential applications many areas include information extraction word sense disambiguation information retrieval recently vector space model vsm information retrieval adapt measure relational similarity achieve score forty-seven collection three hundred and seventy-four college level multiple choice word analogy question vsm approach relation pair word characterize vector frequencies predefined pattern large corpus lra extend vsm approach three ways one pattern derive automatically corpus two singular value decomposition svd use smooth frequency data three automatically generate synonyms use explore variations word pair lra achieve fifty-six three hundred and seventy-four analogy question statistically equivalent average human score fifty-seven relate problem classify semantic relations lra achieve similar gain vsm
automatic extraction acronyms mean corpora important sub task text mine see special case string alignment text chunk align acronym alternative alignments different cost ideally least costly one give correct mean acronym show approach implement mean three tape weight finite state machine three wfsm read text chunk tape one acronym tape two generate alternative alignments tape three three wfsm automatically generate simple regular expression additional algorithms require stage three wfsm size twenty-seven state sixty-four transition find best analysis acronym milliseconds
present generalization viterbi algorithm identify path minimal resp maximal weight n tape weight finite state machine n wfsm accept give n tuple input string s1 sn also allow us compile best transduction give input n tuple weight nm wfsm transducer n input output tap algorithm worst case time complexity ofsn e log sn q n number average length string n tuple q e number state transition n wfsm respectively straight forward alternative consist intersection follow classical shortest distance search operate ofsn eq log sn q time
paper short review csiec project initialize us two thousand and three present continue development improvement csiec project detail include design five new microsoft agent character represent different virtual chat partner limitation simulate dialogs specific practical scenarios like graduate job application interview briefly analyze actual condition feature application field web base english education china finally introduce efforts adapt system requirements english teach learn china point work next
model human dynamics responsible formation evolution call social network structure comprise individuals organizations indicate connectivities exist community topic recently attract significant research interest claim dynamics scale free many practically important case impersonal personal communication auction market access sit www etc human response time thus conform power law certain amount progress recently achieve predict general response rate human population exist formal theories human behavior hardly find satisfactory accommodate comprehensively explain scale observe social network present study novel system theoretic model approach propose successfully apply determine important characteristics communication network analyze consumer behavior www