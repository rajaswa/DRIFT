precise formulation derivation tree adjoin grammars important ramifications wide variety use formalism syntactic analysis semantic interpretation statistical language model argue definition tree adjoin derivation must reformulate order manifest proper linguistic dependencies derivations particular proposal precisely characterizable definition tag derivations equivalence class order derivation tree computationally operational virtue compilation linear index grammars together efficient algorithm recognition parse accord compile grammar
report recent loebner prize competition inspire turing test intelligent behavior presentation cover structure competition outcome first instantiation actual event analysis purpose design appropriateness competition argue competition clear purpose design prevent useful outcome competition inappropriate give current level technology speculate suitable alternatives loebner prize
formalism synchronous tree adjoin grammars variant standard tree adjoin grammars tag intend allow use tag language transduction addition language specification previous work definition transduction relation define synchronous tag give appeal iterative rewrite process rewrite definition derivation problematic greatly extend expressivity formalism make design parse algorithms difficult impossible introduce simple natural definition synchronous tree adjoin derivation base isomorphisms standard tree adjoin derivations avoid expressivity implementability problems original rewrite definition decrease expressivity would otherwise make method unusable offset incorporation alternative definition standard tree adjoin derivation previously propose completely separate reason thereby make practical entertain use natural definition synchronous derivation nonetheless remain problematic case call yet flexibility definition isomorphism requirement may relax remain future research tune exact requirements allowable mappings
dependency grammar usually interpret equivalent strict form x bar theory forbid stack nod bar level eg n immediately dominate n head adequate account one anaphora semantics multiple modifiers require stack accordingly argue dependency grammar dependency grammar salvage reinterpret claim phrase structure modifiers map onto binary branch x bar tree rather flat ones
paper show apply memoization cache subgoals associate answer substitutions constraint logic program set research motivate desire apply constraint logic program clp problems natural language process involve constraint interleave coroutining gb hpsg parse
s92 research begin one thousand, nine hundred and eighty-seven analyze word frequencies present day spanish make speech pathology evaluation tool five hundred two thousand word sample children adolescents adults language input one thousand, nine hundred and eighty-eight one thousand, nine hundred and ninety-one calculations do one thousand, nine hundred and ninety-two statistical lewandowski analyse carry one thousand, nine hundred and ninety-three
propose generalization categorial grammar lexical categories define mean recursive constraints particular introduction relational constraints allow one capture effect recursive lexical rule computationally attractive manner illustrate linguistic merit new approach show account syntax dutch cross serial dependencies position scope adjuncts constructions delay evaluation use process grammars contain recursive constraints
present system generate parsers base directly metaphor parse deduction parse algorithms represent directly deduction systems single deduction engine interpret deduction systems implement correspond parser method generalize easily parsers augment phrase structure formalisms definite clause grammars logic grammar formalisms use rapid prototyping parse algorithms variety formalisms include variants tree adjoin grammars categorial grammars lexicalize context free grammars
relationship lexical functional grammar lfg functional structure f structure sentence semantic interpretations express directly fragment linear logic way explain correctly constrain interactions quantifier scope ambiguity bind anaphora use deductive framework account compositional properties quantify expressions natural language obviate need additional mechanisms cooper storage represent different scopes quantifier might take instead semantic contribution quantifier record ordinary logical formula one whose use proof establish scope quantifier properties linear logic ensure quantifier scoped exactly analysis quantifier scope see recast pereira analysis pereira one thousand, nine hundred and ninety-one express higher order intuitionistic logic use lfg linear logic provide much direct computationally flexible interpretation mechanism least range phenomena develop preliminary prolog implementation linear deductions describe work
present analysis semantic interpretation intensional verbs seek allow take direct object either individual quantifier type produce de dicto de read quantifier case without need stipulate type raise quantify rule simple account follow directly use logical deduction linear logic express relationship syntactic structure mean analysis resemble current categorial approach important ways differ allow greater type flexibility categorial semantics maintain precise connection syntax result able provide derivations certain read sentence intensional verbs complex direct object derivable current purely categorial account syntax semantics interface analysis form part ongoing work semantic interpretation within framework lexical functional grammar
standard hpsg analysis germanic verb cluster explain observe narrow scope read adjuncts verb cluster present extension hpsg analysis account systematic ambiguity scope adjuncts verb cluster constructions treat adjuncts members subcat list extension use powerful recursive lexical rule implement complex constraints show delay evaluation techniques constraint logic program use process lexical rule
many applications natural language process necessary determine likelihood give word combination example speech recognizer may need determine two word combinations eat peach eat beach likely statistical nlp methods determine likelihood word combination accord frequency train corpus however nature language many word combinations infrequent occur give corpus work propose method estimate probability previously unseen word combinations use available information similar word describe probabilistic word association model base distributional word similarity apply improve probability estimate unseen word bigrams variant katz back model similarity base method yield twenty perplexity improvement prediction unseen bigrams statistically significant reductions speech recognition error
temporal relations hold events describe successive utterances often leave implicit underspecified address role two phenomena respect recovery relations one referential properties tense two role temporal constraints impose coherence relations account several facets identification temporal relations integration
mean complete collection reference interest intonational mean miscellaneous reference intonation include additional reference welcome send juliaresearchattcom
previously propose semantic head drive generation methods run problems none daughter constituents syntacto semantic rule schemata grammar fit definition semantic head give shieber et al one thousand, nine hundred and ninety case semantic analysis rule certain constraint base semantic representations eg underspecified discourse representation structure udrss frank reyle one thousand, nine hundred and ninety-two since head drive generation general merit simply return syntactic definition head demonstrate feasibility syntactic head drive generation addition generality syntactic head drive algorithm provide basis logically well define treatment movement syntactic head ad hoc solutions exist far
paper describe natural language parse algorithm unrestricted text use probability base score function select best parse sentence parser pearl time asynchronous bottom chart parser earley type top prediction pursue highest score theory chart score theory represent extent context sentence predict interpretation parser differ previous attempt stochastic parsers use richer form conditional probabilities base context predict likelihood pearl also provide framework incorporate result previous work part speech assignment unknown word model probabilistic model linguistic feature one parse tool interleave techniques instead use traditional pipeline architecture preliminary test pearl successful resolve part speech word speech process ambiguity determine categories unknown word select correct parse first use loosely fit cover grammar
paper describe picky probabilistic agenda base chart parse algorithm use technique call probabilistic prediction predict grammar rule likely lead acceptable parse input use suboptimal search method picky significantly reduce number edge produce cky like chart parse algorithms maintain robustness pure bottom parsers accuracy exist probabilistic parsers experiment use picky demonstrate probabilistic model impact upon efficiency robustness accuracy parser
describe generative probabilistic model natural language call hbg take advantage detail linguistic information resolve ambiguity hbg incorporate lexical syntactic semantic structural information parse tree disambiguation process novel way use corpus bracket sentence call treebank combination decision tree build tease relevant aspects parse tree determine correct parse sentence stand contrast usual approach grammar tailor via usual linguistic introspection hope generate correct parse head head test one best exist robust probabilistic parse model call p cfg hbg model significantly outperform p cfg increase parse accuracy rate sixty seventy-five thirty-seven reduction error
present stochastic finite state model segment chinese text dictionary entries productively derive word provide pronunciations word method incorporate class base model treatment personal name also evaluate system performance take account fact people often agree single segmentation
traditional natural language parsers base rewrite rule systems develop arduous time consume manner grammarians majority grammarian efforts devote disambiguation process first hypothesize rule dictate constituent categories relationships among word ambiguous sentence seek exceptions corrections rule work propose automatic method acquire statistical parser set parse sentence take advantage initial linguistic input avoid pitfalls iterative seemingly endless grammar development process base distributionally derive linguistically base feature language parser acquire set statistical decision tree assign probability distribution space parse tree give input sentence decision tree take advantage significant amount contextual information potentially include lexical information sentence produce highly accurate statistical model disambiguation process base disambiguation criteria selection entropy reduction rather human intuition parser development method able consider sentence human grammarian make individual disambiguation rule experiment parser acquire use statistical framework grammarian rule base parser develop ten year period use train material test sentence decision tree parser significantly outperform grammar base parser accuracy measure grammarian try maximize achieve accuracy seventy-eight compare grammar base parser sixty-nine
claim variety facts concern ellipsis event reference interclausal coherence explain two feature linguistic form question one whether form leave behind empty constituent syntax two whether form anaphoric semantics propose feature interact one two type discourse inference namely common topic inference coherent situation inference differ ways type inference utilize syntactic semantic representations predict phenomena otherwise difficult account
paper present plan base architecture response generation collaborative consultation dialogues emphasis case system consultant user execute agent disagree work contribute overall system collaborative problem solve provide plan base framework capture propose evaluate modify cycle collaboration allow system initiate subdialogues negotiate propose additions share plan provide support claim addition system handle unify manner negotiation propose domain action propose problem solve action beliefs propose discourse action furthermore capture cooperative responses within collaborative framework account question sometimes never answer
degrade text recognition difficult task give noisy text image word recognizer apply generate several candidates word image high level knowledge source use select decision candidate set word image paper propose visual inter word constraints use facilitate candidate selection visual inter word constraints provide way link word image inside text page interpret systematically
conversation person sometimes refer object previously know participant present plan base model agents collaborate reference sort make reference agent use salient attribute referent understand reference agent determine confidence adequacy mean identify referent collaborate agents use judgment suggestion elaboration move refashion inadequate refer expression
cue phrase may use discourse sense explicitly signal discourse structure also sentential sense convey semantic rather structural information paper explore use machine learn classify cue phrase discourse sentential two machine learn program cgrendel c45 use induce classification rule set pre classify cue phrase feature machine learn show effective technique automate generation classification rule also improve upon previous result
certain span utterances discourse refer segment widely assume form coherent units segmental structure discourse claim constrain constrain many phenomena however weak consensus nature segment criteria recognize generate present quantitative result two part study use corpus spontaneous narrative monologues first part evaluate statistical reliability human segmentation corpus speaker intention segmentation criterion use subject segmentations evaluate correlation discourse segmentation three linguistic cue referential noun phrase cue word pause use information retrieval metrics
present algorithm compute n gram probabilities stochastic context free grammars procedure alleviate standard problems associate n grams estimation sparse data lack linguistic structure among others method operate via computation substring expectations turn accomplish solve systems linear equations derive grammar discuss efficient implementation algorithm report practical experience
report describe new technique induce structure hide markov model data base general model merge strategy omohundro one thousand, nine hundred and ninety-two process begin maximum likelihood hmm directly encode train data successively general model produce merge hmm state bayesian posterior probability criterion use determine state merge stop generalize procedure may consider heuristic search hmm structure highest posterior probability discuss variety possible priors hmms well number approximations improve computational efficiency algorithm study three applications evaluate procedure first compare merge algorithm standard baum welch approach induce simple finite state languages small positive train sample find merge procedure robust accurate particularly small amount train data second application use label speech data timit database build compact multiple pronunciation word model use speech recognition finally describe algorithm incorporate operational speech understand system combine neural network acoustic likelihood estimators improve performance single pronunciation word model
current approach computational lexicology language technology knowledge base competence orient try abstract away specific formalisms domains applications result severe complexity acquisition reusability bottleneck alternative propose particular performance orient approach natural language process base automatic memory base learn linguistic lexical task consequences approach computational lexicology discuss application approach number lexical acquisition disambiguation task phonology morphology syntax describe
translate japanese nouns english face problem article number japanese language necessary english composition solve difficult problem classify referential property number nouns three type respectively paper show referential property number nouns sentence estimate fairly reliably word sentence many rule estimation write form similar rewrite rule expert systems obtain correct recognition score eight hundred and fifty-five eight hundred and ninety estimation referential property number respectively sentence use construction rule test rule texts obtain score six hundred and eighty-nine eight hundred and fifty-six respectively
define decidable class tag strongly equivalent cfgs cubic time parsable class serve lexicalize cfgs manner lcfgs schabes water considerably less restriction form grammars class provide normal form tag generate local set much way regular grammars provide normal form cfgs generate regular set
study employ knowledge intensive corpus analysis identify elements communicative context use determine appropriate lexical grammatical form instructional texts ig instructional text generation system base analysis present particularly reference expression precondition relations
explanation base generalization use extract specialize grammar original one use train corpus parse tree allow much faster parse give lower error rate price small loss coverage previously necessary specify tree cut criteria operationality criteria manually derive automatically train set desire coverage specialize grammar do assign entropy value node parse tree cut nod sufficiently high entropy value
glr recently develop robust version generalize lr parser parse almost input sentence ignore unrecognizable part sentence give input sentence parser return collection parse correspond maximal close maximal parsable subsets original input paper describe recent work develop integrate heuristic scheme select parse deem best collection describe heuristic measure use combination scheme preliminary result experiment conduct parse speech recognize spontaneous speech also report
thesis describe logical formalization natural language database interfacing assume existence natural language engine capable mediate surface linguistic string representations literal logical form focus interest question relate literal logical form representations term primitives meaningful underlie database engine begin describe nature problem show variety interface functionalities consider instance type formal inference task call abductive equivalential translation aet functionalities reduce form include answer question respond command reason completeness answer answer meta question type know generate assertions question case linguistic domain theory ldt gamma input formula f give goal construct formula certain properties equivalent f give gamma set permit assumptions ldt certain specify type whose formulas either conditional equivalences horn clauses show aet problem reduce goal direct inference method present abstract description method sketch realization prolog relationship aet several problems previously discuss literature discuss particular show aet provide simple elegant solution call doctor board problem effect allow relativization close world assumption ideas thesis implement concretely within sri clare project use real project payments database ldt example database describe detail examples type functionality achieve within example domain present
paper relate number parse algorithms develop different areas parse theory include deterministic algorithms tabular algorithms parallel algorithm show algorithms base underlie ideas relate exist ideas hope provide opportunity improve algorithms base feature others second purpose paper answer question come area tabular parse namely obtain parse algorithm property table contain little entries possible without possibility two entries represent subderivation
show head drive parse algorithms formulate occur exist literature algorithms inspire family leave right parse algorithms recent publication introduce advance notion head drive parse allow detail specification process order non head elements right hand side develop parse algorithm strategy base lr parse techniques
paper describe modular connectionist model acquisition receptive inflectional morphology model take input form phone one time output associate root inflections simulations use artificial language stimuli demonstrate capacity model learn suffixation prefixation infixation circumfixation mutation template deletion rule separate network modules responsible syllables enable network learn simple reduplication rule well model also embody constraints association line cross
important part semantics complex sentence capture relations among semantic roles subordinate main clause respectively however relations every pair semantic roles amount computation identify relations hold give sentence extremely large paper semantics japanese complex sentence introduce new pragmatic roles call observer motivate respectively bridge semantic roles subordinate main clauses new roles constraints relations among semantic pragmatic roles know almost local within subordinate main clause word semantics whole complex sentence role deal motivate
paper describe automatic word classification system use locally optimal anneal algorithm average class mutual information new word class representation structural tag introduce advantage use statistical language model present summary result one million word lob corpus give algorithm also show discover vowel consonant distinction display ability cluster word syntactically latin corpus finally comparison make current classification system several lead alternative systems show current system perform respectably well
describe implementation carpenter type feature formalism ale discourse grammar kind propose scha polanyi et al examine method resolve parallelism dependent anaphora show coherent feature structural rendition type grammar use operations priority union generalization describe augmentation ale system encompass operations show appropriate choice definition priority union give desire multiple output examples vp ellipsis exhibit strict sloppy ambiguity
paper provide model theoretic semantics feature term augment set descriptions provide constraints specify hpsg style set descriptions fix cardinality set descriptions set membership constraints restrict universal role quantifications set union intersection subset disjointness sound complete terminate consistency check procedure provide determine consistency give term logic show determine consistency term np complete problem
paper describe modular connectionist model acquisition receptive inflectional morphology model take input form phone one time output associate root inflections simplest version network consist separate simple recurrent subnetworks root inflection identification network take phone sequence input show performance two separate modular network superior single network responsible root inflection identification elaborate version model network learn use separate hide layer modules solve separate task root inflection identification
paper demonstrate exponential complexities respect grammar size input length little impact performance three unification base parse algorithms use wide coverage grammar result imply study optimisation unification base parse must rely empirical data complexity theory accurately predict practical behaviour parsers
acquire noun phrase run texts useful many applications word groupingterminology index etc report literatures adopt pure probabilistic approach pure rule base noun phrase grammar tackle problem paper apply probabilistic chunker decide implicit boundaries constituents utilize linguistic knowledge extract noun phrase finite state mechanism test texts susanne corpus result evaluate compare parse field susanne corpus automatically result preliminary experiment encourage
introduce bilingual dual cod theory model bilingual mental representation base model lexical selection neural network implement connectionist transfer project machine translation lexical selection approach two advantage first learnable little human effort knowledge engineer require secondly psycholinguistically well found
paper flow inference communicative intentions discourse structure domain discourse process augment theory discourse interpretation theory distinct mental attitudes reason order provide account attitudes interact reason discourse structure
human face face conversation ideal model human computer dialogue one major feature face face communication multiplicity communication channel act multiple modalities realize natural multimodal dialogue necessary study humans perceive information determine information humans sensitive face independent communication channel convey emotional conversational signal encode facial expressions develop experimental system integrate speech dialogue facial animation investigate effect introduce communicative facial expressions new modality human computer conversation experiment show facial expressions helpful especially upon first contact system also discover feature facial expressions early stage improve subsequent interaction
paper propose learn paradigm problem understand speak language basis work formalization understand problem communication problem result definition stochastic model production speech text start mean sentence result understand algorithm consist viterbi maximization procedure analogous commonly use recognize speech algorithm implement build
argue discourse plan must capture intend causal decompositional relations communicative action present plan algorithm dpocl build plan structure properly capture relations show structure use solve problems plague previous discourse planners allow system participate effectively flexibly ongoing dialogue
probabilistic classifiers use word sense disambiguation either base one contextual feature use model simply assume characterize interdependencies among multiple contextual feature paper different approach formulate probabilistic model present along case study performance model produce manner disambiguation noun interest describe method formulate probabilistic model use multiple contextual feature word sense disambiguation without require untested assumptions regard form model use approach joint distribution variables describe systematic variable interactions thereby limit number parameters estimate support computational efficiency provide understand data
interactive speak dialog provide many new challenge speak language systems one critical prevalence speech repair paper present algorithm detect correct speech repair base find repair pattern repair pattern build find word match word replacements identify fragment edit term rather use set prebuilt templates build pattern fly fair test method combine statistical model filter possible repair successful detect correct eighty repair without use prosodic information parser
describe experience automatic alignment sentence parallel english chinese texts report concern three relate topics one progress hkust english chinese parallel bilingual corpus two experiment address applicability gale church length base statistical method task alignment involve non indo european language three improve statistical method also incorporate domain specific lexical cue
paper describe work parse turkish use lexical functional grammar formalism work represent first significant effort parse turkish implementation base tomita parser develop carnegie mellon university center machine translation grammar cover substantial subset turkish include simple complex sentence deal reasonable amount word order freeness complex agglutinative morphology turkish lexical structure handle use separate two level morphological analyzer discussion key relevant issue regard turkish grammar discuss aspects system present result implementation initial result suggest system parse eighty-two sentence directly almost remain minor pre edit
paper define multiset value linear index grammar unordered vector grammar dominance link former model certain use multiset value feature structure unification base formalisms latter motivate word order variation quasi tree generalization tree two formalisms weakly equivalent important subset context sensitive polynomially parsable
recent research trainable part speech taggers explore stochastic tag taggers obtain high accuracy linguistic information capture indirectly typically tens thousands lexical contextual probabilities brill92 trainable rule base tagger describe obtain performance comparable stochastic taggers capture relevant linguistic information small number simple non stochastic rule paper describe number extensions rule base tagger first describe method express lexical relations tag capture stochastic taggers next show rule base approach tag unknown word finally show tagger extend k best tagger multiple tag assign word case uncertainty
eric brill recently propose simple powerful corpus base language model approach apply various task include part speech tag build phrase structure tree method learn series symbolic transformational rule apply sequence test corpus produce predictions learn process require count match give set rule templates allow method survey large space possible contextual factor paper analyse brill approach interest variation exist decision tree methods base experiment involve part speech tag english ancient greek corpora particular analysis throw light new mechanism seem surprisingly resistant overtraining fast incremental implementation mechanism record dependencies underlie result rule sequence also describe
advent faster computers notion machine translation huge store database translation examples longer unreasonable paper describe attempt merge example base machine translation ebmt approach psycholinguistic principles new formalism context free grammars call marker normal form demonstrate use describe language data way compatible psycholinguistic theories embed formalism standard multivariate optimization framework system build infer correct transfer function set bilingual sentence pair use function translate novel sentence validity line reason test development system call metla one system use infer english french english urdu transfer function small corpora result experiment examine engineer term well linguistic term general result experiment psycho logically linguistically well ground still achieve respectable level success compare similar prototype use hide markov model
extension classical unification call grade unification present capable combine contradictory information interactive process paradigm parser base new operator also present
paper present implement computational model interpret generate indirect answer yes question main feature one discourse plan base approach implicature two reversible architecture generation interpretation three hybrid reason model employ plan inference logical inference four use stimulus condition model speaker motivation provide appropriate unrequested information model handle wider range type indirect answer previous computational model several significant advantage
describe method use statistically collect chinese character group corpus augment chinese dictionary method particularly useful extract domain specific regional word readily available machine readable dictionaries output evaluate use human evaluators previously available dictionary also evaluate performance improvement automatic chinese tokenization result show method output legitimate word acronymic constructions idioms name title well technical compound many lack original dictionary
availability large line text corpora provide natural promise bridge worlds natural language process nlp machine learn ml recent years nlp community aggressively investigate statistical techniques drive part speech taggers application specific text corpora use drive knowledge acquisition much higher level well paper show ml techniques use support knowledge acquisition information extraction systems often difficult specify explicit domain model many information extraction applications always labor intensive implement hand cod heuristics new domain discover nevertheless possible use ml algorithms order capture knowledge implicitly present representative text corpus work address issue traditionally associate discourse analysis intersentential inference generation demonstrate utility ml algorithms higher level language analysis benefit work address portability scalability information extraction ie technologies hand cod heuristics use manage discourse analysis information extraction system months program effort easily need port successful ie system new domain show ml algorithms reduce
article outline new method locate discourse boundaries base lexical cohesion graphical technique call dotplotting application dotplotting discourse segmentation perform either manually examine graph automatically use optimization algorithm result two experiment involve automatically locate boundaries series concatenate document present areas application future directions work also outline
paper present tdl type feature base representation language inference system type definitions tdl consist type feature constraints boolean connectives tdl support open close world reason type allow partition incompatible type work partially well fully expand type possible efficient reason tdl accomplish specialize modules
various feature descriptions employ logic program languages constrain base grammar formalisms common notational primitive descriptions functional attribute call feature descriptions consider paper possibly quantify first order formulae obtain signature binary unary predicate call feature sort respectively establish first order theory ft mean three axiom scheme show completeness construct three elementarily equivalent model one model consist call feature graph data structure common computational linguistics two model consist call feature tree record like data structure generalize tree correspond first order term completeness proof exhibit terminate simplification system decide validity satisfiability possibly quantify feature descriptions
research discourse process identify two representational requirements discourse plan systems first discourse plan must adequately represent intentional structure utterances produce order enable computational discourse agent respond effectively communicative failures citemoorepariscl second discourse plan must represent informational structure utterances addition representational requirements argue discourse planners formally characterizable term soundness completeness
riddle base simple pun classify accord pattern word syllable phrase similarity depend upon devise formal model semantic syntactic regularities underlie simpler type pun riddle also implement preliminary theory computer program generate riddle lexicon contain general data word phrase lexicon content customise produce joke informal evaluation program result set human judge suggest riddle produce program comparable quality general circulation among school children
paper discuss model simple question answer pun implement program jape generate riddle humour independent lexical entries model use two main type structure schemata determine relationships key word joke templates produce surface form joke jape succeed generate piece text recognizably joke good joke mention potential improvements extensions include post production heuristics order joke accord quality
work paper describe spanish tagset use context crater cec fund project aim creation multilingual english french spanish align corpus use international telecommunications union corpus respect version corpus currently tag xerox parc tagger adapt spanish order perform tag spanish version tagset devise ideal one spanish post several list order get feedback
paper describe new approach system screen fault tolerant speech parse screeen stand symbolic connectionist robust enterprise natural language speech parse describe syntactic semantic analysis spontaneous speak language general approach base incremental immediate flat analysis learn syntactic semantic speech parse parallel integration current hypotheses consideration various form speech relate errors goal approach explore parallel interactions various knowledge source learn incremental fault tolerant speech parse approach examine system screen use various hybrid connectionist techniques hybrid connectionist techniques examine promise properties inherent fault tolerance learn gradedness parallel constraint integration input screen hypotheses recognize word speak utterance potentially analyze speech system output hypotheses flat syntactic semantic analysis utterance paper focus general approach overall architecture examples learn flat syntactic speech parse different speech language architectures screen emphasize interactive rather autonomous position learn rather encode flat analysis rather depth analysis fault tolerant process phonetic syntactic semantic knowledge
new flexible inference method horn logic program propose drastic generalization chart parse partial instantiations clauses program roughly correspond arc chart chart like parse semantic head drive generation emerge method parsimonious instantiation scheme ambiguity pack parse complexity reduce standard chart base algorithms
natural languages program languages mind take slogan seriously answer find look various dynamic treatments natural language develop last decade mostly response problems associate donkey anaphora dynamic logic program mean program binary relation set state abstract machine relation mean model aspects effect execution program particular input output behavior anything dynamic aspects various propose dynamic semantics natural languages suppose model anything dynamic model full shall try answer least question provide materials answer others
many current speech recognizers statistical language model use indicate likely certain word speak next give word recognize far statistical language model improve complex speech recognition task tackle since knowledge weaknesses theory often make improve theory easier central idea thesis analyze weaknesses exist statistical language model order subsequently improve end formally define weakness statistical language model term logarithm total probability ltp term closely relate standard perplexity measure use evaluate statistical language model apply definition weakness frequently use statistical language model call bi pos model result example new model unknown word improve performance model fourteen twenty-one moreover one identify weaknesses prompt development generalize n pos language model also outline thesis incorporate linguistic knowledge even extend many word feasible traditional n pos model lead discussion whatknowledge add statistical language model general give criteria select potentially useful knowledge result show usefulness definition weakness perform analysis weaknesses statistical language model general
review evidence claim syntactic ambiguities resolve basis mean compete analyse structure identify collection ambiguities yet mean base account propose one base interaction discourse grammatical function provide evidence proposal examine statistical properties penn treebank syntactically annotate text
syntactic ambiguity abound natural language yet humans difficulty cop fact process ambiguity resolution almost always unconscious infallible however example one demonstrate one horse race past barn fell sentence perfectly grammatical evident appear follow context two two horse show prospective buyer one race past meadow race past barn grammatical yet unprocessable sentence one call garden path sentence existence provide opportunity investigate human sentence process mechanism study fail aim thesis construct computational model language understand predict process difficulty data model know examples garden path non garden path sentence result psycholinguistics widely believe two distinct loci computation sentence process syntactic parse semantic interpretation one longstanding controversy two modules bear responsibility immediate resolution ambiguity claim latter syntactic process module simple device blindly faithfully construct possible analyse sentence current point process interpretive module serve filter occasionally discard certain analyse deem less appropriate ongoing discourse competitors document divide three part first introductory review selection proposals sentence process literature second part explore body data adduce support theory structural preferences one inconsistent present claim show current proposal specify account available data moreover predict structural preference theories go wrong third part theoretical investigation well propose architecture realize use current conceptions linguistic competence present parse algorithm mean base ambiguity resolution method
complexity particular term rewrite system consider rule associativity xyz xyz algorithms exact calculations give longest shortest sequence applications result normal form nf shortest nf sequence term x always n drmx n number occurrences x drmx depth rightmost leaf x longest nf sequence term length nn one two
consider speed humans resolve syntactic ambiguity overwhelm evidence syntactic ambiguity resolve selection analysis whose interpretation sensible one come conclusion interpretation hence parse take place incrementally every word considerations parsimony theory syntactic processor lead one explore simplest parsers one represent analyse define grammar information toward aim simple incremental parser explore proposal competence grammar combinatory categorial grammar ccg address problem proliferate analyse stem ccg associativity derivation solution involve maintain maximally incremental analysis necessary compute maximally right branch analysis use result study rewrite systems show computation efficient
paper discuss extent concept anytime algorithms apply parse algorithms feature unification first try give precise definition anytime algorithm arque parse algorithms classify contract algorithms oppose truly interruptible algorithms restriction transaction active time interrupt issue complete interrupt execute possible provide parser limit anytime behavior fact realize research prototype
paper focus semantic representation verbs computer systems impact lexical selection problems machine translation mt two group english chinese verbs examine show lexical selection must base interpretation sentence well selection restrictions place verb arguments novel representation scheme suggest compare representations selection restrictions use transfer base mt see approach closely align knowledge base mt approach kbmt separate component could incorporate exist systems examples experimental result show use scheme inexact match achieve correct lexical selection
paper present statistical decision procedure lexical ambiguity resolution algorithm exploit local syntactic pattern distant collocational evidence generate efficient effective highly perspicuous recipe resolve give ambiguity identify utilize single best disambiguate evidence target context algorithm avoid problematic complex model statistical dependencies although directly applicable wide class ambiguities algorithm describe evaluate realistic case study problem restore miss accent spanish french text
natural language system disco describe combine powerful flexible grammar development system linguistic competence german include morphology syntax semantics new methods linguistic performance model basis high level competence grammars new methods model multi agent dialogue competence interest sample application appointment schedule calendar management
submission contain postscript final version slide use acl ninety-four tutorial
paper describe texttiling algorithm partition expository texts coherent multi paragraph discourse units reflect subtopic structure texts algorithm use domain independent lexical frequency distribution information recognize interactions multiple simultaneous theme two fully implement versions algorithm describe show produce segmentation correspond well human judgments major subtopic boundaries thirteen lengthy texts
refine extend prior view description purpose contexts use acknowledgment act empirical examination use acknowledgments task base conversation distinguish three broad class acknowledgments ackn self ackn selfackn present catalogue thirteen pattern within class account specific use acknowledgment corpus
dissertation address design parse grammars automatic surface syntactic analysis unconstrained english text consist summary three article morphological disambiguation document grammar morphological part speech disambiguation english do within constraint grammar framework propose fred karlsson disambiguator seek discard alternative morphological analyse propose lexical analyser contextually illegitimate one thousand, one hundred constraints express twenty-three general essentially syntactic statements restrictions linear order morphological tag error rate morphological disambiguator ten time smaller another state art probabilistic disambiguator give allow leave hardest ambiguities unresolved accuracy suggest viability grammar base approach natural language parse thus also contribute general debate concern viability probabilistic vs linguistic techniques experiment heuristics address question resolve ambiguities survive morphological disambiguator two approach present empirically evaluate heuristic disambiguation constraints ii techniques learn fully disambiguate part corpus apply information resolve remain ambiguities
paper describe grammar learn system combine model base data drive learn within single framework result learn grammars use speak english corpus sec suggest combine model base data drive learn produce plausible grammar case use either learn style isolation
present integrate architecture word level sentence level process unification base paradigm core system clp implementation unification engine feature structure support relational value framework hpsg style grammar implement word level process use x2morf morphological component base extend version two level morphology component tightly integrate grammar relation advantage approach morphology syntax keep logically autonomous time minimize interface problems
local grammars represent convenient way automata paper describe illustrate efficient algorithm application local grammars put form lemmatized texts
finite state transducers give efficient representations many natural language phenomena allow account complex lexicon restrictions encounter without involve use large set complex rule difficult analyze show representations make compact indicate perform correspond minimization point interest linguistic side effect operation
abstract language japanese printer fonts japases character character figure print correctly dissertation bachelor degree kyoto universitynagao labmarch one thousand, nine hundred and ninety-four
sample problem train corpus one major source errors corpus base applications paper propose corrective train algorithm best fit run time context domain application bag generation show object adjust adjust probabilities result techniques greatly simplify experimental result demonstrate promise effect train algorithm generic domain specific domain general techniques easily extend various language model corpus base applications
describe efficient bottom parser interleave syntactic semantic structure build two techniques present reduce search reduce local ambiguity limit leave context constraints use reduce local syntactic ambiguity defer sortal constraint application use reduce local semantic ambiguity experimentally evaluate techniques show dramatic reductions number chart edge total parse time robust process capabilities parser demonstrate use improve accuracy speech recognizer
gemini natural language understand system develop speak language applications paper describe architecture gemini pay particular attention resolve tension robustness overgeneration gemini feature broad coverage unification base grammar english fully interleave syntactic semantic process paths bottom parser utterance level parser find interpretations sentence might analyzable complete sentence gemini also include novel components recognize correct grammatical disfluencies parse preferences paper present component component view gemini provide detail relevant measurements size efficiency performance
machine translation mt recently formulate term constraint base knowledge representation unification theories become evident possible design practical mt system without adequate method handle mismatch semantic representations source target languages paper introduce idea information base mt considerably flexible interlingual mt conventional transfer base mt
speak language translation systems develop date rely pipelined architecture main stag speech recognition linguistic analysis transfer generation speech synthesis make projections error rat systems kind natural assume error rat individual components independent make system accuracy product component accuracies paper report experiment carry use sri sic telia research speak language translator one thousand utterance sample unseen data result suggest naive performance model lead serious overestimate system error rat since fact strong dependencies components predict system error rate independence assumption simple multiplication result sixteen proportional overestimate utterances nineteen overestimate utterances length one ten word consider
simple general method describe combine different knowledge source reorder n best list hypotheses produce speech recognizer method automatically trainable acquire information positive negative examples experiment describe test one thousand utterance sample unseen atis data
show model social interaction particularly dialogue attitude obligation useful adjunct popularly consider attitudes belief goal intention mutual share counterparts particular show discourse obligations use account natural manner connection question answer dialogue obligations use along part discourse context extend coverage dialogue system
paper present new approach phoneme recognition use nonsequential sub phoneme units units call acoustic events phonologically meaningful well recognizable speech signal acoustic events form phonologically incomplete representation compare distinctive feature problem may partly overcome incorporate phonological constraints currently twenty-four binary events describe manner place articulation vowel quality voice use recognize german phonemes phoneme recognition paradigm consist two step acoustic events determine speech signal phonological parser use generate syllable phoneme hypotheses event lattice result obtain speaker dependent corpus present
present algorithm acquire word pair phonological form semantic representations larger utterances unsegmented phoneme sequence semantic representations algorithm maintain utterance utterance single coherent dictionary learn presence homonymy synonymy noise test result corpus utterances generate childes database mother child interactions present
paper describe first step towards definition abstract machine linguistic formalisms base type feature structure hpsg core design abstract machine give detail include compilation process high level specification language abstract machine language implementation abstract instructions thus apply methods prove useful computer science study natural languages grammar specify use formalism endow operational semantics currently machine support unification simple feature structure unification sequence structure cyclic structure disjunction
paper present theory computational implementation generate prosodically appropriate synthetic speech response database query proper distinctions contrast emphasis express intonation contour synthesize rule control grammar discourse model knowledge base theory base combinatory categorial grammar formalism easily integrate notions syntactic constituency semantics prosodic phrase information structure result current implementation demonstrate system ability generate variety intonational possibilities give sentence depend discourse context
discourse planner task orient dialogue must able make choices whether relevant optional information example satellite rst base planner communicate claim effective text planners must explicitly model aspects hearer cognitive state hearer attend inferences hearer draw order make choices argue mere representation hearer knowledge inadequate support claim one analysis naturally occur dialogue two simulate generation discourse situation vary cognitive parameters hearer result show model cognitive state lead effective discourse measure respect simple task
turkish considerably freer word order english interpretations different word order turkish rely information describe sentence relate discourse context capture syntactic feature free word order language present adaptation combinatory categorial grammars call ccgs set ccgs ccgs verb subcategorization requirements relax require set arguments without specify linear order integrate level information structure represent pragmatic function topic focus ccgs allow certain pragmatic distinctions mean influence word order sentence compositional way finally discuss strategy use within implement generation system produce turkish sentence context appropriate word order simple database query task
techdoc implement system demonstrate feasibility generate multilingual technical document basis language independent knowledge base application domain user maintenance instructions produce underlie plan structure represent activities participate object properties relations paper give brief outline system architecture discuss recent developments project addition actual event simulation kb step towards document author tool multimodal user interface slightly correct version paper appear coling ninety-four proceed
third person fictional narrative text compose passages objectively narrate events also passages present character thoughts perceptions inner state passages take character psychological point view language understander must determine current psychological point view order distinguish beliefs character facts story correctly attribute beliefs attitudes source understand discourse relations among sentence track psychological point view trivial problem many sentence explicitly mark point view whether point view sentence objective character latter character often depend context sentence appear track psychological point view problem address work approach seek extensive examinations naturally occur narrative regularities ways author manipulate point view develop algorithm track point view basis regularities find paper present algorithm give demonstrations implement system describe result preliminary empirical study lend support algorithm
ability cheaply train text classifiers critical use information retrieval content analysis natural language process task involve data partly fully textual algorithm sequential sample machine learn statistical classifiers develop test newswire text categorization task method call uncertainty sample reduce much five hundred fold amount train data would manually classify achieve give level effectiveness
various methods propose align texts two languages canadian parliamentary debateshansards methods generate bilingual lexicon product present alternative alignment strategy call k vec start estimate lexicon example discover english word fisheries similar french peches note distribution fisheries english text similar distribution peches french k vec depend sentence boundaries
quantitative representation discourse structure compute measure lexical cohesion relations among adjacent block text representations propose deal sub topic text segmentation parallel corpus similar representations derive versions text various languages use parallel segmentation alternative measure text translation similarity
paper present implement multi tape two level model capable describe semitic non linear morphology computational framework behind current work motivate kay one thousand, nine hundred and eighty-seven formalism present extension formalism report pulman hepple one thousand, nine hundred and ninety-three objectives current work stay close possible spirit standard two level morphology stay close linguistic description semitic stem present model use ease semitist paper illustrate finite state transducers fsts standard two level morphology model replace multi tape auxiliary versions afsts one account semitic root pattern morphology use high level notation
present efficient broad coverage principle base parser english parser implement c run sun sparcstations x windows contain lexicon ninety thousand entries construct automatically apply set extraction conversion rule entries machine readable dictionaries
describe implementation hybrid statistical symbolic approach repair parser failures speech speech translation system describe module take input fragment parse return repair mean representation negotiate speaker complete mean utterance generate hypotheses fit fragment partial parse together coherent mean representation draw upon statistical symbolic information constrain repair hypotheses likely meaningful update statistical model use improve performance time
automatic text tag important component higher level analysis text corpora output use many natural language process applications languages like turkish finnish agglutinative morphology morphological disambiguation crucial process tag structure many lexical form morphologically ambiguous paper describe pos tagger turkish text base full scale two level specification turkish morphology base lexicon twenty-four thousand root word augment multi word idiomatic construct recognizer importantly morphological disambiguator base local neighborhood constraints heuristics limit amount statistical information tagger also functionality statistics compilation fine tune morphological analyzer log erroneous morphological parse commonly use root etc preliminary result indicate tagger tag ninety-eight ninety-nine texts accurately minimal user intervention furthermore sentence morphologically disambiguate tagger lfg parser develop turkish generate average fifty less ambiguous parse parse almost twenty-five time faster tag functionality specific turkish apply language proper morphological analysis interface
paper present unify approach parse top bottom leave corner parsers relate preorder postorder inorder tree traversals show simplest bottom leave corner parsers leave recursive must convert use extend greibach normal form partial execution bottom leave corner parsers collapse together bup parser matsumoto
large amount low medium quality english texts produce machine translation mt systems optical character readers ocr non native speakers english text must postedited hand see light day improve text quality tedious work automation receive much research attention anyone postedited technical report thesis write non native speaker english know potential automate postediting system case mt generate text argue construction postediting modules portable across mt systems alternative hardcoding improvements inside one system example build complete self contain postediting module task article selection english noun phrase notoriously difficult problem japanese english mt system contain two hundred thousand rule derive automatically online text resources report learn algorithms accuracy comparisons human performance
knowledge base machine translation kbmt systems achieve excellent result constrain domains yet scale newspaper text reason knowledge resources lexicons grammar rule world model must painstakingly handcraft scratch one hypotheses test pangloss machine translation project whether resources semi automatically acquire large scale paper focus construction large ontology knowledge base world model support kbmt contain representations seventy thousand commonly encounter object process qualities relations ontology construct merge various online dictionaries semantic network bilingual resources semi automatic methods methods eg conceptual match semantic taxonomies broadly applicable problems import export knowledge one kb another methods eg bilingual match allow knowledge engineer build index kb second language spanish japanese
paper describe algorithm computation first follow set use feature theoretic grammars value set consist pair feature theoretic categories algorithm preserve much information grammars possible use negative restriction define equivalence class addition simple data structure lead order magnitude improvement execution time naive implementation
paper argue type inferencing incorrectly implement appropriateness specifications type feature structure promote combination type resolution unfilling correct efficient alternative consider expressive limit alternative approach throughout use feature cooccurence restrictions illustration linguistic motivation
paper demonstrate multi tape two level formalism use write two level grammars arabic non linear morphology use high level computationally tractable notation three illustrative grammars provide base cv moraic affixational analyse complement proposal handle hitherto computationally untreated problem break plural show best grammars describe arabic non linear morphology moraic case templatic stem affixational case templatic stem paper demonstrate break plural derive two level theory via implicit derivation singular
description entity interpret true false object use feature structure descriptions accrue several computational benefit paper create explicit interpretation type feature structure use description define notion satisfiable feature structure create simple effective algorithm decide feature structure satisfiable
paper attempt bring together two approach language analysis possible use probabilistic information principle base grammars parsers consider include discussion theoretical computational problems arise finally partial implementation ideas present along preliminary result test small set sentence
paper describe architecture integrate extensible corpus query system develop university stuttgart give examples modules realize within architecture modules form core corpus workbench within propose architecture information require evaluation query may derive different knowledge source corpus text databases line thesauri different mean either direct lookup database call external tool may infer necessary information time query evaluation information available method information access state declaratively individually corpus lead flexible extensible modular corpus workbench
present lhip system incremental grammar development use extend dcg formalism system use robust island base parse method control user define performance thresholds
apply decision tree induction problem discourse clue word sense disambiguation genetic algorithm automatic partition train set intrinsic decision tree induction give rise linguistically viable rule
discuss implementation issue marie one mostly symbolic parser fully implement marie two statistical parser partially implement address corpus one hundred thousand picture caption argue mix approach marie two better corpus algorithms data simpler
discuss combine knowledge base rule base statistical part speech taggers use two mature taggers engcg xerox tagger independently tag text combine result produce fully disambiguate text twenty-seven thousand word test sample take previously unseen corpus achieve nine hundred and eighty-five accuracy paper present data detail describe problems encounter course combine two taggers discuss problem evaluate taggers
paper investigate use selectional restriction constraints predicate impose arguments language model speech recognition use un tag corpus follow public domain tagger simple finite state machine obtain verb object pair unrestricted english text measure impact knowledge verb prediction direct object term perplexity cluster base language model result show even though cluster bigram useful verb object model combination two lead improvement cluster bigram model
describe experimentally evaluate method automatically cluster word accord distribution particular syntactic contexts deterministic anneal use find lowest distortion set cluster anneal parameter increase exist cluster become unstable subdivide yield hierarchical soft cluster data cluster use basis class model word coocurrence model evaluate respect hold test data
paper propose approximate n gram markov model bag generation direct word association pair distance use approximate n one gram n gram train table model parameters word association model merit word association model markov model train knowledge bag generation also apply lexical selection machine translation design
present automatic method weight contributions preference function use disambiguation initial scale factor derive solution least square minimization problem improvements make hill climb method apply disambiguate sentence atis air travel information system corpus performance result scale factor compare hand tune factor focus one class preference function base semantic lexical collocations experimental result present show function vary considerably select correct analyse particular define function perform significantly better ones base mutual information likelihood ratios lexical associations
paper compare qualitative reason model translation quantitative statistical model consider model within context two hypothetical speech translation systems start logic base design point characteristics best preserve eliminate move second quantitative design quantitative language translation model base relations lexical head phrase statistical parameters structural dependency lexical transfer linear order use select set implicit relations word source utterance correspond set relations target language word likely translation original utterance
effective problem solve among multiple agents require better understand role communication collaboration paper show communicative strategies greatly improve performance resource bound agents strategies highly sensitive task requirements situation parameters agents resource limitations base argument two source evidence one analysis corpus fifty-five problem solve dialogues two experimental simulations collaborative problem solve dialogues experimental world design world parameterize task requirements agents resources communicative strategies
paper present aspects involve formalization implementation hpsg theories basis logical setups carpenter one thousand, nine hundred and ninety-two king one thousand, nine hundred and eighty-nine one thousand, nine hundred and ninety-four briefly compare regard usefulness basis hpsgii pollard sag one thousand, nine hundred and ninety-four possibilities express hpsg theories hpsgii architecture various computational systems ale troll cuf tfs discuss beside formal characterization possibilities paper investigate specific choices constraints certain linguistic motivations ie lexicon structure licence grammatical principles ale implementation theory german propose hinrichs nakazawa one thousand, nine hundred and ninety-four use example ale grammar include appendix
semantic feedback important source information parser could use deal local ambiguities syntax however difficult devise systematic communication mechanism interactive syntax semantics article propose variant leave corner parse define point syntax semantics interact account grammatical relations thematic roles define content communication conflict resolution strategy base independent preferences syntax semantics result interactive model implement program call compere show account wide variety psycholinguistic data structural lexical ambiguities
psychological investigations lead considerable insight work human language comprehension system article look set principles derive psychological find argue particular organization linguistic knowledge along particular process strategy present computational model sentence process base principles many study show human sentence comprehension incremental interactive process semantic higher level information interact syntactic information make inform commitments early possible local ambiguity early commitments may make use top guidance knowledge different type must applicable independently others evidence study error recovery delay decisions point toward arbitration mechanism combine syntactic semantic information resolve ambiguities order account propose type linguistic knowledge must represent common form must separable apply independently integrate process time arbitrator present uniform representation computational model call compere base representation process strategy
natural language understand program get bogged multiplicity possible syntactic structure process real world texts human understanders much difficulty work analyze relationships parse strategies degree local ambiguity encounter semantic feedback syntax propose parse algorithm call head signal leave corner parse hslc minimize local ambiguities support interactive syntactic semantic analysis parser implement sentence understand program call compere
human language understander collection modular process operate relative autonomy single integrate process ongoing debate polarize language process community two fundamentally different type model posit camp conclude wrong one camp put forth model separate processors distinct knowledge source explain one body data propose model single processor homogeneous monolithic knowledge source explain body data paper argue hybrid approach combine unify processor separate knowledge source provide explanation body data demonstrate feasibility approach computational model call compere believe approach bring language process community significantly closer offer human like language process systems
development model human sentence process traditionally follow one two paths either model posit sequence process modules task specific knowledge eg syntax semantics posit single processor utilize different type knowledge inextricably integrate monolithic knowledge base previous work model sentence processor result model different process modules use separate knowledge source operate parallel arrive interpretation sentence one highlight model offer explanation sentence processor might recover error choose mean ambiguous word recent experimental work laurie stowe strongly suggest human sentence processor deal syntactic error recovery use mechanism much like propose model semantic error recovery another way interpret stowe find human sentence processor consist single unify process module utilize multiple independent knowledge source parallel sentence processor build upon architecture time exhibit behavior associate modular approach time act like integrate system paper explore ideas via prototype computational model sentence process call compere propose set psychological experiment test theories
summarize recent machine translation mt research information sciences institute usc describe application development japanese english newspaper mt system work aim scale grammar base knowledge base mt techniques scale involve use statistical methods acquire effective knowledge resources make reasonable linguistic choices face knowledge gap
paper describe research toward automatic interpretation compound nouns use corpus statistics initial study aim syntactic disambiguation present approach present base associations upon thesaurus categories association data gather unambiguous case extract corpus apply analysis ambiguous compound nouns work present still progress first attempt syntactically analyse test set two hundred and forty-four examples show seventy-five correctness future work aim improve accuracy extend technique assign semantic role information thus produce complete interpretation
compound nouns example noun compound become common natural language pose number difficult problems nlp systems notably increase complexity parse paper develop probabilistic model syntactically analyse compound model predict compound noun structure base knowledge affinities nouns acquire corpus problems inherent corpus base approach address data sparseness overcome use semantically motivate word class sense ambiguity explicitly handle model implementation base model describe lauer one thousand, nine hundred and ninety-four correctly parse seventy-seven test set
present methodology extract selectional restrictions variable level abstraction phrasally analyze corpora method relay use wide coverage noun taxonomy statistical measure co occurrence linguistic items experimental result performance method provide
anaphora resolution one active research areas natural language process study examine focus tool resolution pronouns kind anaphora focus discourse phenomenon like anaphora candy sidner formalize focus one thousand, nine hundred and seventy-nine mit phd thesis devise several algorithms resolve definite anaphora include pronouns present theory computational framework generally implement algorithms algorithms relate focus pronoun resolution implement thesis implementation provide better comprehension theory conceptual computational point view result program test different discourse segment evaluation analysis experiment present together statistical result
situation theory mathematical theory mean introduce jon barwise john perry evoke great theoretical practical interest motivate framework computational systems prosit pioneer work direction unfortunately lack real life applications systems study preliminary attempt remedy deficiency examine much prosit reflect situation theoretic concepts solve group epistemic puzzle use construct provide program language
free word order languages every sentence embed specific context among others order constituents determine categories theme rheme contrastive focus paper show recognise translate categories automatically sentential basis sentence embed achieve without refer context modifier class traditionally neglect linguistic description fully cover propose method coling ninety-four kyoto vol page sixty-nine seventy-five
speak language applications natural dialogue settings place serious requirements choice process architecture especially adverse phonetic acoustic condition parse procedures develop analyse incoming speech time synchroneous incremental manner able schedule resources accord vary condition recognition process depend actual degree local ambiguity parser select among available constraints order narrow search space little effort possible parse approach base constraint satisfaction techniques discuss provide important characteristics desire real time behaviour attempt mimic attention focus capabilities human speech comprehension mechanism
techniques present define model computational linguistics theories methods generalize diagram develop author model artificial intelligence plan reason show applicable model computation linguistics theories show extensional intensional interpretations model generate automatically assign mean computations linguistics theories natural languages keywords computational linguistics reason model g diagram model dynamic model implementation linguistics logics artificial intelligence
describe framework induce probabilistic grammars corpora positive sample first sample incorporate add ad hoc rule work grammar subsequently elements model state nonterminals merge achieve generalization compact representation choice merge stop govern bayesian posterior probability grammar give data formalize trade close fit data default preference simpler model occam razor general scheme illustrate use three type probabilistic grammars hide markov model class base n grams stochastic context free grammars
propose new algorithm call dk vec align pair asian indo european noisy parallel texts without sentence boundaries dk vec improve previous alignment algorithms handle better non linear nature noisy corpora algorithm use frequency position recency information feature pattern match dynamic time warp use match technique word pair algorithm produce small bilingual lexicon provide anchor point alignment
professional translators often dictate translations orally type afterwards transtalk project aim automate second part process originality dictation system lie fact acoustic signal produce translator source text translation make available system probable translations source text predict predictions use help speech recognition system lexical choices present result first prototype show mark improvement performance speech recognition task translation predictions take account
many kinds language model use speech understand suffer imperfect model intra sentential contextual influence argue problem address cluster sentence train corpus automatically subcorpora criterion entropy reduction calculate separate language model parameters cluster kind cluster offer way represent important contextual effect therefore significantly improve performance model also offer reasonably automatic mean gather evidence whether complex context sensitive model use general kind linguistic information likely reward effort would require develop cluster improve performance model prove existence context dependencies exploit unclustered model evidence claim present result show cluster improve model others atis domain result consistent find model suggest existence otherwise improvement bring cluster indeed good pointer whether worth develop unclustered model
modifiers general adverbs particular neglect categories linguistics consequently treatment natural language process pose problems article present dictionary information german adverbs necessary deal word order degree modifier scope problems nlp also give evidence claim classification accord position class differ semantic classification
paper present constraint base semantic formalism hpsg advantage formlism show respect grammar fragment german deal quantifier scope ambiguities trigger scramble movement ii ambiguities arise collective distributive distinction plural nps syntax semantics interface directly implement syntactic condition quantifier scoping distributivity construction semantic representations guide general principles govern interaction syntax semantics principles act constraint narrow set possible interpretations sentence mean ambiguous sentence represent single partial representations call younderspecified discourse representation structure constraints add monotonically gain information content sentence need build large number alternative representations sentence filter subsequent discourse world knowledge advantage udrss allow monotonic incremental interpretation also equip truth condition proof theory allow inferences draw directly structure quantifier scope resolve
paper present approach spell correction agglutinative languages base two level morphology dynamic program base search algorithm spell correction agglutinative languages significantly different languages like english concept word languages much wider entries find dictionary owe productive word formation derivational inflectional affixations overview certain issue relevant mathematical preliminaries formally present problem solution present result experiment spell correction turkish ural altaic agglutinative language result indicate find intend correct word ninety-five case offer first candidate seventy-four case edit distance one
paper present formalization center approach model attentional structure discourse use basis algorithm track discourse context bind pronouns describe grosz joshi weinstein one thousand, nine hundred and eighty-six process center attention entities discourse give rise intersentential transitional state continue retain shift propose extension state handle additional case multiple ambiguous pronouns algorithm implement hpsg natural language system serve interface database query application
order take step towards establish methodology evaluate natural language systems conduct case study attempt evaluate two different approach anaphoric process discourse compare accuracy coverage two publish algorithms find co specifiers pronouns naturally occur texts dialogues present quantitative result hand simulate algorithms analysis naturally give rise qualitative evaluation recommendations perform evaluations general illustrate general difficulties encounter quantitative evaluation problems allow underlie assumptions b determine handle underspecifications c evaluate contribution false positives error chain
central role lexicon mean text theory mtt dependency base linguistic theories replicate linguistic theories base context free grammars cfgs describe tree adjoin grammar tag system arise naturally process lexicalize cfgs tag grammar therefore compare directly mean text model mtm illustrate point discuss computational complexity certain non projective constructions suggest way incorporate locality word order definitions surface syntactic component mtt
simple method categorize texts predetermine text genre categories use statistical standard technique discriminant analysis demonstrate application brown corpus discriminant analysis make possible use large number parameters may specific certain corpus information stream combine small number function parameters weight basis useful discriminate text genres application information retrieval discuss
paper discuss lexicographical concept lexical function potential exploitation development machine translation lexicon design handle collocations
paper present xtag system grammar development tool base tree adjoin grammar tag formalism include wide coverage syntactic grammar english various components system discuss preliminary evaluation result parse various corpora give result comparison xtag ibm statistical parser alvey natural language tool parser also give
dilemma intend enhance quality increase productivity expert human translators present writer relevant lexical information mechanically extract comparable exist translations thus replace compensate absence lexicographer stand terminologist rather translator use statistics crude surface analysis minimum prior information dilemma identify instance suggest counterparts parallel source target texts level individual word dilemma form part tool kit translation focus text structure consistency large text volumes rather frame sentence interaction many actors large project rather retrieval machine store data decision make rather application give rule particular system tune need ongoing translation european community legislation languages candidate member countries system demonstrate use professional translators promise result
part speech tag hide markov model statistical model use assign grammatical categories word text early work field rely corpus tag human annotator train model recently cut et al one thousand, nine hundred and ninety-two suggest train achieve minimal lexicon limit amount priori information probabilities use baum welch estimation automatically refine model paper report two experiment design determine much manual train information need first experiment suggest initial bias either lexical transition probabilities essential achieve good accuracy second experiment reveal three distinct pattern baum welch estimation two pattern estimation ultimately reduce accuracy tag rather improve pattern applicable predict quality initial model similarity tag train corpus corpus tag heuristics decide use estimation effective manner give conclusions broadly agreement merialdo one thousand, nine hundred and ninety-four give greater detail contributions different part model
technique detect errors make hide markov model taggers describe base compare observable value tag process threshold result approach allow accuracy tagger improve accept lower efficiency define proportion word tag empirical observations present demonstrate validity technique suggest choose appropriate threshold
paper present syntactic lexicon english originally derive oxford advance learner dictionary oxford dictionary current idiomatic english modify augment hand thirty-seven thousand syntactic entries eight part speech x windows base tool available maintain lexicon perform search c lisp hook also available lexicon easily utilize parsers program
paper present fully lexicalize grammar formalism particularly attractive framework specification natural language grammars discuss detail feature base lexicalize tree adjoin grammars fb ltags representative class lexicalize grammars illustrate advantage lexicalize grammars various contexts natural language process range wide coverage grammar development parse machine translation also present method compact efficient representation lexicalize tree
present analysis dutch cross serial dependencies head drive phrase structure grammar arguably analysis differ analyse refer additional mechanisms eg sequence union head wrap standard structure share immediate dominance schema linear precedence rule
grammar model concurrent object orient natural language parse introduce complete lexical distribution grammatical knowledge achieve build upon head orient notions valency dependency inheritance mechanisms use capture lexical generalizations underlie concurrent computation model rely upon actor paradigm consider message pass protocols establish dependency relations ambiguity handle
text corpora tag part speech information useful many areas linguistic research paper new part speech tag method base neural network net tagger present performance compare hmm tagger trigram base tagger show net tagger perform well trigram base tagger better hmm tagger
behavioral specification object orient grammar model consider model base full lexicalization head orientation via valency constraints dependency relations inheritance mean non redundant lexicon specification concurrency computation computation model rely upon actor paradigm concurrency enter asynchronous message pass actors particular elaborate principles global behavior lexically distribute grammar correspond parser specify term event type network event network resp
use third language construct bilingual dictionary necessary discriminate equivalencies inappropriate word derive result ambiguity third language propose method treat utilize structure dictionaries measure nearness mean word result dictionary word word bilingual dictionary nouns use refine entries equivalencies publish bilingual dictionaries
reference resolution one important task natural language process paper author first determine referents locations dousha literally mean company appear japanese newspaper article secondly three heuristic methods two use semantic information text company name pattern propose test accurately identify correct referents propose methods base semantic pattern show high accuracy reference resolution dousha ninety suggest semantic pattern match methods effective reference resolution newspaper article
paper report investigation problem assign tone pitch contour propose model intend serve tool phonologists work instrumentally obtain pitch data tone languages motivation exemplification model provide data take fieldwork bamileke dschang cameroon follow recent work liberman others provide parametrised f0 prediction function p generate f0 value tone sequence explore asymptotic behaviour downstep next observe transcribe sequence x pitch ie f0 value amount find tone sequence pt x combinatorial optimisation problem two non deterministic search techniques provide genetic algorithm simulate anneal algorithm finally two implementations one technique describe compare use artificial real data sequence twenty tone program adapt tone languages adjust f0 prediction function
often argue accurate machine translation require reference contextual knowledge correct treatment linguistic phenomena drop arguments accurate lexical selection one historical arguments favor interlingua approach since revolve around deep semantic representation better able handle type linguistic phenomena see require knowledge base approach paper present alternative approach exemplify prototype system machine translation english korean implement synchronous tag approach essentially transfer base use semantic feature unification accurate lexical selection polysemous verbs semantic feature combine discourse model store previously mention entities also use recovery topicalize arguments paper concentrate translation korean english
paper present morphological lexicon english handle three hundred and seventeen thousand inflect form derive ninety thousand stem lexicon available two format first use implementation two level processor morphological analysis second derive first one efficiency reason consist disk base database use unix hash table facility also build x window tool facilitate maintenance browse lexicon package ready integrate natural language application parser hook write lisp c
concern syntactic annotation unrestricted text combine rule base analysis subsequent exploitation empirical data rule base surface syntactic analyser leave amount ambiguity output resolve use empirical pattern implement system generate apply corpus base pattern pattern describe main constituents sentence local context syntactic function several partly reduntant pattern pattern parser select analysis sentence match strictest possible pattern system apply experimental corpus present result discuss possible refinements method linguistic point view
paper describe new corpus base approach prepositional phrase attachment disambiguation present result compare performance algorithm corpus base approach problem
describe tagger base hide markov model use tag compose feature part speech gender etc contextual probability tag state transition probability deduce contextual probabilities feature value pair approach advantageous available train corpus small tag set large case morphologically rich languages
ideally time incremental algorithm use process change function size change rather say size entire current input base formalization set things change incremental modification paper investigate extent possible give guarantee chart base parse framework discuss general utility minimality notion incremental process
lexicalize grammar formalism lexicalize tree adjoin grammar ltag lexical item associate least one elementary structure supertag localize syntactic semantic dependencies thus parser lexicalize grammar must search large set supertags choose right ones combine parse sentence present techniques disambiguate supertags use local information lexical preference local lexical dependencies similarity ltag dependency grammars exploit dependency model supertag disambiguation performance result various model supertag disambiguation unigram trigram dependency base model present
use feature base tree adjoin grammar tag paper present linguistically motivate analyse constructions claim require multi component adjunction feature base tag analyse permit parse constructions use exist unification base earley style tag parser thus obviate need multi component tag parser without sacrifice linguistic coverage english
first present view detection correction syntactic errors introduce new correction method base heuristic criteria use decide correction prefer weight criteria lead flexible parametrable system adapt user partition tree base linguistic criteria agreement rule rather computational criteria necessary end propose extensions lexical correction syntactic errors aim adaptable user friendly system capable automatic correction applications
paper present proverb text planner argumentative texts proverb main feature combine global hierarchical plan unplanned organization text respect local derivation relations complementary way former split task present particular proof subtasks present subproofs latter simulate next intermediate conclusion present choose guidance local focus
natural language generation must work insufficient input underspecifications cause shortcomings component provide input preliminary state incrementally give input paper aim escape dead end situations make assumptions discuss global aspects default handle two problem class default incremental syntactic generator vm gen present substantiate discussion
comparison two smooth methods word bigram model linda bauman peto department computer science university toronto abstract word bigram model estimate text corpora require smooth methods estimate probabilities unseen bigrams delete estimation method use formula prij lambda fi one lambdafij fi fij relative frequency conditional relative frequency give j respectively lambda optimize parameter mackay one thousand, nine hundred and ninety-four propose bayesian approach use dirichlet priors yield different formula prij alpha fj alpha mi one alpha fj alpha fij fj count j alpha mi optimize parameters thesis describe experiment two methods train two million word corpus take canadian hansard compare basis experimental perplexity assign share test corpus methods prove equally accurate mackay method use fewer resources
use term natural social scientific title abstract study perspective sublanguages specialize dictionaries different notions sublanguage distinctiveness explore objective methods separate hard soft sciences suggest base measure sublanguage use dictionary characteristics sublanguage distinctiveness abstract automatically classify high degree accuracy use formula consider degree uniqueness term sublanguage may prove useful text filter information retrieval systems
report describe research design implementation work carry build clare system sri international cambridge england clare design natural language process system facilities reason understand context generate cooperative responses project involve development sri core language engine alshawi one thousand, nine hundred and ninety-two mit press natural language processor design implementation new components reason response generation clare system advance state art wide variety areas use novel techniques develop project extend coverage scale know techniques language components application independent provide interfaces development new type application
codeswitching contexts language syntactic head determine distribution complement mahootian one thousand, nine hundred and ninety-three derive generalization represent head anchor elementary tree lexicalize tag however codeswitching sequence amenable head complement analysis instance adnominal adjectives occupy position available language tag derivation sequence must use unanchored auxiliary tree palabras heavy duty heavy duty word spanish english poplack one million, nine hundred and eighty thousand, five hundred and eighty-four taste lousy sana lousy taste english swahili myers scotton one hundred and ninety-nine thousand, three hundred and twenty-nine ten give null hypothesis codeswitching monolingual sequence derive identical manner sequence like provide evidence pure lexicalize tag inadequate description natural language
previous work english determiners primarily concentrate semantics scoping properties rather complex order behavior little work do determiner order generally split determiners three subcategories however small number categories capture finer distinctions necessary correctly order determiners paper present syntactic account determiner sequence base eight independently identify semantic feature complex determiners genitives partitives determiner modify adverbials also present work implement part xtag wide coverage grammar english base feature base lexicalize tree adjoin grammar fb ltag formalism
lexical selection machine translation consist several relate components two receive lot attention lexical map underlie concept lexical item choose correct subcategorization frame base argument structure mt applications small relatively domain specific third component lexical selection generally overlook distinguish lexical items closely relate conceptually mt systems propose use world knowledge module decide word appropriate base various pragmatic stylistic constraints interest see much accomplish use combination syntax lexical semantics use separate ontologies language implement fb ltags able elegantly model specific language dependent syntactic semantic distinctions necessary filter choice lexical item
xtag ongoing project develop wide coverage grammar english base feature base lexicalize tree adjoin grammar fb ltag formalism xtag system integrate morphological analyzer n best part speech tagger early style parser x window interface along wide coverage grammar english develop use system system serve linguist workbench develop fb ltag specifications paper present description recent improvements various components xtag system also present recent performance wide coverage grammar various corpora compare performance wide coverage domain specific grammars
discuss two constructions long scramble ecm verbs challenge syntactic theories include traditional tag approach since seem require exceptional mechanisms postulate argue constructions fact analyze similar manner namely involve verb select defective complement complement defective lack certain case assign abilities represent functional head constructions differ many abilities lack follow previous analysis scramble rambow one thousand, nine hundred and ninety-four propose tag analysis base quasi tree
present parse algorithm polynomial time complexity large subset v tag languages v tag variant multi component tag handle free word order phenomena beyond class lcfrs include regular tag algorithm base cyk style parser tag
number researchers note similarities ltags ccgs observe resemblance felt could make use wide coverage grammar develop xtag project build wide coverage ccg knowledge attempt construct large scale ccg parser lexicon support paper describe system build adapt various xtag components ccg find despite similarities formalisms certain part grammatical workload distribute differently addition flexibility ccg derivations allow translate grammar handle number non constituent constructions xtag grammar
present new software architecture nlp systems make heterogeneous components demonstrate architectural prototype build atr context speech translation
computational model acquisition knowledge encyclopedic texts describe model implement program call snowy read unedited texts world book encyclopedia acquire new concepts conceptual relations topics deal dietary habit animals classifications habitats program also able answer ample set question knowledge acquire paper describe essential components model namely semantic interpretation inferences representation end evaluation performance program sample question able answer relation program similar nature
current syntactic theory limit range grammatical variation severely logical problem grammar learn trivial yet children exhibit characteristic stag syntactic development least sixth year rather posit maturational delay suggest acquisition difficulties result limitations manipulate grammatical representations argue genesis complex sentence reflect increase generative capacity systems generate structural descriptions conjoin clauses demand regular tree rewrite system sentential embed use context free tree substitution grammar modification require tag mildly context sensitive system
new tightly couple speech natural language integration model present tdnn base large vocabulary continuous speech recognition system unlike popular n best techniques develop integrate mainly hmm base speech natural language systems word level obviously inadequate morphologically complex agglutinative languages model construct speak language system base phoneme level integration tdnn cyk speak language architecture design implement use tdnn base diphone recognition module integrate table drive phonological morphological co analysis integration model provide seamless integration speech natural language connectionist speech recognition systems especially morphologically complex languages korean experiment result show speaker dependent continuous eojeol word recognition integrate morphological analysis eighty morphological analysis success rate directly speech input middle level vocabularies
describe automate method identify class morphologically relate word line dictionary link individual sense derive form one sense base form mean morphological relation attribute also present algorithm compute score reflect system92s certainty derivational link computation rely content semantic relations associate sense extract automatically parse sense definition subject parse structure automate semantic analysis process entire set headwords dictionary fashion create large set direct derivational graph access components broad coverage nlp system spurious unlikely derivations discard rather add dictionary assign negative score allow system handle non standard use form
generate test algorithm describe parse surface form one lexical entries use linearly order phonological rule algorithm avoid exponential expansion search space naive parse algorithm would face encode form parse ambiguities arise parse algorithm implement test real language data speed compare favorably kimmo type parser
cormack one thousand, nine hundred and ninety-two propose framework pronominal anaphora resolution proposal integrate focus theory sidner et al drt kamp reyle analyze methodology adjust process portuguese texts scope framework widen cover sentence contain restrictive relative clauses subject ellipsis test conceive apply probe adequacy propose modifications deal process current texts
describe design comlex syntax computational lexicon provide detail syntactic information approximately thirty-eight thousand english headwords consider type errors arise create lexicon errors measure control
theory interlanguage il lexicons outline emphasis il lexical entries base hpsg notion lexical sign theory account idiosyncratic lexical transfer syntactic subcategorisation idioms first language il also account developmental stag il lexical grammar grammatical variation use lexical item theory offer tool robust parse lexical transfer errors diagnosis errors
krifka one thousand, nine hundred and ninety-three suggest focus see mean provide material range semantic pragmatic function work rather specific semantic pragmatic function current paper describe implementation general idea apply interpretation
unbounded dependencies often model trace gap thread unification base grammars pollard sag however suggest analysis extraction base lexical rule exclude notion trace pands one thousand, nine hundred and ninety-four chapter nine parse suggest trade indeterminism lexical ambiguity paper provide short introduction approach extraction lexical rule illustrate linguistic power approach apply particularly idiosyncratic dutch extraction data
propose paradigm concurrent natural language generation order represent grammar rule distributively adopt categorial unification grammar cug category own functional type augment type lambda calculus several new combinators make order lambda conversions free partial local process concurrent calculus model chemical abstract machine show example japanese causative auxiliary verb require drastic rearrangement case domination
label sentence boundaries necessary prerequisite many natural language process task include part speech tag sentence alignment end sentence punctuation mark ambiguous disambiguate systems use brittle special purpose regular expression grammars exception rule alternative develop efficient trainable algorithm use lexicon part speech probabilities fee forward neural network train less one minute method correctly label nine hundred and eighty-five sentence boundaries corpus twenty-seven thousand sentence boundary mark show method efficient easily adaptable different text genres include single case texts
develop automatic abstract generation system japanese expository write base rhetorical structure extraction system first extract rhetorical structure compound rhetorical relations sentence cut less important part extract structure generate abstract desire length evaluation generate abstract show contain maximum seventy-four important sentence original text system utilize text browser prototypical interactive document retrieval system
datr declarative representation language lexical information principle neutral respect particular process strategies previous datr compiler interpreter systems support one access strategy closely resemble set inference rule procedural semantics datr evans gazdar 1989a paper present alternative access strategy reverse query strategy non trivial subset datr
paper present alternative approach multiple inheritance type feature structure approach feature structure associate several type come different hierarchies dimension case multiple inheritance type supertypes different hierarchies contrast approach approach base single type hierarchy feature structure one unique general type multiple inheritance involve computation greatest lower bound hierarchy propose approach support current linguistic analyse constraint base formalisms like hpsg inheritance lexicon knowledge representation nlp systems finally show multi dimensional inheritance hierarchies compile prolog term representation allow compute conjunction two type efficiently prolog term unification
paper present methodology build manipulate human orient dictionaries methodology apply construction french english malay dictionary obtain cross semi automatically two bilingual dictionaries use microsoft word specialize language write transcriptors small powerful dictionary tool
paper present algorithm select appropriate classifier word noun thai language frequently happen fluctuation choice classifier give concrete noun point view whole spe ech community individual speakers basically exect rule classifier selection far rule base approach give default rule pick correspond classifier noun registration classifier noun limit type unit classifier type open due mean representation propose corpus base method biber one thousand, nine hundred and ninety-three nagao one thousand, nine hundred and ninety-three smadja one thousand, nine hundred and ninety-three generate noun classifier associations nca overcome problems classifier assignment semantic construction noun phrase nca create statistically large corpus recomposed concept hierarchy constraints frequency occurrences
speak language translator prototype practically useful systems capable translate continuous speak language within restrict domains prototype system translate air travel atis query speak english speak swedish french construct modifications possible exist piece speech language process software speech recognizer language understander connect fairly conventional pipelined n best interface paper focus ways language processor make intelligent use sentence hypotheses deliver recognizer ways include one produce modify hypotheses reflect possible presence repair utter word sequence two fast parse version grammar automatically specialize frequent constructions train corpus three allow syntactic semantic factor interact acoustic ones choice mean structure translation acoustically prefer hypothesis always select even within linguistic coverage
describe extension earley parser stochastic context free grammars compute follow quantities give stochastic context free grammar input string probabilities successive prefix generate grammar b probabilities substrings generate nonterminals include entire string generate grammar c likely viterbi parse string posterior expect number applications grammar production require reestimating rule probabilities b compute incrementally single leave right pass input algorithm compare favorably standard bottom parse methods scfgs work efficiently sparse grammars make use earley top control structure process context free rule format without conversion normal form combine computations single algorithm finally algorithm simple extensions process partially bracket input find partial parse likelihoods ungrammatical input
paper discuss follow issue decide whether certain property language competence property performance property claim answer question give priori answer depend formal devices formal grammars machine available us describe language discuss issue context complexity process center embed relative clauses english scramble german example arbitrary depths embed
natural language generation nlg techniques use automatically produce technical documentation domain knowledge base linguistic contextual model discuss application nlg technology technical usefulness cost benefit perspective discussion base largely experience idas documentation generation project reactions various interest people industry idas hope summary experience idas lessons learn beneficial researchers wish build technical documentation generation systems
survey recent applications orient nl generation systems claim despite different theoretical background systems remarkably similar architecture term modules divide generation process computations modules perform way modules interact also compare consensus architecture among apply nlg systems psycholinguistic knowledge humans speak argue least aspects consensus architecture seem agreement know human language production despite fact psycholinguistic plausibility general goal developers survey systems
dependency grammar use linguists basis syntactic components grammar formalisms also use natural language parse china attempt make use grammar formalism parse chinese sentence use corpus base techniques paper review properties dependency grammar embody four axioms well formedness condition dependency structure show allow multiple governors do followers formalism unnecessary practice augment dependency grammar functional label also discuss light build functional structure sentence parse also facilitate semantic interpretation
paper present overview current research concern knowledge extraction technical texts particular use empirical techniques identification generation semantic representation consider key step discovery useful n grams correlations cluster n grams
statistical language model frequently suffer lack train data problem alleviate cluster reduce number free parameters need train however cluster model follow drawback enough data train unclustered model cluster variant may perform worse currently use language model corpora eg wall street journal corpus performances cluster unclustered model compare try address question develop follow two ideas first get cluster algorithm potentially high performance exist algorithm extend deal higher order n grams second make possible cluster large amount train data efficiently heuristic speed algorithm present result cluster algorithm use cluster trigrams wall street journal corpus language model produce compete exist back model especially little train data available cluster model clearly outperform back model
natural language understand applications interactive plan face face translation require extensive inferencing many inferences base mean particular open class word provide representation support lexically base inferences primary concern lexical semantics representation language first order logic well understand semantics multitude inferencing systems implement thus prime candidate serve lexical semantics representation however argue fol although good start point need extend efficiently concisely support lexically base inferences need
infants face difficult problem segment continuous speech word without benefit fully develop lexicon several source information speech might help infants solve problem include prosody semantic correlations phonotactics research date focus determine source infants might sensitive little work do determine potential usefulness source computer simulations report first attempt measure usefulness distributional phonotactic information segment phoneme sequence algorithms hypothesize different segmentations input word select best hypothesis accord minimum description length principle result indicate useful information phoneme distributions phonotactic rule combination source useful
paper describe parser sequence english part speech label utilise probabilistic grammar train use inside outside algorithm initial metagrammar define linguist rule compatible metagrammatical constraints automatically generate train rule low probability reject yield wide coverage parser capable rank alternative analyse series corpus base experiment describe parser performance
implement approach couple constraint base phonology component articulatory speech synthesizer propose articulatory gesture ensure tight connection components comprise physical phonetic phonological aspects phonological model eg syllabification phonological process german final devoice express constraint logic program language cuf extend cuf arithmetic constraints allow simultaneous description phonology phonetics thus declarative lexicalist theories grammar hpsg may enrich level detail phonetic realisation initial acoustic demonstrations show approach principle capable synthesize full utterances linguistically motivate fashion
analyze compound nouns one crucial issue natural language process systems particular systems aim wide coverage domains paper propose method analyze structure japanese compound nouns use word collocations statistics thesaurus experiment conduct one hundred and sixty thousand word collocations analyze compound nouns average length forty-nine character accuracy method eighty