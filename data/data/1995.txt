present result investigation set elementary tree lexicalize tree adjoin grammar represent lexical knowledge representation language datr evans gazdar 1989ab ltag consideration base one describe abeille et al one thousand, nine hundred and ninety approach similar vijay shanker schabes one thousand, nine hundred and ninety-two formulate inheritance hierarchy efficiently encode elementary tree however rather create new representation formalism task employ techniques establish utility lexically orient frameworks particular show datr default mechanism use eliminate need non immediate dominance relation descriptions surface ltag entries allow us embed tree structure feature theory manner reminiscent hpsg subcategorisation frame hence express lexical rule relations feature structure
present approach natural language understand base computable grammar constructions construction consist set feature form description mean context grammar set constructions kind grammar key element mincal implement natural language speech enable interface line calendar system system consist nl grammar parser line calendar domain knowledge base date time meet application knowledge base calendar speech recognizer speech generator interfaces modules claim architecture work general speak interfaces small domains paper present two novel aspects architecture use constructions integrate descriptions form mean context one whole b separation domain knowledge application knowledge describe data structure encode constructions structure knowledge base interactions key modules system
paper present parser base description logics dl german hpsg style fragment specify parser rely mainly inferential capabilities underlie dl system give preferential default extension dl disambiguation achieve choose parse contain qualitatively minimal number exceptions
frame base knowledge representation model adopt idhs intelligent dictionary help system describe paper use represent lexical knowledge acquire automatically conventional dictionary moreover enrichment process perform dictionary knowledge base dynamic exploitation knowledge base exploitation properties lexical semantic relations also describe
paper describe tool design generate semi automatically sortal constraints specific domain use natural language nl understand system tool evaluate use sri gemini nl understand system atis domain
propose lexical organisation multilingual lexical databases mldb organisation base acceptions word sense detail lexical organisation show mock build experiment also present current work define prototyping specialise system management acception base mldb keywords multilingual lexical database acception linguistic structure
parse unrestricted language wide cover grammars often undergenerate undergeneration tackle either sentence correction grammar correction thesis concentrate upon automatic grammar correction machine learn grammar solution problem undergeneration broadly speak grammar correction approach classify either data drive model base data drive learners use data intensive methods acquire grammar typically use grammar formalisms unsuited need practical text process guarantee result grammar adequate subsequent semantic interpretation data drive learners acquire grammars generate string humans would judge grammatically ill form overgenerate fail assign linguistically plausible parse model base learners knowledge intensive reliant success upon completeness model grammaticality practice model incomplete give thesis deal undergeneration learn hypothesise combine use data drive model base learn would allow data drive learn compensate model base learn incompleteness whilst model base learn would compensate data drive learn unsoundness describe system use test hypothesis empirically system combine data drive model base learn acquire unification base grammars suitable practical text parse use speak english corpus data quantitatively measure undergeneration overgeneration parse plausibility show hypothesis correct
profit extension standard prolog feature inheritance templates profit allow programmer grammar developer declare inheritance hierarchy feature templates sort feature term use profit program together prolog term provide clearer description language linguistic structure profit compile sort feature term prolog term representation build prolog term unification use unification sort feature structure special unification algorithm need profit program compile prolog program meta interpreter need execution profit thus provide direct step grammars develop sort feature term prolog program usable practical nlp systems
propose bottom variant earley deduction bottom deduction preferable top deduction allow incremental process even head drive grammars data drive subsumption check need preference value attach lexical items use guide best first search discuss scan step bottom earley deduction index scheme help avoid useless deduction step
novel approach hpsg base natural language process describe use line compiler automatically prime declarative grammar generation parse input prim grammar advance earley style processor way provide elegant solution problems empty head efficient bidirectional process illustrate special case hpsg generation extensive test large hpsg grammar reveal important constraints form grammar
describe compiler development environment feature augment two level morphology rule integrate full nlp system compiler optimize class languages include many european ones rapid development debug descriptions new languages key design decision compose morphophonological morphosyntactic information lexicon compile description result typical compilation time minute allow reasonably full feature base description french inflectional morphology develop month linguist new system
paper present interactive spell correction system modern greek entire system base morphological lexicon emphasis give development lexicon especially far storage economy speed efficiency dictionary coverage concern extensive research conduct computer engineer linguisting field order describe inflectional morphology economically possible
present dialogue component speech speech translation system verbmobil contrast conventional dialogue systems mediate dialogue process maximally fifty dialogue depth special requirements like robustness efficiency lead three layer hybrid architecture dialogue module use statistics automaton planner dialogue memory construct incrementally
present variations affect association measure thresholding technique learn selectional restrictions line corpora use wide coverage noun taxonomy statistical measure generalize appropriate semantic class evaluation measure selectional restrictions learn task discuss finally experimental evaluation variations report
nptool fast accurate system extract noun phrase english texts purpose eg information retrieval translation unit discovery corpus study general introduction system architecture present outline follow examination recently write constraint syntax evaluation report conclude paper
possible specify grammatical representation descriptors application guidelines degree consistently apply different grammarians eg produce benchmark corpus parser evaluation arguments give little empirical evidence article report double blind experiment surface orient morphosyntactic grammatical representation use large scale english parser argue consistently applicable representation morphology also shallow syntax specify grammatical representation near one hundred coverage run text specify reasonable effort especially representation base structural distinctions ie structurally resolvable
two main methodologies construct knowledge base natural language analyser linguistic data drive recent state art part speech taggers base data drive approach know feasibility linguistic rule base approach relate level description success data drive approach part speech analysis may appear surprise paper case make syntactic nature part speech tag new tagger english use linguistic distributional rule outline empirically evaluate test benchmark corpus thirty-eight thousand word previously unseen text syntax base system reach accuracy ninety-nine compare ninety-five ninety-seven accuracy best competitors result suggest feasibility linguistic approach also part speech analysis
concern dependency orient morphosyntactic parse run text parse grammar avoid introduce structurally unresolvable distinctions order optimise accuracy parser also beneficial grammarian expressive structural representation available possible reductionistic parse system policy may result considerable ambiguity input however even massive ambiguity tackle efficiently accurate parse description effective parse technology
paper describe substitutional approach ellipsis resolution give comparable result dalrymple shieber pereira one thousand, nine hundred and ninety-one without need order sensitive interleave quantifier scoping ellipsis resolution argue order independence result view semantic interpretation build description semantic composition instead common view interpretation actually perform composition
argue resource share commonly manifest semantic account coordination instead appropriately handle term structure share lfg f structure provide extension previous account lfg semantics dalrymple et al 1993b accord dependencies f structure view resources result one one correspondence use f structure mean maintain result system sufficiently restrict case approach overgenerate property resource sensitivity resource share appear problematic actually provide explanatory advantage systems freely replicate resources derivation
show categorial deduction implement higher order linear logic program thereby realise parse deduction associative non associative lambek calculi provide method solution parse problem lambek categorial grammar applicable variety extensions
provide constraint base computational model linear precedence employ hpsg grammar formalism extend feature logic add wide range constraints involve precedence describe sound complete terminate deterministic constraint solve procedure give deterministic computational model achieve weaken logic sufficient linguistic applications involve word order
describe method analyse temporal structure discourse take account effect tense aspect temporal adverbials rhetorical structure minimise unnecessary ambiguity temporal structure part discourse grammar implement carpenter ale formalism method build temporal structure discourse combine constraints preferences use constraints reduce number possible structure exploit hpsg type hierarchy unification purpose apply preferences choose remain options use temporal center mechanism end recommend underspecified representation structure use techniques use avoid generate temporal rhetorical structure higher level information use disambiguate
paper describe combinatory categorial formalism call multiset ccg capture syntax interpretation free word order languages turkish formalism compositionally derive predicate argument structure information structure eg topic focus sentence parallel uniformly handle word order variation among arguments adjuncts within clause well complex clauses across clause boundaries
paper define unification base id lp grammars base type feature structure nonterminals propose variant earley algorithm decide whether give input sentence member language generate particular type unification id lp grammar solution problem nonlocal flow information unification id lp grammars discuss seiffert one thousand, nine hundred and ninety-one incorporate algorithm time try connect technical work linguistics present example problem result hpsg approach linguistics hinrichs nakasawa one thousand, nine hundred and ninety-four richter sailer one thousand, nine hundred and ninety-five computational linguistics draw connections approach systems implement hpsg especially troll system gerdemann et al forthcoming
show linear index grammars process polynomial time exploit constraints make possible extensive use structure share paper describe formalism powerful linear index grammar also process polynomial time use similar techniques formalism refer partially linear patr manipulate feature structure rather stack
paper provide probabilistic interpretation type feature structure similar use pollard sag begin version interpretation lack treatment entrant feature structure provide extend interpretation allow sketch algorithms allow numerical parameters probabilistic interpretations hpsg estimate corpora
paper present analysis temporal anaphora sentence contain quantification events within framework discourse representation theory analysis partee one thousand, nine hundred and eighty-four quantify sentence introduce temporal connective give wrong truth condition temporal connective subordinate clause problem previously analyze de swart one thousand, nine hundred and ninety-one instance proportion problem give solution generalize quantifier approach use careful distinction different notions reference time base kamp reyle one thousand, nine hundred and ninety-three propose solution problem within framework drt show applications solution additional temporal anaphora phenomena quantify sentence
paper propose robust parser parse extragrammatical sentence parser recover use syntactic information easily modify extend utilize syntactic information
paper present constraint base semantic formalism hpsg syntax semantics interface directly implement syntactic condition quantifier scoping distributivity construction semantic representations guide general principles govern interaction syntax semantics principles act constraint narrow set possible interpretations sentence mean ambiguous sentence represent single partial representations call younderspecified discourse representation structure constraints add monotonically gain information content sentence need build large number alternative representations sentence filter subsequent discourse world knowledge advantage udrss allow monotonic incremental interpretation also equip truth condition proof theory allow inferences draw directly structure quantifier scope resolve
paper adresses problem reason ambiguities semantic representations present leave scope relations quantifiers operators unspecified truth condition provide representations different consequence relations judge basis intuitive correctness finally inference pattern present operate directly underspecified structure ie rely translation set disambiguations
paper investigate syntax extraposition hpsg framework present english german data partly take corpora provide analysis use lexical rule nonlocal dependency condition bind dependency formulate relative antecedent extraposed phrase entail fix site extraposition exist analysis account interaction extraposition front coordination predict constraints multiple extraposition
paper describe method automatically acquire syntactic semantic classifications unknown word method reduce search space lexical acquisition problem utilize leave right context unknown word link grammar provide convenient framework implement method
paper propose corpus base language model topic identification analyze association noun noun noun verb pair lob corpus word association norms base three factor one word importance two pair co occurrence three distance train paragraph sentence level noun noun noun verb pair respectively topic coherence postulation nouns strongest connectivities nouns verbs discourse form prefer topic set collocational semantics use identify topics paragraph discuss topic shift phenomenon among paragraph
bi directional korean english dialog translation system design implement use memory base translation technique system kemdt korean english memory base dialog translation system perform korean english english korean translation use unify memory network extend marker pass algorithm resolve word order variation frequent word omission problems korean classify concept sequence element four different type extend marker pass base translation algorithm unlike previous memory base translation systems kemdt system develop bilingual memory network unify bi directional marker pass translation algorithm efficient language specific process separate morphological processors memory base translator kemdt technology provide hierarchical memory network efficient marker base control recent example base mt paradigm
paper concern detection correction sub sentential english text errors previous spell program unless restrict small set word operate post processors date grammar checker program deal ill form input usually step directly spell considerations full scale parse assume complete sentence work describe aim evaluate effectiveness shallow sub sentential process feasibility cooperative error check build test appropriately error process system system construction outline incorporate morphological check use new two level error rule direct letter graph tag positional trigrams partial parse intend test discuss
work report result study do within larger project semantics natural languages view field artificial intelligence computational linguistics project choose corpus insurance claim report texts deal relatively circumscribe domain road traffic thereby limit extra linguistic knowledge necessary understand moreover texts present number specific characteristics insofar write quasi institutional set impose many constraints production first determine constraints order show provide writer mean create succint text possible symmetric way provide reader mean interpret text distinguish factual argumentative aspects
paper concern anaphora resolution prepositional phrase pp attachment frequent ambiguities natural language process several methods propose deal phenomenon separately however none propose systems consider way deal phenomena tackle issue propose algorithm co ordinate treatment two problems efficiently ie aim also exploit step result component provide
paper cmp lg yymmnnn accept publication student session eacl ninety-five outline ongoing work use statistical unsupervised neural network methods cluster word untagged corpora approach interest attempt understand development human intuitive categorization language well try improve computational methods natural language understand preliminary result use simple statistical approach describe along work use unsupervised neural network distinguish sense class word fall
paper describe implementation base recent model psycholinguistic literature define parse operation allow reanalysis dependencies within incremental monotonic process architecture discuss search strategies application head initial language english head final language japanese
literal movement grammars lmgs provide general account extraposition phenomena attribute mechanism allow top displacement syntactical information lmgs provide simple efficient treatment complex linguistic phenomena cross serial dependencies german dutch separate treatment natural language parse phase closely resemble traditional context free treatment disambiguation phase carry use match oppose full unification employ current grammar formalisms linguistical relevance
paper present grammar formalism design use data orient approach language process formalism best describe right linear index grammar extend linguistically interest ways paper go investigate corpus pre parse formalism may process provide probabilistic language model use parse fresh texts
german language model xerox hmm tagger present model performance compare two german taggers partial parameter estimation full adaption parameters pre tag corpora ambiguity type resolve model analyse compare ambiguity type english french finally model error type describe argue although overall performance model german comparable result english french exact analysis demonstrate important differences type disambiguation involve german
paper describe approach sentence categorization originality base natural properties languages train set dependency implementation fast small robust textual errors tolerant test french english spanish german discrimination system give interest result achieve one test nine hundred and ninety-four correct assignments real sentence resolution power base grammatical word common word alphabet grammatical word alphabet language disposal system compute likelihood select name language optimum likelihood tag sentence non resolve ambiguities maintain discuss reason lead us use linguistic facts present several directions improve system classification performance categorization sentence linguistic properties show difficult problems sometimes simple solutions
paper report preliminary phase ongoing research towards develop intelligent tutor environment turkish grammar one components environment corpus search tool among aspects language use present learner sample sentence along morphological analyse follow brief introduction turkish language morphology paper describe morphological analysis ambiguity resolution use construct corpus use search tool finally implementation issue detail involve user interface tool discuss
dialect group discover objectively automatically cluster analysis phonetic transcriptions find linguistic atlas first step analysis computation linguistic distance pair sit compute levenshtein distance phonetic string correlate closely much laborious technique determine count isoglosses accurate familiar metric compute ham distance base whether vocabulary entries match actual cluster step traditional agglomerative cluster work better top technique partition around medoids agglomerative cluster phonetic string comparison distance apply gaelic reasonable dialect boundaries obtain correspond national within ireland provincial boundaries
paper compare two compete approach part speech tag statistical constraint base disambiguation use french test language impose time limit experiment amount time spend design constraint system time use train test easy implement statistical model describe two systems compare result accuracy statistical method reasonably good comparable taggers english constraint base tagger seem superior even limit time allow rule development
earlier describe two taggers french statistical one constraint base one two taggers tokeniser morphological analyser paper describe aspects work concern definition tagset build lexicon derive exist two level morphological analyser definition lexical transducer guess unknown word
paper define language l specify lfg grammars enable constraints lfg composite ontology c structure synchronise f structure state directly appeal lfg construction algorithm need use l specify schemata annotate rule lfg uniqueness completeness coherence principles broader issue raise work note discuss
provide unify account sentence level text level anaphora within framework dependency base grammar model criteria anaphora resolution within sentence boundaries rephrase major concepts gb bind theory text level anaphora incorporate adapt version grosz sidner style focus model
paper present semantic study motion complexes ie motion verb follow spatial preposition focus spatial temporal intrinsic semantic properties motion verbs one hand spatial prepositions hand address problem combine basic semantics order formally automatically derive spatiotemporal semantics motion complex spatiotemporal properties components
present new method characterize interpretive possibilities generate elliptical constructions natural language unlike previous analyse postulate ambiguity interpretation derivation full clause source ellipsis analysis require hide ambiguity analysis follow relatively directly abstract statement ellipsis interpretation problem predict correctly wide range interactions ellipsis semantic phenomena quantifier scope bind anaphora finally although analysis state nonprocedurally admit direct computational method generate interpretations
paper present algorithm tag word whose part speech properties unknown unlike previous work algorithm categorize word tokens context instead word type algorithm evaluate brown corpus
nominalization highly productive phenomena languages process nominalization eject verb syntactic role nominal position original verb often replace semantically empty support verb eg make proposal choice support verb give nominalization unpredictable cause problem language learners well natural language process systems present method discover support verbs untagged corpus via low level syntactic process comparison arguments attach verbal form potential nominalized form result process list potential support verbs nominalized form give predicate
automatic word classification system design process word unigram bigram frequency statistics extract corpus natural language utterances system implement binary top form word cluster employ average class mutual information metric result classifications hierarchical allow variable class granularity word represent structural tag unique n bite number significant bite pattern incorporate class information access structural tag immediately provide access classification level correspond word classification system successfully reveal structure english phonemic semantic level system compare directly indirectly recent word classification systems class base interpolate language model construct exploit extra information supply classifications experiment show new model improve model performance
computers interpret language incrementally recent years psycholinguistic evidence incremental interpretation become compel suggest humans perform semantic interpretation constituent boundaries possibly word word however possible computational applications receive less attention paper consider various potential applications particular graphical interaction dialogue review theoretical computational tool available map fragment sentence fully scoped semantic representations finally tease apart relationship dynamic semantics incremental interpretation
despite large amount theoretical work do non constituent coordination last two decades many computational systems still treat coordination use adapt parse strategies similar fashion sysconj system develop atns paper review theoretical literature show many theoretical account actually worse coverage account base process finally show process account describe formally declaratively term dynamic grammars
paper describe parser categorial grammar provide fully word word incremental interpretation parser require fragment sentence form constituents thereby avoid problems spurious ambiguity paper include brief discussion relationship basic categorial grammar formalisms hpsg dependency grammar lambek calculus also include discussion issue arise parse lexicalise grammars possibilities use statistical techniques tune particular languages
paper introduction natural language interfaces databases nlidbs brief overview history nlidbs first give advantage disadvantage nlidbs discuss compare nlidbs formal query languages form base interfaces graphical interfaces introduction linguistic problems nlidbs confront follow benefit readers less familiar computational linguistics discussion move nlidb architectures portability issue restrict natural language input systems include menu base nlidbs nlidbs reason capabilities less explore areas nlidb research present namely database update meta knowledge question temporal question multi modal nlidbs paper end reflections current state art
dialogues agents autonomous agent deliberate whether accept reject contributions current speaker speaker simply assume proposal assertion accept however examination corpus naturally occur problem solve dialogues show agents often explicitly indicate acceptance rejection rather speaker must infer whether hearer understand accept current contribution base indirect evidence provide hearer next dialogue contribution paper propose model role informationally redundant utterances provide evidence support inferences mutual understand acceptance model one require theory mutual belief support mutual beliefs various strengths two explain function class informationally redundant utterances explain account three contribute theory dialogue show mutual beliefs infer absence master slave assumption
discourse strategy strategy communicate another agent design effective dialogue systems require design agents choose among discourse strategies claim design effective strategies must take cognitive factor account propose new method test hypothesize factor present experimental result effective strategy support deliberation propose method computational dialogue simulation provide new empirical basis computational linguistics
paper provide detail description sentence segmentation system first introduce cmp lg nine million, four hundred and eleven thousand and twenty-two provide result systematic experiment involve sentence boundary determination include context size lexicon size single case texts also include result successfully adapt system german french source code system available compress tar file ftp cs trcsberkeleyedu pub cstr satztarz
paper present relevant issue consider design general purpose lemmatizer tagger basque euslem lemmatizer tagger conceive basic tool necessary linguistic applications use lexical data base morphological analyzer previously develop implement due characteristics language tagset propose structure level level refinement previous one sense add detail information focus problems find design tagset strategies morphological disambiguation use
recognition problem attribute value grammars avgs show undecidable johnson one thousand, nine hundred and eighty-eight therefore general form avgs practical use paper study restrict form avg recognition problem decidable though still np complete r avg show r avg formalism capture context free languages introduce variation call line parsability constraint honest parsability constraint let us different type r avg coincide precisely well know time complexity class
paper assess complexity result formalisms describe feature theories use computational linguistics show complexity result immediate conclusions draw complexity recognition problem unification grammars use feature theories one hand complexity feature theories provide upper bind complexity unification grammars hand complexity feature theories need provide lower bind therefore argue formalisms describe actual unification grammars instead feature theories thus complexity result formalisms judge upon hardness unification grammars computational linguistics
pattern match capabilities neural network use locate syntactic constituents natural language paper describe fully automate hybrid system use neural net operate within grammatic framework address representation language connectionist process describe methods constrain problem size function network briefly explain result give
prove theorem state semantics encode compositional semantics mean essentially standard definition compositionality formally vacuous show compositional semantics require systematic mean function arbitrary must belong class possible distinguish compositional non compositional semantics result believe paper clarify concept compositionality open possibility make systematic formal comparisons different systems grammars
comparison make vectors derive use ordinary co occurrence statistics large text corpora vectors derive measure inter word distance dictionary definitions precision word sense disambiguation use co occurrence vectors one thousand, nine hundred and eighty-seven wall street journal 20m total word higher use distance vectors collins english dictionary 60k head word 16m definition word however experimental result suggest distance vectors contain different semantic information co occurrence vectors
paper show first problems raise proper name natural language process second introduce knowledge representation structure use base conceptual graph explain techniques use process know unknown proper name last give performance system work intend deal
experiment design explore relationship tag accuracy nature tagset describe use corpora english french swedish particular question internal versus external criteria tagset design consider general conclusion external linguistic criteria follow problems associate tag unknown word inflect languages briefly consider
paper present computational model conversational participants collaborate order make refer action successful model base view language goal direct behavior propose content refer expression account plan paradigm approach allow process build refer expressions identify referents capture plan construction plan inference also allow us account participants clarify refer expression use meta action reason manipulate plan derivation correspond refer expression account clarification goals arise infer clarification plan affect agent propose agents certain state mind state include intention achieve goal refer plan agents currently consider mental state sanction adoption goals acceptance infer plan act link understand generation
describe compiler translate set hpsg lexical rule interaction definite relations use constrain lexical entries compiler ensure automatic transfer properties unchanged lexical rule thus operational semantics full lexical rule mechanism use hpsg linguistics provide program transformation techniques use advance result encode final output constitute computational counterpart linguistic generalizations capture lexical rule allow fly application
paper propose evaluation adequacy constraint logic program paradigm natural language process theoretical aspects question discuss several work adopt pragmatic point view argumentation rely concrete solutions use actual contraints clp sense neither easy direct however clp improve parse techniques several aspects concision control efficiency direct representation linguistic formalism discussion illustrate several examples presentation hpsg parser
conduct empirical analysis relation control discourse structure apply control criteria four dialogues identify three level discourse structure investigate mechanism change control structure find utterance type cue word predict shift control participants use certain type signal discourse goals proceed successfully resort interruptions
conversation two people usually mix initiative control conversation transfer one person another apply set rule transfer control four set dialogues consist total one thousand, eight hundred and sixty-two turn application control rule let us us derive domain independent discourse structure derive structure indicate initiative play role structure discourse order explore relationship control initiative discourse process like center analyze distribution four different class anaphora two data set distribution indicate control segment hierarchically relate others analysis suggest discourse participants often mutually agree change topic also compare initiative task orient advice give dialogues find allocation control manner control transfer radically different two dialogue type differences explain term collaborative plan principles
speak language process require speech natural language integration moreover speak korean call unique process methodology due linguistic characteristics paper present skope connectionist symbolic speak korean process engine emphasize one connectionist symbolic techniques must selectively apply accord relative strength weakness two linguistic characteristics korean must fully consider phoneme recognition speech language integration morphological syntactic process design implementation skope demonstrate connectionist symbolic hybrid architectures construct speak agglutinative language process also skope present many novel ideas speech language process phoneme recognition morphological analysis syntactic analysis experiment show skope viable approach speak korean process
paper describe abstract machine linguistic formalisms base type feature structure hpsg core design abstract machine give detail include compilation process high level language abstract machine language implementation abstract instructions machine engine support unification type possibly cyclic feature structure separate module deal control structure instructions accommodate parse phrase structure grammars treat linguistic formalism high level declarative program language apply methods prove useful computer science study natural languages grammar specify use formalism endow operational semantics
use thermodynamic formalism introduce gibbsian model identification regular grammars base positive evidence model mimic natural language acquisition procedure drive prosody represent thermodynamical potential statistical question face estimate incidenc e matrix subshift finite type sample produce gibbs state whose potential know model acquaint robustness language acquisition procedure language change probabilistic appr oach use avoid invoke ad hoc restrictions berwick subset principle
like many verb final languages germn display considerable word order freedom syntactic constraint order nominal arguments verb long verb remain final position effect refer scramble interpret transformational frameworks leftward movement arguments furthermore arguments embed clause may move clause effect refer long distance scramble scramble recently receive considerable attention syntactic literature status long distance scramble rarely address reason problematic status data long distance scramble highly dependent pragmatic context also strongly subject degradation due process constraints case center embed immediately clear whether assume observe unacceptability highly complex sentence due grammatical restrictions whether assume competence grammar place restrictions scramble therefore sentence fact grammatical unacceptability grammatically possible word order due process limitations paper argue second view present process model german
semantic theories natural language associate mean utterances provide mean lexical items rule determine mean larger units give mean part mean often assume combine via function application work well constituent structure tree use guide semantic composition however believe functional structure lexical functional grammar best use provide syntactic information necessary constrain derivations mean cross linguistically uniform format difficult however reconcile approach combination mean function application contrast compositional approach present deductive approach assemble mean base reason constraints mesh well unordered nature information functional structure use linear logic glue assemble mean allow coherent treatment lfg requirements completeness coherence well modification quantification
one important question apply nlg benefit value add business speak nlg technology offer template base approach despite importance question apply nlg community however discuss much research nlg community think pity paper try summarize issue involve recap current think topic goal answer question think know enough able rather increase visibility issue research community hope get input ideas important question conclude list specific research areas would like see work think would increase value add nlg templates
present lexgram system amalgam lambek categorial grammar head drive phrase structure grammar hpsg show grammar formalism implement well structure useful tool actual grammar development
give previously unseen form morphologically n ways ambiguous best estimator lexical prior probabilities various function form argue best estimator provide compute relative frequencies various function among hapax legomena form occur exactly corpus result important implications development stochastic morphological taggers especially initial hand tag corpus require predict lexical priors low frequency morphologically ambiguous type would occur give corpus one concentrate tag good representative sample hapax legomena rather extensively tag word frequency range
paper discuss relationship memoized top recognizers chart parsers present version memoization suitable continuation pass style program apply simple formalization top recognizer yield terminate parser
draw appropriate defeasible inferences prove one pervasive puzzle natural language process recurrent problem pragmatics paper provide theoretical framework call stratify logic accommodate defeasible pragmatic inferences framework yield algorithm compute conversational conventional scalar clausal normal state implicatures presuppositions associate utterances algorithm apply equally simple complex utterances sequence utterances
rely strength linguistic philosophical perspectives construct framework offer unify explanation presuppositions existential commitment use rich ontology set methodological principles embed essence meinong philosophy grice conversational principles stratify logic unrestricted interpretation quantifiers result logical formalism yield tractable computational method uniformly calculate presuppositions give utterance include existential ones
since austin introduce term infelicity linguistic literature flood use formal computational explanation give thesis provide one infelicities occur pragmatic inference cancel contribution assume existence finer grain taxonomy respect pragmatic inferences show one want account natural language expressiveness one distinguish pragmatic inferences felicitous defeat pragmatic inferences infelicitously defeasible thus show one consider least three type information indefeasible felicitously defeasible infelicitously defeasible cancellation last determine pragmatic infelicities new formalism devise accommodate three level information call stratify logic within able express formally notions utterance presuppose p utterance infelicitous special attention pay implications work solve well know existential philosophical puzzle formalism yield algorithm compute interpretations utterances determine associate presuppositions signal infelicitous utterances implement common lisp algorithm apply equally simple complex utterances sequence utterances
examine problem generate definite noun phrase appropriate refer expressions ie noun phrase one successfully identify intend referent hearer whilst two convey false conversational implicatures grice one thousand, nine hundred and seventy-five review several possible computational interpretations conversational implicature maxims different computational cost argue simplest may best seem closest human speakers describe recommend algorithm detail along specification resources host system must provide order make use algorithm implementation use natural language generation component idas system paper appear april june one thousand, nine hundred and ninety-five issue cognitive science make available cmp lg permission ablex publishers journal
optimality theory constraint base theory phonology allow constraints violate consequently implement theory present problems declarative constraint base process frameworks basis two regularity assumptions candidate set regular constraints model transducers paper present prove correct algorithms compute action constraints hence derive surface form
paper show default base phonologies potential capture morphophonological generalisations capture non defaul theories achieve result offer characterisation underspecification theory optimality theory term methods order default result mean machine learn techniques build non defualt analyse may provide suitable basis morphophonological analysis
statistical rule base approach part speech pos disambiguation advantage limitations especially korean narrow windows provide hide markov model hmm cover necessary lexical long distance dependencies pos disambiguation hand rule base approach accurate flexible new tag set languages regard statistical rule base hybrid method take advantage approach call robust flexible pos disambiguation present one method two phase learn architecture hybrid statistical rule base pos disambiguation especially korean method statistical learn morphological tag error correct rule base learn brill one thousand, nine hundred and ninety-two style tagger also design hierarchical flexible korean tag set cope multiple tag applications require different tag set experiment show two phase learn method overcome undesirable feature solely hmm base solely rule base tag especially morphologically complex korean
paper introduce spell correction system integrate seamlessly morphological analysis use multi tape formalism handle various semitic error problems illustrate reference arabic syriac examples model handle errors vocalisation diacritics phonetic syncopation morphographemic idiosyncrasies addition damerau errors complementary correction strategy morphologically sound morphosyntactically ill form word outline
paper present ongoing work plan base discourse processor develop context enthusiast spanish english translation system part janus multi lingual speech speech translation system demonstrate theories discourse postulate strict tree structure discourse either intentional attentional level totally adequate handle spontaneous dialogues present extension approach along implementation plan base discourse processor demonstrate implementation approach outperform implementation base strict tree structure approach
bernard lang define parse calculation intersection fsa input cfg view input parse fsa rather string combine well approach speech understand systems parse take word lattice input rather word string furthermore certain techniques robust parse model finite state transducers paper investigate generalize approach unification grammars particular concentrate might calculation intersection fsa dcg show exist parse algorithms easily extend fsa input however also show termination properties change drastically show undecidable whether intersection fsa dcg empty even dcg line parsable furthermore discuss approach cope problem
lexicalist approach machine translation offer significant advantage development linguistic descriptions however shake bake generation algorithm whitelock coling ninety-two np complete present polynomial time algorithm lexicalist mt generation provide sufficient information transfer ensure determinism
linguistic constraints effectively resolve parse location naturally introduce paper show constraints propagate memoizing parser chart parser much way variable bind provide general treatment constraint coroutining memoization prolog code simple application technique bouma van noord one thousand, nine hundred and ninety-four categorial grammar analysis dutch provide
relationship lexical functional grammar lfg functional structure f structure sentence semantic interpretations express directly fragment linear logic way correctly explain constrain interactions quantifier scope ambiguity bind anaphora intensionality deductive approach semantic interpretaion obviate need additional mechanisms cooper storage represent possible scopes quantify np explain interactions quantify nps anaphora intensional verbs seek single specification linear logic argument requirements intensional verbs sufficient derive correct read predictions intensional verb clauses nonquantified quantify direct object particular de dicto de read derive quantify object effect type raise quantify rule frameworks follow linear logic theorems approach resemble current categorial approach important ways differ allow greater type flexibility categorial semantics maintain precise connection syntax result able provide derivations certain read sentence intensional verbs complex direct object derivable current purely categorial account syntax semantics interface
syntactic natural language parsers show inadequate process highly ambiguous large vocabulary text evidence poor performance domains like wall street journal movement away parse base approach text process general paper describe spatter statistical parser base decision tree learn techniques construct complete parse every sentence achieve accuracy rat far better publish result work base follow premise one grammars complex detail develop manually interest domains two parse model must rely heavily lexical contextual information analyze sentence accurately three exist n gram model techniques inadequate parse model experiment compare spatter ibm computer manuals parser spatter significantly outperform grammar base parser evaluate spatter penn treebank wall street journal corpus use parseval measure spatter achieve eighty-six precision eighty-six recall thirteen cross bracket per sentence sentence forty word less ninety-one precision ninety recall five cross bracket sentence ten twenty word length
error tolerant recognition enable recognition string deviate mildly string regular set recognize underlie finite state recognizer recognition applications error tolerant morphological process spell correction approximate string match information retrieval description concepts algorithms involve give examples two applications context morphological analysis error tolerant recognition allow misspell input word form correct morphologically analyze concurrently present application error tolerant analysis agglutinative morphology turkish word algorithm apply morphological analysis language whose morphology fully capture single possibly large finite state transducer regardless word formation process morphographemic phenomena involve context spell correction error tolerant recognition use enumerate correct candidate form give misspell string within certain edit distance apply language word list comprise inflect form whose morphology fully describe finite state transducer present experimental result spell correction number languages result indicate recognition work efficiently candidate generation spell correction many european languages english dutch french german italian others large word list root inflect form contain well two hundred thousand form generate candidate solutions within ten forty-five milliseconds edit distance one sparcstation ten forty-one spell correction turkish error tolerant
paper introduce calculus regular expressions replace operator define set replacement expressions concisely encode several alternate variations operation basic case unconditional obligatory replacement upper lower conditional versions replacement upper lower leave right constrain operation leave right contexts upper lower leave right may regular expressions complexity replace expressions denote regular relations replace operator define term regular expression operators use techniques introduce ronald kaplan martin kay regular model phonological rule systems computational linguistics two hundred and three three hundred and thirty-one three hundred and seventy-eight one thousand, nine hundred and ninety-four
variety statistical methods noun compound analysis implement compare result support two main conclusions first use conceptual association enable broad coverage also improve accuracy second analysis model base dependency grammar substantially accurate one base deepest constituents even though latter prevalent literature
describe corpus base induction algorithm probabilistic context free grammars algorithm employ greedy heuristic search within bayesian framework post pass use inside outside algorithm compare performance algorithm n gram model inside outside algorithm three language model task two task train data generate probabilistic context free grammar task algorithm outperform techniques third task involve naturally occur data task algorithm perform well n gram model vastly outperform inside outside algorithm
collaborative plan activities since agents autonomous heterogeneous inevitable conflict arise beliefs plan process case conflict relevant task hand agents engage collaborative negotiation attempt square away discrepancies beliefs paper present computational strategy detect conflict regard propose beliefs engage collaborative negotiation resolve conflict warrant resolution model capable select effective aspect address pursuit conflict resolution case multiple conflict arise select appropriate evidence justify need modification furthermore capture negotiation process recursive propose evaluate modify cycle action model successfully handle embed negotiation subdialogues
introduce three new techniques statistical language model extension model nonmonotonic contexts divergence heuristic together techniques result language model state even fewer parameters low message entropies example techniques achieve message entropy one hundred and ninety-seven bits char brown corpus use eighty-nine thousand, three hundred and twenty-five parameters contrast character four gram model require two hundred and fifty time many parameters order achieve message entropy two hundred and forty-seven bits char fact model perform significantly better use vastly fewer parameters indicate better probability model natural language text
present new approach hpsg process compile hpsg grammars express type constraints definite clause program provide clear computationally useful correspondence linguistic theories implementation compiler perform line constraint inheritance code optimization result able efficiently process hpsg grammars without hand translate definite clause phrase structure base systems
evans gazdar introduce datr simple non monotonic language represent natural language lexicons although number implementations datr exist full language lack explicit declarative semantics paper rectify situation provide mathematical semantics datr present view datr language define certain kinds partial function case formal model provide transparent treatment datr notion global context show datr default mechanism account interpret value descriptors families value index paths
grammars natural languages may learn use genetic algorithms reproduce mutate grammatical rule part speech tag improve quality later generations grammatical components syntactic rule randomly generate evolve rule result improve parse occasionally improve retrieval filter performance allow propagate lust system learn characteristics language sublanguage use document abstract learn document rank obtain parse abstract unlike application traditional linguistic rule retrieval filter applications lust develop grammatical structure tag without prior imposition common grammatical assumptions eg part speech assumptions produce grammars empirically base optimize particular application
previous work study new type dcgs datalog grammars inspire database theory efficiency show better dcg counterparts terminate oldt resolution article motivate variant datalog grammars allow us meta grammatical treatment coordination treatment improve respect previous work coordination logic grammars although research need test respect
logic formalism present increase expressive power id lp format gpsg enlarge inventory order relations extend domain application non siblings allow concise modular declarative statement intricate word order regularities
aggregate different piece similar information necessary generate concise easy understand report technical domains paper present general algorithm combine similar message order generate one coherent sentence process trivial might expect problems encounter briefly describe
present implement compilation algorithm translate hpsg lexicalize feature base tag relate concepts two theories hpsg elaborate principle base theory possible phrase structure tag provide mean represent lexicalize structure explicitly objectives meet give clear definitions determine projection structure lexicon identify maximal projections auxiliary tree foot nod
technique reduce tagset use n gram part speech disambiguation introduce evaluate experiment technique ensure information provide original tagset restore reduce one crucial since interest linguistically motivate tag part speech disambiguation reduce tagset need fewer parameters statistical model allow accurate parameter estimation additionally slight significant improvement tag accuracy
semantic cluster domain form important feature useful perform syntactic semantic disambiguation several attempt make extract semantic cluster domain probabilistic taxonomic techniques however much progress make evaluate obtain semantic cluster paper focus evaluation mechanism use evaluate semantic cluster produce system provide human experts
terminological acquisition important issue learn nlp due constant terminological renewal technological change term play key role several nlp activities machine translation automatic index text understand opposition classical approach propose incremental process terminological enrichment operate exist reference list large corpora candidate term acquire extract variants reference term fastr unification base partial parser acquisition perform within specific morpho syntactic contexts coordinations insertions permutations compound rich conceptual link learn together candidate term cluster term relate coordination yield class conceptually close term graph result insertions denote generic specific relations graceful degradation volume acquisition partial initial list confirm robustness method incomplete data
paper present statistical approach dialogue act process dialogue component speech speech translation system vm statistics dialogue process use predict follow dialogue act application example show support repair unexpected dialogue state occur
tableaux originate decision method logical language also extend obtain structure spell information set sentence term truth value assignments atomic formulas appear approach pursue structure compositional rule provide obtain presuppositions logical statement atomic subformulas presuppositions rule base classical logic semantics show model behaviour presuppositions observe natural language sentence build ldots advantage method exist frameworks presuppositions discuss
paper describe substantial advance analysis parse diagram use constraint grammars addition set type grammar spatial index data make possible efficiently parse real diagram substantial complexity system probably first demonstrate efficient diagram parse use grammars easily retargeted domains work assume diagram available flat collection graphics primitives line polygons circle bezier curve text appropriate future electronic document vectorized diagram convert scan image class diagram analyze include xy data graph genetic diagram draw biological literature well finite state automata diagram state arc example parse four part data graph compose one hundred and thirty-three primitives require thirty-five sec use macintosh common lisp macintosh quadra seven hundred
present pattern match method compile bilingual lexicon nouns proper nouns unaligned noisy parallel texts asian indo european language pair tag information one language use word frequency position information high low frequency word represent two different vector form pattern match new anchor point find noise elimination techniques introduce obtain seven hundred and thirty-one precision also show result use compilation domain specific noun phrase
paper describe linguistic processor speak dialogue system parser receive word graph recognition module input task find best path graph complete solution find robust mechanism select multiple partial result apply show information content rate result improve selection base integrate quality score combine word recognition score context dependent semantic predictions result parse word graph without predictions report
present work progress machine acquisition lexicon sentence unsegmented phone sequence pair primitive representation mean simple exploratory algorithm describe along direction current work discussion relevance problem child language acquisition computer speech recognition
define semantic complexity use new concept mean automata measure semantic complexity understand prepositional phrase depth understand system natural language interface line calendar argue possible measure semantic complexities natural language process systems build systems exhibit relatively complex behavior build semantically simple components
one central knowledge source information extraction system dictionary linguistic pattern use identify conceptual content text paper describe crystal system automatically induce dictionary concept node definitions sufficient identify relevant information train corpus concept node definitions generalize far possible without produce errors minimum number dictionary entries cover positive train instance test accuracy propose definition crystal often surpass human intuitions create reliable extraction rule
shake bake machine translation algorithm head drive phrase structure grammar introduce base algorithm propose whitelock unification categorial grammar translation process analyse determine potential source inefficiency reside proposals introduce greatly improve efficiency generation algorithm preliminary empirical result test involve small grammar present suggestions greater improvement algorithm provide
natural language generation systems embody mechanisms choose whether subsequently refer already introduce entity mean pronoun definite noun phrase relatively systems however consider refer entites mean one anaphoric expressions lingformthe small green one paper look involve generate refer expressions type consideration fit capability standard algorithm refer expression generation lead us suggest revision assumptions underlie exist approach demonstrate usefulness approach one anaphora generation context simple database interface application make observations impact approach refer expression generation generally
paper present novel applications explanation base learn ebl technique parse lexicalize tree adjoin grammars novel aspects immediate generalization parse train set b generalization recursive structure c representation generalize parse finite state transducers highly impoverish parser call stapler also introduce present experimental result use ebl different corpora architectures show effectiveness approach
current nlp systems make significant use punctuation intuitively treatment punctuation seem necessary analysis production text whilst suggest field discourse structure still unclear whether punctuation help syntactic field investigation attempt answer question parse corpus base material two similar grammars one include rule punctuation ignore punctuate grammar significantly perform unpunctuated one conclusion punctuation play useful role syntactic process
predict discourse segment boundaries linguistic feature utterances use corpus speak narratives data present two methods develop segmentation algorithms train data hand tune machine learn multiple type feature use result approach human performance independent test set methods use cross validation machine learn
experiment carry compare swedish teleman english susanne corpora use hmm base novel reductionistic statistical part speech tagger indicate tag teleman corpus difficult task performance two different taggers comparable
traditional approach quantifier scope typically need stipulation exclude read unavailable human understanders paper show quantifier scope phenomena precisely characterize semantic representation constrain surface constituency distinction referential quantificational nps properly observe ccg implementation describe compare approach
dtg design share advantage tag overcome limitations dtg involve two composition operations call subsertion sister adjunction distinctive feature dtg unlike tag complete uniformity way two dtg operations relate lexical items subsertion always correspond complementation sister adjunction modification furthermore dtg unlike tag provide uniform analysis wh movement english kashmiri despite fact wh element kashmiri appear sentence second position sentence initial position english
synchronous tree adjoin grammars use machine translation however translate free order language korean english complicate present mechanism translate scramble korean sentence english combine concepts multi component tag mc tag synchronous tag stag
paper show datr widely use formal language lexical knowledge representation use define ltag lexicon inheritance hierarchy internal lexical rule bottom featural encode use ltag tree allow lexical rule implement covariation constraints within feature structure approach eliminate considerable redundancy otherwise associate ltag lexicon
present argument construction grammars base minimum description length mdl principle formal version ockham razor argument consist use linguistic computational evidence set formal model apply mdl principle prove superiority respect alternative model show construction base representations least order magnitude compact correspond lexicalize representations linguistic data result significant understand relationship syntax semantics consequently choose nlp architectures instance whether process proceed pipeline syntax semantics pragmatics whether linguistic information combine set constraints broader perspective paper argue certain model process also provide methodology determine advantage different approach nlp
present model nlp ontology context directly include grammar model base concept construction consist set feature form set semantic pragmatic condition describe application context description mean model ontology embed grammar eg hierarchy np constructions base correspond ontology ontology also use define contextual parameters eg leave currentquestion time right parser base model allow us build set dialog understand systems include line calendar bank machine insurance quote system propose approach alternative standard pipeline design morphology syntax semantics pragmatics account mean conform intuitions compositionality homomorphism syntax semantics
common feature recent unification base grammar formalisms give user ability define structure however possibility mostly limit include nonmonotonic operations paper show nonmonotonic operations also user define apply default logic reiter one thousand, nine hundred and eighty generalize previous result nonmonotonic sort young round one thousand, nine hundred and ninety-three
explore issue arise try establish connection underspecification hypothesis pursue nlp literature work ambiguity semantics psychological literature theory underspecification develop first principles ie start definition mean sentence semantically ambiguous know way humans deal ambiguity underspecified language specify translation language grammar cover sentence display three class semantic ambiguity lexical ambiguity scopal ambiguity referential ambiguity expressions language denote set sense formalization defeasible reason underspecified representations present base default logic issue confront formalization discuss
paper describe work perform withing crater corpus resources terminology extthem raction mlap ninety-three twenty project fund commission european communities particular address issue adapt xerox tagger spanish order tag spanish version itu international telecommunications union corpus model implement tagger briefly present along modifications perform order use parameters probabilistically estimate initial decisions like tagset lexicon train corpus also discuss finally result present benefit mix model justify
paper concern generate understand discourse anaphoric noun phrase present result analysis discourse anaphoric noun phrase n1233 corpus ten narrative monologues choice definite pronoun phrasal np conform largely gricean constraints informativeness discuss dale reiter appear recent model show augment understand well generate range data present argue integrate center grosz et al one thousand, nine hundred and eighty-three kameyama one thousand, nine hundred and eighty-five model apply uniformly discourse anaphoric pronouns phrasal nps conclude hypothesis address interaction local global discourse process
common algorithms sentence word alignment allow automatic identification word translations parallel texts study suggest identification word translations also possible non parallel even unrelated texts method propose base assumption correlation pattern word co occurrences texts different languages
augment reality research area try embody electronic information space within real world computational devices crucial issue within area recognition real world object situations natural language process much easier determine interpretations utterances even ill form context situation fix therefore introduce robust natural language process system augment reality situation awareness base idea develop portable system call ubiquitous talker consist lcd display reflect scene user look transparent glass ccd camera recognize real world object color bar id cod microphone recognize human voice speaker output synthesize voice ubiquitous talker provide user information relate recognize object use display voice also accept request question voice input user feel talk object system
show belief model dialogue simplify assumption make participants cooperate ie commit goals require deception domains need maintain individual representations deeply nest beliefs instead three specific type belief use summarize state nest belief exist domain entity set design compiler belief model system accept input description agents interactions task domain express fully expressive belief logic non monotonic temporal extensions generate operational belief model use domain sufficient requirements cooperative dialogue include negotiation complex domain plan compile model incorporate belief simplification mention also use simplify temporal logic belief base restrict circumstances beliefs change shall review motivation create system introduce general procedure take logical specification domain procesing operational model shall discuss specific change make procedure limit level abstraction concepts belief nest default reason time express finally shall go work example relate map task simple cooperative problem solve exercise
eric brill introduce transformation base learn show part speech tag fairly high accuracy method apply higher level textual interpretation locate chunk tag text include non recursive basenp chunk purpose convenient view chunk tag problem encode chunk structure new tag attach word automatic test use treebank derive data technique achieve recall precision rat roughly ninety-two basenp chunk eighty-eight somewhat complex chunk partition sentence interest adaptations transformation base learn approach also suggest application
introduce l2kp monadic second order language reason tree characterize strongly context free languages sense set finite tree definable l2kp iff modulo projection local set set derivation tree generate cfg provide flexible approach establish language theoretic complexity result formalisms base systems well formedness constraints tree demonstrate technique sketch two result government bind theory first show free indexation mechanism assume mediate variety agreement bind relationships gb definable l2kp therefore enforcible cfgs second show spite limitation reasonably complete gb account english define l2kp consequently language license account strongly context free illustrate issue involve establish result look definition l2kp chain limitations definition provide insight type natural linguistic principles correspond higher level language complexity close speculation possible significance result generative linguistics
consistent text many word phrase repeatedly use one sentence identical phrase set consecutive word repeat different sentence constituent word sentence tend associate identical modification pattern identical part speech identical modifiee modifier relationships thus syntactic parser parse sentence unify structure part speech modifiee modifier relationships among morphologically identical word complete parse sentence within text provide useful information obtain partial parse sentence paper describe method complete partial parse maintain consistency among morphologically identical word within text regard part speech modifiee modifier relationship experimental result obtain use method technical document offer good prospect improve accuracy sentence analysis broad coverage natural language process system machine translation system
paper describe resolve system use decision tree learn classify coreferent phrase domain business joint venture experiment present performance resolve compare performance manually engineer set rule task result show decision tree achieve higher performance rule two three evaluation metrics develop coreference task addition achieve better performance rule resolve provide framework facilitate exploration type knowledge useful solve coreference problem
paper show induce n best translation lexicon bilingual text corpus use statistical properties corpus together four external knowledge source knowledge source cast filter subset cascade uniform framework new objective evaluation measure use compare quality lexicons induce different filter cascade best filter cascade improve lexicon quality one hundred and thirty-seven plain vanilla statistical method approach human performance drastically reduce size train corpus much smaller impact lexicon quality knowledge source use make practical train small hand build corpora language pair large bilingual corpora unavailable moreover three four filter prove useful even use large train corpora
paper argue importance high quality translation speak language translation systems describe architecture suitable rapid development high quality limit domain translation systems implement within advance prototype english french speak language translator focus paper hybrid transfer model combine unification base rule set trainable statistical preferences roughly rule encode domain independent grammatical information preferences encode domain dependent distributional information preferences train set examples produce system annotate human judge correct incorrect experiment describe model test two thousand utterance sample previously unseen data
order generate cohesive discourse many relations hold text segment need signal reader mean cue word discourse markers program usually simplistic way eg use one marker per relation reality however language offer wide range markers inform choices make order account variety identify parameters govern choices detailled linguistic analyse necessary work one area discourse relations concession family identify underlie pragmatics semantics undertake extensive corpus study examine range markers use english german basis initial classification markers propose generation model produce bilingual text incorporate marker choice overall decision framework
introduce constraints necessary type check higher order concurrent constraint language solve incremental algorithm constraint system extend rational unification constraints xsubseteq say x least structure model weak instance relation tree notion instance carefully choose weaker usual one render semi unification undecidable semi unification serve link unification problems arise type inference consider computational linguistics polymorphic recursion correspond subsumption semi unification problem type constraint problem correspond weak subsumption feature graph linguistics decidability problem whatsit feature graph settle dorrecitedoerreweaksubsumption94 nociterupprosnerjohnson94 contrast dorre algorithm fully incremental refer finite state automata algorithm also lot flexible allow number extensions record sort disjunctive type type declarations others make suitable type inference full fledge program language
paper argue optimality theory provide explanatory model syllabic parse english french argument base psycholinguistic facts mysterious argument buttress computational implementation develop model important several reason first provide demonstration ot use performance domain second suggest new relationship phonological theory psycholinguistics code perl include www interface run http mayodouglassarizonaedu
many theories semantic interpretation use lambda term manipulation compositionally compute mean sentence theories usually implement language prolog simulate lambda term operations first order unification however interest case combinatory categorial grammar account coordination construct do obscure underlie linguistic theory trick need implementation paper show use abstract syntax permit higher order logic program allow elegant implementation semantics combinatory categorial grammar include handle coordination construct
many different tagsets use exist corpora tagsets vary accord objectives specific project may far apart robust parse vs spell correction many situations however one would like uniform access linguistic information encode corpus annotations without know classification scheme detail paper describe tool map unstructured morphosyntactic tag constraint base type configurable specification language standard tagset map rely manually write set map rule automatically check consistency certain case unsharp mappings unavoidable noise ie group word form sl conform specification appear output map system automatically detect noise inform user tool test rule upenn tagset citeup susanne tagset citegarside framework eaglesfootnotelre project eagle cf citeeagles validation phase standardise tagsets european languages
paper describe recent work project amalgam automatic map among lexico grammatical annotation model investigate ways map lead corpus annotation scheme order improve resuability collation include corpora single large annotate corpus provide detail language model develop task speech handwrite recognition particular focus method extract mappings corpora annotate accord one annotation scheme
paper compare consistency base account agreement phenomena unification base grammars implication base account base simple feature extension lambek categorial grammar lcg show lcg treatment account constructions recognize problematic unification base treatments
short abstract computational linguistics researchers university pennsylvania describe ongoing individual joint project
knowledge base machine translation kbmt techniques yield high quality domains detail semantic model limit vocabulary control input grammar scale along dimension mean acquire large knowledge resources also mean behave reasonably definitive knowledge yet available paper describe fill various kbmt knowledge gap often use robust statistical techniques describe quantitative qualitative result japangloss broad coverage japanese english mt system
large scale natural language generation require integration vast amount knowledge lexical grammatical conceptual robust generator must able operate well even piece knowledge miss must also robust incomplete inaccurate input attack problems build hybrid generator gap symbolic knowledge fill statistical methods describe algorithms show experimental result also discuss hybrid generation model use simplify current generators enhance portability even perfect knowledge principle obtainable
present approach syntax base machine translation combine unification style interpretation statistical process approach enable us translate japanese newspaper article english quality far better word word translation novel ideas include use feature structure encode word lattices use unification compose manipulate lattices unification also allow us specify abstract feature delay target language synthesis enough source language information assemble statistical component enable us search efficiently among compete translations locate high english fluency
recently punctuation receive little attention linguistics computational linguistics literature since publication nunberg one thousand, nine hundred and ninety monograph topic however punctuation see stock begin rise spur part nunberg grind break work number valuable inquiries subsequently undertake include hovy arens one thousand, nine hundred and ninety-one dale one thousand, nine hundred and ninety-one pascual one thousand, nine hundred and ninety-three jones one thousand, nine hundred and ninety-four briscoe one thousand, nine hundred and ninety-four continue line research investigate paper nunberg approach present punctuation format devices might incorporate nlg systems insofar present paper focus proper syntactic treatment punctuation differ subsequent work first examine issue generation perspective
paper address issue define context specifically different contexts need understand particular type texts corpus choose homogeneous allow us determine characteristic properties texts certain inferences draw reader characteristic properties come real world domain k context type events texts describe f context genre texts e context together three contexts provide elements resolution anaphoric expressions several type disambiguation show particular argumentation aspect texts essential part context explain inferences draw
present technique construct random field set train sample learn paradigm build increasingly complex field allow potential function feature support increasingly large subgraphs feature weight train minimize kullback leibler divergence model empirical distribution train data greedy algorithm determine feature incrementally add field iterative scale algorithm use estimate optimal value weight statistical model techniques introduce paper differ common much natural language process literature since probabilistic finite state push automaton model build approach also differ techniques common computer vision literature underlie random field non markovian large number parameters must estimate relations learn approach include decision tree boltzmann machine give demonstration method describe application problem automatic word classification natural language process key word random field kullback leibler divergence iterative scale divergence geometry maximum entropy algorithm statistical learn cluster word morphology natural language process
paper describe approach automatic identification lexical information line dictionaries approach use bootstrapping techniques specifically ambiguity dictionary text treat properly approach consist process line dictionary multiple time time refine lexical information previously acquire identify new lexical information strength approach lexical information acquire definitions syntactically ambiguous give information acquire first pass use improve syntactic analysis definitions subsequent pass context lexical knowledge base type lexical information need represent view fix set rather set change give resources lexical knowledge base requirements analysis systems access
account utterance interpretation discourse need face issue discourse context control space interact preferences assume discourse process architecture distinguish grammar pragmatics subsystems term monotonic nonmonotonic inferences discuss independently motivate default preferences interact interpretation intersentential pronominal anaphora framework general discourse process model integrate grammar pragmatics subsystems propose fine structure preferential interpretation pragmatics term defeasible rule interactions pronoun interpretation preferences serve empirical grind draw survey data specifically obtain present purpose
strictest interpretation theories center intonational mean fail predict existence pitch accent pronominals yet occur felicitously speak discourse explain emphasize dual function serve pitch accent markers propositional semantic pragmatic attentional salience distinction underlie proposals attentional consequences pitch accent apply pronominals particular pitch accent may weaken reinforce cospecifier status center attention contrastively stress pronominal may force shift even contraindicate textual feature
intelligent voice prosthesis communication tool reconstruct mean ill structure sequence icons symbols express mean sentence natural language french develop use people express orally natural language able comply grammatical rule natural language describe available corpora iconic communication children cerebral palsy lead us implement simple relevant semantic description symbol lexicon show unification base bottom semantic analysis allow system uncover mean user utterances compute proper dependencies symbols result analysis pass lexicalization module choose right word natural language use build linguistic semantic network semantic network generate french sentence via hierarchization tree use lexicalize tree adjoin grammar finally describe modular customizable interface develop system
article depth review eugene charniak book statistical language learn review evaluate appropriateness book introductory text statistical language learn variety audiences also include extensive bibliography article paper might use supplement book learn teach statistical language model
paper present approach allow efficient integration speech recognition language understand use tomita generalize lr parse algorithm purpose glrp algorithm revise agenda mechanism use control flow computation parse process new approach use integrate speech recognition speech understand incrementally beam search method considerations implement test ten word lattices
recent work consider corpus base statistical approach problem prepositional phrase attachment ambiguity typically ambiguous verb phrase form v np1 p np2 resolve model consider value four head word v n1 p n2 paper show problem analogous n gram language model speech recognition one common methods language model back estimate applicable result wall street journal data eight hundred and forty-five accuracy obtain use method surprise result importance low count events ignore events occur less five time train data reduce performance eight hundred and sixteen
study centre generation instructions household appliances show knowledge device together knowledge environment use reason instructions information communicate instructions plan version knowledge artifact environment present latter call plan knowledge form axioms situation calculus plan knowledge formally characterize behaviour artifact use produce basic plan action device user take accomplish give goal explain procedural warn instructions generate basic plan order partially justify instruction generation automate formal device design specification assume plan knowledge derivable device world knowledge
discovery system detect correspondences data describe base familiar induction methods j mill give set observations system induce causally relate facts observations application empirical linguistic discovery describe
paper present incremental method tag proper name german newspaper texts tag perform analysis syntactic textual contexts proper name together morphological analysis proper name select process supply new contexts use find new proper name procedure apply small german corpus fifty thousand word correctly disambiguate sixty-five capitalize word improve apply large corpus
paper describe computational framework grammar architecture different linguistic domains morphology syntax semantics treat separate components compositional domains word phrase formation model uniform process contribute derivation semantic form morpheme well lexeme lexical representation form semantic content tactical constraints phonological realization motivation work handle morphology syntax interaction eg valency change causatives subcategorization impose case mark affix incremental way model base combinatory categorial grammars
paper argue contrary prevail opinion linguistics philosophy literature sortal approach aspectual composition indeed explanatory support view develop synthesis compete proposals hinrichs krifka jackendoff take jackendoff cross cut sortal distinctions point departure show account well suit computational purpose also sketch implement calculus eventualities yield many desire inferences detail model theoretic semantics implementation find white one thousand, nine hundred and ninety-four
although unification use implement weak form beta reduction several linguistic phenomena better handle use form lambda calculus paper present higher order feature description calculus base type lambda calculus show techniques use clg resolve complex feature constraints efficiently extend cclg simple formalism base categorial grammars design test practical feasibility calculus
paper present unification base lexical platform design highly inflect languages like roman ones formalism propose encode lemma base lexical source well suit linguistic generalizations source automatically generate allomorph index dictionary adequate efficient process set software tool implement around formalism access libraries morphological processors etc
previous approach robustness natural language process usually treat deviant input relax grammatical constraints whenever successful analysis provide normal mean schema imply error detection always come prior error handle behaviour hardly compete human model many erroneous situations treat without even notice paper analyse necessary precondition achieve higher degree robustness natural language process suggest quite different approach base procedure structural disambiguation offer possibility cope robustness issue natural way eventually might suit accommodate quite different aspects robust behaviour within single framework
model full treatment spanish inflection verbs nouns adjectives present model base feature unification rely upon lexicon allomorphs stem morphemes word form build concatenation allomorphs mean special contextual feature make use standard definite clause grammars dcg include prolog implementations instead typical finite state approach allow us take advantage declarativity bidirectionality logic program nlp salient feature approach simplicity really straightforward rule lexical components develop simple model complex phenomena declarativity bidirectionality consistency completeness model discuss correct word form analyse generate even alternative ones gap paradigms preserve prolog implementation develop analysis generation spanish word form consist six dcg rule lexicalist approach ie information dictionary although quite efficient current implementation could improve analysis use non logical feature prolog especially word segmentation dictionary access
paper discuss question whether phrasal comparatives give direct interpretation require analysis elliptic constructions answer yes adequate analysis wide read attributive wra comparatives seem case ellipsis direct asymmetric analysis fit data narrow scope attributive comparatives question whether syntactic semantic process provide miss linguistic material complement wra comparatives also give complex answer linguistic context access combine reconstruction operation mechanism anaphoric reference analysis make straightforward syntactic assumptions part make possible use generalize functional application semantic operation allow us model semantic composition flexible way
morphological systems natural languages replete examples devices use multiple purpose one type morphological process example suffixation noun case verb tense two identical morphemes example suffix english noun plural possessive sort similarity would expect convey advantage language learners form transfer one morphological category another connectionist model morphology acquisition fault suppose inability represent phonological similarity across morphological categories hence facilitate transfer paper describe connectionist model acquisition morphology show exhibit transfer type model treat morphology acquisition problem one learn map form onto mean vice versa network learn mappings make phonological generalizations embed connection weight since weight share different morphological categories transfer enable set experiment artificial stimuli network train first one morphological task eg tense second eg number show context suffixation prefixation template rule second task facilitate second category either make use form general process type eg prefixation first
method give invert logic grammar display point view logical form rather word string lr compile techniques use allow recursive descent generation algorithm perform functor merge much way lr parser perform prefix merge improvement semantic head drive generator result much smaller search space amount semantic lookahead vary appropriate tradeoff point table size result nondeterminism find automatically
turkish possibly many languages verbs often convey several mean totally unrelated use subject object oblique object adverbial adjuncts certain lexical morphological semantic feature co occurrence restrictions addition usual sense variations due selectional restrictions verbal arguments case mean convey case frame idiomatic compositional subtle constraints paper present approach build constraint base case frame lexicon use natural language process turkish whose prototype implement tfs system develop univ stuttgart number observations make turkish indicate need something beyond traditional transitive intransitive distinction utilize framework verb valence consider obligatory co existence arbitrary subset possible arguments along obligatory exclusion certain others relative verb sense additional morphological lexical semantic constraints syntactic constituents organize five tier constraint hierarchy utilize map give syntactic structure case fraame specific verb sense
write specifications computer program easy since one take account disparate conceptual worlds application domain software development bridge conceptual gap propose control natural language declarative application specific specification language control natural language subset natural language accurately efficiently process computer expressive enough allow natural usage non specialists specifications control natural language automatically translate prolog clauses hence become formal executable translation use definite clause grammar dcg enhance feature structure inter text reference specification eg anaphora resolve help discourse representation theory drt generate prolog clauses add knowledge base implement prototypical specification system successfully process specification simple automate teller machine
consider problem learn certain type lexical semantic knowledge express binary relation word call sub categorization verbs verb noun relation compound noun phrase relation noun noun relation specifically view problem line learn problem sense littlestone learn model learner goal minimize total number prediction mistake computational learn theory literature goldman rivest schapire subsequently goldman warmuth consider line learn problem binary relations x zero one one domain set x partition relatively small number type namely cluster consist behaviorally indistinguishable members x paper extend model suppose set x partition small number type propose host prediction algorithms two dimensional extensions goldman warmuth weight majority type algorithm propose original model apply algorithms learn problem compound noun phrase relation noun relate another case form noun phrase together experimental result show algorithms perform goldman warmuth algorithm also theoretically analyze performance one algorithms form upper bind worst case number prediction mistake make
address problem automatically acquire case frame pattern large corpus data particular view problem problem estimate conditional distribution partition word propose new generalization method base mdl minimum description length principle order assist efficiency method make use exist thesaurus restrict attention partition present cut thesaurus tree thus reduce generalization problem estimate tree cut model thesaurus give efficient algorithm provably obtain optimal tree cut model give frequency data sense mdl use case frame pattern obtain use method resolve pp attachment ambiguityour experimental result indicate method improve upon least effective exist methods
first define unification grammar formalism call tree homomorphic feature structure grammar base lexical functional grammar lfg strong restriction syntax equations show grammar formalism define full abstract family languages capable describe cross serial dependencies type find swiss german
index languages interest computational linguistics least class languages chomsky hierarchy show adequate describe string set natural language sentence define class unification grammars exactly describe class index languages
paper address problem represent ambiguities way allow monotonic disambiguation direct deductive computation paper focus extension formalism underspecified drss ambiguities introduce plural nps deal collective distributive distinction also generic cumulative read addition provide systematic account underspecified treatment plural pronoun resolution
paper discuss notion bridge discourse representation theory tool account discourse referents establish implicitly lexical semantics referents use ideas generative lexicon theory introduce antecedents anaphoric expressions link proper antecedent need accommodate connection network discourse referents already establish
discuss extension standard logical rule functional application abstraction categorial grammar cg order deal specific case polysemy borrow generative lexicon theory propose mechanism coercion next rich nominal lexical semantic structure call qualia structure previous paper introduce coercion framework sign base categorial grammar investigate impact traditional fregean compositionality paper elaborate idea mostly work towards introduction new semantic dimension current versions sign base categorial grammar two representations derive prosodic one form logical one model introduce also detaled representation lexical semantics extra knowledge serve account linguistic phenomena like metonymy
paper present robust parse algorithm base link grammar formalism parse natural languages algorithm natural extension original dynamic program recognition algorithm recursively count number linkages two word input sentence modify algorithm use notion null link order allow connection pair adjacent word regardless dictionary definitions algorithm proceed make three dynamic program pass first pass input parse use original algorithm enforce constraints link ensure grammaticality second pass total cost substring word compute cost determine number null link necessary parse substring final pass count total number parse minimal cost original prune techniques natural counterparts robust algorithm use together memoization techniques enable algorithm run efficiently cubic worst case complexity implement ideas test parse switchboard corpus conversational english corpus comprise approximately three million word text correspond one hundred and fifty hours transcribe speech collect telephone conversations restrict seventy different topics although small fraction sentence corpus grammatical standard criteria robust link grammar parser able extract relevant structure large portion sentence present result experiment use system include analyse select random sentence corpus
develop formal grammatical system call link grammar show english grammar encode system give algorithms efficiently parse link grammar although expressive power link grammars equivalent context free grammars encode natural language grammars appear much easier new system write program general link parse write link grammar english language performance preliminary system breadth english phenomena capture computational resources use indicate approach may practical use well linguistic significance program write c may obtain internet
paper address important problem example base machine translation ebmt namely measure similarity sentence fragment set store examples new method propose measure similarity accord surface structure content second contribution use cluster make retrieval best match example database efficient result large number test case celex database present
paper present prototype lexicalist machine translation system base call shake bake approach whitelock one thousand, nine hundred and ninety-two consist analysis component dynamic bilingual lexicon generation component show apply range mt problems multi lexeme translations handle bi lexical rule map bilingual lexical sign new bilingual lexical sign argue much translation handle equate translationally equivalent list lexical sign either directly bilingual lexicon derive bi lexical rule lexical semantic information organize qualia structure pustejovsky one thousand, nine hundred and ninety-one use mechanism restrict domain rule
propose theory dynamical systems offer appropriate tool model many phonological aspects speech production perception dynamic account speech rhythm show useful description japanese mora time english time phrase repetition task orientation contrast fundamentally familiar symbolic approach phonology time model sequentially array symbols propose adaptive oscillator offer useful model perceptual entrainment lock temporal pattern speech production help explain speech often perceive regular experimental measurements seem justify dynamic model deal real time also help us understand languages differ temporal detail contribute foreign accent example fact languages differ greatly temporal detail suggest effect mere motor universals dynamical model intrinsic components phonological characterization language
explore consequences layer lambek proof system arbitrary constraint logic simple model theoretic semantics hybrid language provide particularly simple combination lambek proof system base logic complete furthermore proof system underlie base logic assume black box essential reason need perform black box entailment check assume feature logic base logic entailment check amount subsumption test well know quasi linear time decidable problem
present system investigation computational properties categorial grammar parse base label analytic tableaux theorem prover proof method allow us take modular approach basic grammar keep constant range categorial calculi capture assign different properties label algebra theorem prove strategy particularly well suit treatment categorial grammar allow us distribute computational cost algorithm deal grammatical type algebraic checker constrain derivation
currently two philosophies build grammars parsers statistically induce grammars wide coverage grammars one way combine strengths approach wide coverage grammar heuristic component domain independent whose contribution tune particular domains paper discuss three stage approach disambiguation context lexicalize grammar use variety domain independent heuristic techniques present train algorithm use hand bracket treebank parse set weight heuristics compare performance grammar performance ibm statistical grammar use untrained train weight heuristics
agent possess knowledge need perform action may privately plan obtain require information may involve another agent plan process engage dialogue paper show requirements knowledge precondition use account information seek subdialogues discourse first present axiomatization knowledge precondition sharedplan model collaborative activity grosz kraus one thousand, nine hundred and ninety-three provide analysis information seek subdialogues within general framework discourse process framework sharedplans relationships among use model intentional component grosz sidner one thousand, nine hundred and eighty-six theory discourse structure
consider problem multinomial estimation give alphabet k distinct symbols tell th symbol occur exactly ni time past basis information alone must estimate conditional probability next symbol report present new solution fundamental problem statistics demonstrate solution outperform standard approach theory practice
paper explore number issue analysis data requirements statistical nlp systems preliminary framework view systems propose sample exist work compare within framework first step toward theory data requirements make establish result relevant bound expect error rate class simplify statistical language learners function volume train data
paper address practical concern predict much train data sufficient statistical language learn system first briefly review earlier result show combine bind expect accuracy mode base learner function volume train data develop accurate estimate expect accuracy function assumption input uniformly distribute since estimate expensive compute also give close cheaply computable approximation finally report series simulations explore effect input uniformly distribute although result base simplistic assumptions tentative step toward useful theory data requirements sll systems
maximum entropy method recently successfully introduce variety natural language applications applications however power maximum entropy method achieve cost considerable increase computational requirements paper present technique closely relate classical cluster expansion statistical mechanics reduce computational demand necessary calculate conditional maximum entropy language model
academic discipline often divide hard soft sciences may understand donor discipline produce concepts borrow discipline borrower discipline import originate term use describe concepts use distinguish hard soft donor borrower well individual discipline specific sublanguages use term frequencies birth growth death migration concepts associate term examine
hybrid methodology resolution text level ellipsis present paper incorporate conceptual proximity criteria apply ontologically well engineer domain knowledge base approach center base functional topic comment pattern state text grammatical predicate ellipsis turn procedural aspects evaluation within framework actor base implementation lexically distribute parser
relaxation label optimization technique use many field solve constraint satisfaction problems algorithm find combination value set variables satisfy maximum possible degree set give constraints paper describe experiment perform apply pos tag result obtain also ponder possibility apply word sense disambiguation
chinese text process systems use double byte cod almost exist sanskrit base indian languages use single byte cod text process observation chinese information process technique already achieve great technical development east west contrastindian languages process computer less word process purpose paper mainly emphasize method process indian languages computational linguistic point view overall design method illustrate paperthis method concentrate maximum resource utilization compatibility ultimate goal multiplatform multilingual system keywords text procrssing multilingual text process chinese language process indian language process character cod
paper present method resolution lexical ambiguity automatic evaluation brown corpus method rely use wide coverage noun taxonomy wordnet notion conceptual distance among concepts capture conceptual density formula develop purpose fully automatic method require hand cod lexical entries hand tag text kind train process result experiment automatically evaluate semcor sense tag version brown corpus
paper explore acquisition conceptual knowledge bilingual dictionaries french english spanish english english spanish use pre exist broad coverage lexical knowledge base lkb wordnet bilingual nominal entries disambiguate agains wordnet therefore link bilingual dictionaries wordnet yield multilingual lkb mlkb result mlkb structure wordnet nod attach additionally disambiguate vocabulary languages two different complementary approach explore one approach entry dictionary take turn exploit information entry inferential capability disambiguate translation give semantic density wordnet approach bilingual dictionary merge wordnet exploit mainly synonymy relations approach use different dictionary approach attain high level precision show disambiguate bilingual nominal entries therefore link bilingual dictionaries wordnet feasible task
describe approach robust domain independent syntactic parse unrestricted naturally occur english input technique involve parse sequence part speech punctuation label use unification base grammar couple probabilistic lr parser describe coverage several corpora use grammar report result parse experiment use probabilities derive bracket train data report first substantial experiment assess contribution punctuation derive accurate syntactic analysis parse identical texts without naturally occur punctuation mark
main aim translation accurate transfer mean result grammatically lexically correct also communicatively adequate paper stress need discourse analysis aim preserve communicative mean english polish machine translation unlike english positional language word order grammatically determine polish display strong tendency order constituents accord degree salience informationally salient elements place towards end clause regardless grammatical function center theory develop track give information units english theory functional sentence perspective predict informativeness subsequent constituents provide theoretical background work notion center extend accommodate pronominalisation exact reiteration also definiteness center point construct center information additionally grade applicable primary constituents give utterance information use order post transfer constituents correctly rely statistical regularities syntactic clue
current definitions notions lexical density semantic weight base division word close open class intuition paper develop computationally tractable definition semantic weight concentrate mean word semantically light definition involve look frequency word particular syntactic constructions indicative lightness verbs make take function support verbs often consider semantically light test definition carry experiment base grefenstette teufel one thousand, nine hundred and ninety-five automatically identify light instance word corpus do incorporate frequency relate definition semantic weight statistical approach similar grefenstette teufel result show plausible definition semantic lightness verbs possibly extend define semantic lightness class word
recently several type japanese english machine translation systems develop require initial process rewrite original text easily translatable japanese therefore systems unsuitable translate information need speedily disseminate overcome limitation multi level translation method base constructive process theory propose paper describe benefit use method japanese english machine translation system alt j e comparison conventional compositional methods multi level translation method emphasize importance mean contain expression structure whole show capable translate typical write japanese base mean text context comparative ease hopeful carry useful machine translation manual pre edit
paper present heuristic method use information japanese text along knowledge english countability number store transfer dictionaries determine countability number english noun phrase incorporate method machine translation system alt j e help raise percentage noun phrase generate correct use article number sixty-five seventy-three
describe algorithm generation phase shake bake machine translation system since problem np complete unlikely algorithm efficient case case test offer improvement whitelock previously publish algorithm work carry author employ sharp laboratories europe ltd
paper show agents choice communicative action design mitigate effect resource limit context particular feature collaborative plan task first motivate number hypotheses effective language behavior base statistical analysis corpus natural collaborative plan dialogues hypotheses test dialogue testbed whose design motivate corpus analysis experiment testbed examine interaction one agents resource limit attentional capacity inferential capacity two agents choice communication three feature communicative task affect task difficulty inferential complexity degree belief coordination require tolerance errors result show good algorithms communication must define relative agents resource limit feature task algorithms inefficient inferentially simple low coordination fault tolerant task effective task require coordination complex inferences fault intolerant result provide explanation occurrence utterances human dialogues prima facie appear inefficient provide basis design effective algorithms communicative choice resource limit agents
expectations correlation cue phrase duration unfilled pause structure speak discourse frame light grosz sidner theory discourse test directions give dialogue result suggest cue phrase discourse structure task may align show correlation pause length modifications speakers make discourse structure
speech natural language systems develop english indo european languages neglect morphological process integrate speech natural language word level agglutinative languages korean japanese morphological process play major role language process since languages complex morphological phenomena relatively simple syntactic functionality obviously degenerate morphological process limit usable vocabulary size system word level dictionary result exponential explosion number dictionary entries agglutinative languages need sub word level integration leave room general morphological process paper develop phoneme level integration model speech linguistic process general morphological analysis agglutinative languages efficient parse scheme integration korean model lexically base categorial grammar formalism unordered argument suppress category extensions chart drive connectionist parse method introduce
word group useful language process task increasingly available thesauri appear line distributional word cluster techniques improve however many task one interest relationships among word sense word paper present method automatic sense disambiguation nouns appear within set relate nouns kind data one find line thesauri output distributional cluster algorithms disambiguation perform respect wordnet sense fairly fine grain however method also permit assignment higher level wordnet categories rather sense label method illustrate primarily example though result rigorous evaluation also present
paper present new measure semantic similarity taxonomy base notion information content experimental evaluation suggest measure perform encouragingly well correlation seventy-nine benchmark set human similarity judgments upper bind ninety human subject perform task significantly better traditional edge count approach sixty-six
paper demonstrate challenge problem arabic break plural diminutive handle multi tape two level model extension two level morphology
present unsupervised learn algorithm acquire natural language lexicon raw speech algorithm base optimal encode symbol sequence mdl framework use hierarchical representation language overcome many problems stymie previous grammar induction procedures forward map symbol sequence speech stream model use feature base articulatory gesture present result acquisition lexicons language model raw speech text phonetic transcripts demonstrate algorithm compare favorably report result respect segmentation performance statistical efficiency
squib examine role limit attention theory discourse structure propose model attentional state relate current hierarchical theories discourse structure empirical evidence human discourse process capabilities first present examples predict grosz sidner stack model attentional state consider alternative model attentional state cache model account examples make particular process predictions finally suggest number ways future research could distinguish predictions cache model stack model
give present state work natural language process address argue first advance science applications require revival concern language broadly speak world second attack summarise task make ever important growth electronic text resources require understand role large scale discourse structure mark important text content good way forward
paper present approach prolog style term encode type feature structure type feature structure encode constrain appropriateness condition carpenter ale system unlike ale impose independently motivate close world assumption assumption allow us apply term encode case problematic previous approach particular previous approach rule multiple inheritance specification feature value declarations subtypes present approach spececial case handle well though increase complexity grammars without multiple inheritance specification feature value encode present reduce previous approach
phys rev letter seven hundred and thirty-two five december ninety-four mantegna et al conclude basis zipf rank frequency data noncoding dna sequence regions like natural languages cod regions argue contrary empirical fit zipf law use criterion similarity natural languages although dna presumably organize system sign mandelbrot one thousand, nine hundred and sixty-one sense observation statistical feature sort present mantegna et al paper would light similarity dna grammar natural language grammars observation exact zipf like behavior distinguish underlie process toss side die finite state branch process