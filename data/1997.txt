interpretation natural language inherently context sensitive word natural language ambiguous mean heavily dependent linguistic context use study lexical semantics separate notion context paper take contextual approach lexical semantics study linguistic context lexical atoms sticky phrase hot dog since lexical atoms may occur frequently unrestricted natural language text recognize crucial understand naturally occur text paper propose several heuristic approach exploit linguistic context identify lexical atoms arbitrary natural language text
paper present overview speak language translator slt system hybrid language process architecture focus way rule base statistical methods combine achieve robust efficient performance within linguistically motivate framework general argue rule desirable order encode domain independent linguistic constraints achieve high quality grammatical output corpus derive statistics need systems efficient robust hybrid architectures superior point view portability architectures make use one type information address topics multi engine strategies robust translation robust bottom parse use prune grammar specialization rational development linguistic rule set use balance domain corpora efficient supervise train interactive disambiguation work describe fully implement current version slt two system
expert consultation dialogues inevitable agent time insufficient information determine whether accept reject proposal agent result need agent initiate information share subdialogue form set share beliefs within agents effectively evaluate proposal paper present computational strategy initiate information share subdialogues resolve system uncertainty regard acceptance user proposal model determine information share pursue select focus information share among multiple uncertain beliefs choose effective information share strategy utilize newly obtain information evaluate user proposal furthermore model capable handle embed information share subdialogues
paper describe efficient robust implementation bi directional head drive parser constraint base grammars parser develop ovis system dutch speak dialogue system information public transport obtain telephone review motivation head drive parse strategies head corner parse particular non deterministic version head corner parser present memoization technique apply obtain fast parser goal weaken technique introduce greatly improve average case efficiency term speed space requirements argue favor memoization strategy goal weaken comparison ordinary chart parsers strategy apply selectively therefore enormously reduce space requirements parser practical loss time efficiency observe contrary experiment describe head corner leave corner parsers implement selective memoization goal weaken outperform standard chart parsers experiment include grammar ovis system alvey nl tool grammar head corner parse mix bottom top process certain approach towards robust parse require purely bottom process therefore seem head corner parse unsuitable robust parse techniques however show underspecification arise naturally logic program environment use head corner parser allow robust parse techniques particular robust parse model describe implement ovis
paper describe call screen approach learn robust process spontaneously speak language screen approach flat analysis use shallow sequence category representations analyze utterance various syntactic semantic dialog level rather use deeply structure symbolic analysis use flat connectionist analysis screen approach aim support speech language process use one data drive learn two robustness connectionist network order test approach develop screen system base new robust learn flat analysis paper focus detail description screen architecture flat syntactic semantic analysis interaction speech recognizer detail evaluation analysis robustness influence noisy incomplete input main result paper flat representations allow robust process spontaneous speak language deeply structure representations particular show fault tolerance learn capability connectionist network support flat analysis provide robust speak language process within overall hybrid symbolic connectionist framework
describe novel technique implement system construct subcategorization dictionary textual corpora dictionary entry encode relative frequency occurrence comprehensive set subcategorization class english initial experiment sample fourteen verbs exhibit multiple complementation pattern demonstrate technique achieve accuracy comparable previous approach limit highly restrict set subcategorization class also demonstrate subcategorization dictionary build system improve accuracy parser appreciable amount
thesis address automatic lexical error recovery tokenization corrupt text input propose technique automatically correct misspell segmentation errors real word errors unify framework use model language production model type behavior make tokenization part recovery process type process model noisy channel hide markov model use model channel characteristics weak statistical language model use predict sentence likely transmit channel components hold together token pass framework provide desire tight couple orthographic pattern match linguistic expectation system ctr connect text recognition test two corpora derive two different applications natural language dialogue system transcription type scenario experiment show ctr automatically correct considerable portion errors test set without introduce much noise segmentation error correction rate virtually faultless
describe annotation scheme tool develop create linguistically annotate corpora non configurational languages since requirements formalism differ posit configurational languages several feature add influence architecture scheme result scheme reflect stratificational notion language make minimal assumptions interrelation particular representational strata
classify review current approach software infrastructure research development delivery nlp systems task motivate discussion current trend field nlp language engineer describe system call gate general architecture text engineer provide software infrastructure top heterogeneous nlp process modules may evaluate refine individually may combine larger application systems gate aim support researchers developers work component technologies eg parse tag morphological analysis work develop end user applications eg information extraction text summarisation document generation machine translation second language learn gate promote reuse component technology permit specialisation collaboration large scale project allow comparison evaluation alternative technologies first release gate available see http wwwdcsshefacuk research group nlp gate
technical memo describe information extraction point view potential user technology knowledge language process assume information extraction process take unseen texts input produce fix format unambiguous data output data may use directly display users may store database spreadsheet later analysis may use index purpose information retrieval applications see also http wwwdcsshefacuk hamish
appointment schedule problem face daily many individuals organizations cooperate agent systems develop partially automate task order extend circle participants far possible advocate use natural language transmit e mail describe cosma fully implement german language server exist appointment schedule agent systems cosma cope multiple dialogues parallel account differences dialogue behaviour human machine agents nl coverage sublanguage achieve corpus base grammar development use message extraction techniques
statistical model word sense disambiguation often base small number contextual feature model assume characterize interactions among set feature model selection present alternative approach sequential search possible model conduct order find model best characterize interactions among feature paper expand exist model selection methodology present first comparative study model selection search strategies evaluation criteria apply problem build probabilistic classifiers word sense disambiguation
information retrieval ir important application area natural language process nlp one encounter genuine challenge process large quantities unrestricted natural language text much effort make apply nlp techniques ir nlp techniques evaluate document collection larger several megabytes many nlp techniques simply efficient enough robust enough handle large amount text paper propose new probabilistic model noun phrase parse report application parse technique enhance document index effectiveness use syntactic phrase provide parser supplement single word index evaluate two hundred and fifty megabytes document collection experiment result show supplement single word syntactic phrase index consistently significantly improve retrieval performance
paper propose efficient example selection method example base word sense disambiguation systems construct practical size database considerable overhead manual sense disambiguation require method characterize reliance notion train utility degree example informative future example selection use train system system progressively collect examples select greatest utility paper report effectivity method experiment one thousand sentence compare experiment random example selection method reduce overhead without degeneration performance system
information technology much offer linguistics opportunities offer large scale data analysis stimulus develop formal computational model chance use language systems automatic natural language process paper discuss possibilities detail examine actual work do evident far primarily research within new field computational linguistics largely motivate demand interest practical process systems information technology rather little influence linguistics large different reason good ones information technology deserve attention linguists
natural language process systems parsers generators taggers need access lexicon word language thesis present lexicon architecture natural language process turkish give query form consist surface form feature act restrictions lexicon produce feature structure contain morphosyntactic syntactic semantic information possible interpretations surface form satisfy restrictions lexicon base contemporary approach like feature base representation inheritance unification make use two information source morphological processor lexical database contain open close class word turkish system implement sicstus prolog standalone module use natural language process applications
important part build natural language generation nlg system knowledge acquisition decide specific schemas plan grammar rule forth use nlg system discuss experiment perform ka content selection rule context build nlg system generate health relate material experiment suggest useful supplement corpus analysis ka techniques develop build expert systems structure group discussions think aloud protocols also raise point ka issue may influence architectural design issue particular decision whether plan approach use content selection suspect case ka may easier constructive expert system techniques production rule case base reason use determine content generate text
paper describe method automatic creation knowledge source text generation use information extraction internet present prototype system call profile use client server architecture extract noun phrase descriptions entities people place organizations system serve two purpose information extraction tool allow users search textual descriptions entities utility generate functional descriptions fd use functional unification base generation system present evaluation approach applications natural language generation summarization
paper introduce linguistic style improvisation theory set algorithms improvisation speak utterances artificial agents applications interactive story dialogue systems argue linguistic style key aspect character show speech act representations common ai provide abstract representations computer character improvise show mechanisms propose introduce possibility socially orient agents meet requirements lifelike character believable satisfy particular criteria improvisation propose hay roth
human annotation natural language facilitate standardize evaluation natural language process systems support automate feature extraction document consist instructions annotate temporal information schedule dialogs dialogs participants schedule meet one another task orient dialogs would arise many useful applications instance automate information providers automate phone operators explicit instructions support good inter rater reliability serve documentation class annotate
paper method domain adaptation cluster language model develop base previously develop cluster algorithm modify optimisation criterion result show slightly superior previously publish fillup method use adapt standard n gram model however improvement methods give compare model build scratch adaptation data quite small less eleven relative improvement word error rate suggest methods still unsatisfactory practical point view
knowledge structure call concept cluster knowledge graph cckgs introduce along process construction machine readable dictionary cckgs contain multiple concepts interrelate multiple semantic relations together form semantic cluster represent conceptual graph knowledge acquisition perform children first dictionary collection conceptual cluster together form basis lexical knowledge base cckg contain limit number highly connect word give useful information particular domain situation
dysphasic subject complete linguistic abilities produce weakly structure topicalize language offer artificial symbolic languages help communicate way adapt linguistic abilities structural analysis corpus utterances children cerebral palsy define semantic lexicon symbolic language use basis semantic analysis process able retrieve interpretation utterances semantic analyser currently use application design convert iconic languages natural language might find use field language rehabilitation
present dialogue module speech speech translation system verbmobil follow approach solution dialogue process mediate scenario depend single constrain process tool combination several simple efficient robust components show solution dialogue process work apply real data give examples module contribute correct translation german english
investigate utility algorithm translation lexicon acquisition sable use previously large corpus acquire general translation lexicons algorithm apply much smaller corpus produce candidates domain specific translation lexicons
describe prototype system multilingual gisting web page present evaluation methodology base notion gisting decision support evaluation paradigm straightforward rigorous permit fair comparison alternative approach easily generalize evaluation situations user face decision make basis information restrict alternative form
present trainable model identify sentence boundaries raw text give corpus annotate sentence boundaries model learn classify occurrence either valid invalid sentence boundary train procedure require hand craft rule lexica part speech tag domain specific information model therefore train easily genre english trainable roman alphabet language performance comparable better performance similar systems emphasize simplicity retrain new domains
challenge translate name technical term across languages different alphabets sound inventory items commonly transliterate ie replace approximate phonetic equivalents example computer english come konpyuutaa japanese translate items japanese back english even challenge practical interest transliterate items make bulk text phrase find bilingual dictionaries describe evaluate method perform backwards transliterations machine method use generative model incorporate several distinct stag transliteration process
paper present paradise paradigm dialogue system evaluation general framework evaluate speak dialogue agents framework decouple task requirements agent dialogue behaviors support comparisons among dialogue strategies enable calculation performance subdialogues whole dialogues specify relative contribution various factor performance make possible compare agents perform different task normalize task complexity
paper argue need distinguish task dialogue initiatives present model track shift type initiatives dialogue interactions model predict initiative holders next dialogue turn base current initiative holders effect observe cue change evaluation across various corpora show use cue consistently improve accuracy system prediction task dialogue initiative holders two four eight thirteen percentage point respectively thus illustrate generality model
paper describe approach constraint base syntactic theories term finite tree automata solutions constraints express weak monadic second order mso logic represent tree automata recognize assignments make formulas true show allow efficient representation knowledge content constraints use practical tool grammatical theory verification achieve use intertranslatability formulas mso logic tree automata embed mso logic constraint logic program scheme usefulness approach discuss examples realm principles parameters base parse
paper present method combine set unsupervised algorithms accurately disambiguate word sense large completely untagged corpus although techniques word sense resolution present stand alone belief full fledge lexical ambiguity resolution combine several information source techniques set techniques apply combine way disambiguate genus term two machine readable dictionaries mrd enable us construct complete taxonomies spanish french test accuracy eighty overall ninety-five two way ambiguous genus term show taxonomy build limit structure dictionaries ldoce
understand speaker turn conversation one need segment intonational phrase clean speech repair might occur identify discourse markers paper argue problems must resolve together must resolve early process stream put forward statistical language model resolve problems pos tag use language model speech recognizer find account interactions task performance task improve pos tag perplexity
describe use energy function optimization shallow syntactic parse approach use linguistic rule corpus base statistics strengths linguistic statistical approach nlp combine single framework rule contextual constraints resolve syntactic ambiguities express alternative tag statistical language model consist corpus base n grams syntactic tag success hybrid syntactic disambiguator evaluate hold benchmark corpus also contributions linguistic statistical language model hybrid model estimate
paper discuss use ontologies natural language process classify various kinds ontologies employ nlp discuss various benefit problems design particular focus place experience gain use upper model linguistically motivate ontology originally design use penman text generation system proposals nlp ontology design criteria make
present constraint base morphological disambiguation system individual constraints vote match morphological parse disambiguation tokens sentence perform end select parse receive highest vote constraint application paradigm make outcome disambiguation independent rule sequence hence relieve rule developer worry potentially conflict rule sequence result disambiguate turkish indicate use five hundred constraint rule additional simple statistics attain recall ninety-five ninety-six precision ninety-four ninety-five one hundred and one parse per token system implement prolog currently investigate efficient implementation base finite state transducers
paper deal problem text generation plan approach make limit formally specifiable contact account grammar propose enhancement systemically base generation architecture german komet system aspects kunze theory semantic emphasis gain control concept selection generation choice fine grain grammatical variation
provide general account parallelism discourse apply special case resolve possible read instance vp ellipsis show several problematic examples account natural straightforward fashion generality approach make directly applicable variety type ellipsis reference
specify algorithm build hierarchy referential discourse segment local center data spatial extension nest discourse segment constrain reachability potential antecedents anaphoric expression beyond local level adjacent center pair thus center model scale level global referential structure discourse empirical evaluation algorithm supply
new account parameter set grammatical acquisition present term generalize categorial grammar embed default inheritance hierarchy provide natural partial order set parameters experiment show several experimentally effective learners define framework evolutionary simulations suggest learner default initial settings parameters emerge provide learn memory limit environment linguistic adaptation contain appropriate language
although sloppy interpretation usually account theories ellipsis often arise non elliptical contexts paper theory sloppy interpretation provide capture fact underlie idea sloppy interpretation result semantic constraint parallel structure theory show predict sloppy read deaccented paycheck sentence well relational event one anaphora show capture interaction sloppy strict ambiguity quantification bind
argue grammatical process viable alternative concept spot process speak input practical dialogue system discuss structure grammar properties parser method achieve robustness discuss test result suggest grammatical process allow fast accurate process speak input
although much say parallelism discourse formal computational theory parallelism structure still outstanding paper present theory give two parallel utterances predict parallel elements theory consist sort higher order abductive calculus show reconcile insights discourse theories parallelism higher order unification approach discourse semantics thereby provide natural framework capture effect parallelism discourse semantics
propose new method classify document categories simple method conduct hypothesis test word base distributions categories suffer data sparseness problem order address difficulty guthrie etal develop method use distributions base hard cluster word ie word assign single cluster word cluster treat uniformly method might however degrade classification result since distributions employ always precise enough represent differences categories propose use soft cluster word ie word assign several different cluster cluster characterize specific word probability distribution define document category finite mixture model linear combination probability distributions cluster thereby treat problem classify document conduct statistical hypothesis test finite mixture model order accomplish test employ algorithm help efficiently estimate parameters finite mixture model experimental result indicate method outperform method use distributions base hard cluster also method use word base distributions method base cosine similarity
constraint logic grammars provide powerful formalism express complex logical descriptions natural language phenomena exact term describe phenomena may however require form grade distinctions provide grammars recent approach weight constraint logic grammars attempt address issue add numerical calculation schemata deduction scheme underlie clp framework currently extralogical extensions relate model theoretic counterpart operational semantics clp ie come formal semantics aim paper present clear formal semantics weight constraint logic grammars abstract away specific interpretations weight nevertheless give insights parse problem weight grammars build formalization constraint logic grammars clp scheme hoehfeld smolka one thousand, nine hundred and eighty-eight formal semantics give quantitative version clp quantitative clp scheme also valuable clp task independent grammars
describe two methods relevant multi lingual machine translation systems use port linguistic data grammars lexicons transfer rule systems use process relate languages methods fully implement within speak language translator system use create versions system two new language pair use month expert effort
describe treebanker graphical tool supervise train involve domain customization disambiguation component speech language understand system treebanker present user need system expert range properties distinguish compete analyse utterance relatively easy judge allow train corpus complete far less time far less expertise would need analyse inspect directly become possible corpus twenty thousand sentence complexity atis corpus judge around three weeks work linguistically aware non expert
recently researchers work lfg framework propose algorithms take advantage implicit context free components unification grammar maxwell ninety-six paper clarify mathematical foundations techniques provide uniform framework formally study eliminate need special purpose runtime data structure record ambiguity paper posit identity ambiguous feature structure grammars state finitely ambiguous representations best see unification grammars certain type call interaction free grammars generate backtrack free way feature structure subsume ambiguous representation work extend line research billot lang eighty-nine lang ninety-four stress connection chart grammars chart see specialization reference grammar give input string show specialization grammar transform interaction free form practicality list individual solutions produce less time space
paper analyse relation use similarity memory base learn notion back smooth statistical language model show two approach closely relate argue feature weight methods memory base paradigm offer advantage automatically specify suitable domain specific hierarchy specific general condition information without need large number parameters report two applications approach pp attachment pos tag method achieve state art performance domains allow easy integration diverse information source rich lexical representations
paper defend notion semantic tag view disambiguation sense instead semantic tag first step interpretation process assign lexical item representation systematically relate sense semantic process step derive discourse dependent interpretations lead new type semantic lexicon corelex support underspecified semantic tag design base systematic polysemous class class base acquisition lexical knowledge specific domains
paper present first result comparative study aim test feasibility different inductive learn techniques perform automatic acquisition linguistic knowledge within natural language database interface interface architecture machine learn module replace elaborate semantic analysis component learn module learn correct map user input correspond database command base collection past input data use exist interface production plan control system evaluation compare result achieve different instance base model base learn algorithms
fastus system extract information natural language text entry database applications work essentially cascade nondeterministic finite state automaton five stag operation fastus stage one name fix form expressions recognize stage two basic noun group verb group prepositions particles recognize stage three certain complex noun group verb group construct pattern events interest identify stage four correspond event structure build stage five distinct event structure describe event identify merge use generate database entries decomposition language process enable system exactly right amount domain independent syntax domain dependent semantic pragmatic process apply right larger scale structure fastus efficient effective use successfully number applications
language model speech recognition tend concentrate solely recognize word speak paper redefine speech recognition problem goal find best sequence word syntactic role part speech utterance necessary first step towards tighten interaction speech recognition natural language understand
paper describe translation methodology adopt speak language translator slt address characteristics speech translation task context essential achieve easy customization new languages new domains discuss issue arise attempt evaluate speech translator present result evaluation carry slt several language pair
sense tag automatic assignment appropriate sense lexicon word text specialise instance general problem semantic tag category type discuss recent word sense disambiguation algorithms appropriate sense tag belief sense tag carry effectively combine several simple independent methods include design tagger prototype system implement correctly tag eighty-six polysemous word tokens small test set provide evidence hypothesis correct
paper present corpus base method assign grammatical subject object relations ambiguous german construct make use unsupervised learn procedure collect train test data back model make assignment decisions
present knowledge context base system parse translate natural language evaluate sentence wall street journal apply machine learn techniques system use parse action examples acquire supervision generate deterministic shift reduce parser form decision structure rely heavily context encode feature describe morphological syntactic semantic aspects give parse state
present novel ofn3 parse algorithm dependency grammar develop three contrast ways stochasticize propose lexical affinity model word struggle modify b sense tag model word fluctuate randomly selectional preferences c generative model speaker flesh word syntactic conceptual structure without regard implications hearer also give preliminary empirical result evaluate three model parse performance annotate wall street journal train text derive penn treebank result generative ie top model perform significantly better others equally well assign part speech tag
technical report appendix eisner one thousand, nine hundred and ninety-six give superior experimental result report talk version paper eisner one thousand, nine hundred and ninety-six train three probability model small set four thousand conjunction free dependency grammar parse derive wall street journal section penn treebank evaluate model hold test set use novel ofn3 parse algorithm present paper describe detail experiment repeat larger train set twenty-five thousand sentence report talk extensive train yield greatly improve performance nearly half sentence parse misattachments two thirds parse one misattachment model describe original write paper best score still obtain generative top model c however slightly better model also explore particular two variants comprehension bottom model b better attachment accuracy ninety unlike model c tag word accurately comparable trigram tagger differences statistically significant tag roughly know advance search error eliminate new model attain attachment accuracy ninety-three find parser collins one thousand, nine hundred and ninety-six combine highly train tagger also achieve ninety-three train test sentence similarities differences discuss
concern different approach automatic pos tag engcg two constraint base morphological tagger compare double blind test state art statistical tagger common disambiguation task use common tag set experiment show amount remain ambiguity error rate statistical tagger one order magnitude greater rule base one two relate issue prim effect compromise result disagreement human annotators also address
learn problems text process domain often map text space whose dimension measure feature text eg word three characteristic properties domain high dimensionality b learn concepts instance reside sparsely feature space c high variation number active feature instance work study three mistake drive learn algorithms typical task nature text categorization argue algorithms categorize document learn linear separator feature space properties make ideal domain show quantum leap performance achieve modify algorithms better address specific characteristics domain particular demonstrate one variation document length tolerate either normalize feature weight use negative weight two positive effect apply threshold range train three alternatives consider feature frequency four benefit discard feature train overall present algorithm variation littlestone winnow perform significantly better algorithm test task use similar feature set
consider use language model whose size accuracy intermediate different order n gram model two type model study particular aggregate markov model class base bigram model map word class probabilistic mix order markov model combine bigram model whose predictions condition different word type model train expectation maximization algorithms maximum likelihood estimation examine smooth procedures model interpose different order n grams find significantly reduce perplexity unseen word combinations
paper describe experimental comparison three unsupervised learn algorithms distinguish sense ambiguous word untagged text methods describe paper mcquitty similarity analysis ward minimum variance method algorithm assign instance ambiguous word know sense definition base solely value automatically identifiable feature text methods feature set find successful disambiguate nouns rather adjectives verbs overall accurate procedures mcquitty similarity analysis combination high dimensional feature set
library practical abstractions libpa provide efficient implementations conceptually simple abstractions c program language believe best library code conceptually simple easily understand application programmer parameterized type enjoy wide applicability least efficient straightforward special purpose implementation find software satisfy highest standards software design implementation test benchmarking current libpa release source code distribution consist modules portable memory management one dimensional array arbitrary type compact symbol table hash table arbitrary type trie module length delimit string arbitrary alphabets single precision float point number extend exponents logarithmic representations probability value use either fix float point number use libpa implement wide range statistical model continuous discrete domains time space efficiency libpa allow us build larger statistical model previously report investigate computationally intensive techniques previously possible find libpa indispensible research hope find useful
paper report recent improvements exemplar base learn approach word sense disambiguation achieve higher disambiguation accuracy use larger value k number nearest neighbor use determine class test example ten fold cross validation automatically determine best k obtain improve disambiguation accuracy large sense tag corpus first use citeng96 accuracy achieve improve exemplar base classifier comparable accuracy data set obtain naive bay algorithm report citemooney96 highest disambiguation accuracy among seven state art machine learn algorithms
study contextual linguistic factor constrain discourse phenomena reference come depend increasingly annotate language corpora prepare corpora important evaluate reliability annotation methods readily available report present method compute reliability coreference annotation first review method apply information retrieval metrics recall precision coreference annotation propose marc vilain collaborators show method make possible construct contingency table compute cohen kappa familiar reliability metric compare recall precision reliability data set also show recall precision misleadingly high kappa factor chance agreement among coders preferable measure develop annotate corpora pre exist target annotation exist
certain applications require output information extraction system probabilistic downstream system reliably fuse output possibly contradictory information source paper consider problem assign probability distribution alternative set coreference relationships among entity descriptions present result initial experiment several approach estimate distributions application use sri fastus information extraction system
semantic knowledge great asset natural language process systems usually hand cod application although semantic information available general purpose knowledge base wordnet cyc many applications require domain specific lexicons represent word categories particular topic paper present corpus base method use build semantic lexicons specific categories input system small set seed word category representative text corpus output rank list word associate category user review top rank word decide ones enter semantic lexicon experiment five categories users typically find sixty word per category ten fifteen minutes build core semantic lexicon
paper present statistical parser natural language obtain parse accuracy roughly eighty-seven precision eighty-six recall surpass best previously publish result wall st journal domain parser require little human intervention since information use make parse decisions specify concise simple manner combine fully automatic way maximum entropy framework observe run time parser test sentence linear respect sentence length furthermore parser return several score parse sentence paper show scheme pick best parse twenty highest score parse could yield dramatically higher accuracy ninety-three precision recall
paper present compilation procedure determine internal external indices sign unification base grammar use improve computational efficiency lexicalist chart generation procedure take input grammar set feature paths indicate position semantic indices sign calculate fix point set equations derive grammar result set independent constraints state indices sign bind sign within complete sentence base constraints two test formulate reduce search space generation
paper introduce new statistical approach partition text automatically coherent segment approach enlist short range long range language model help sniff likely sit topic change text aid search system consult set simple lexical hint learn associate presence boundaries inspection large corpus annotate data also propose new probabilistically motivate error metric use natural language process information retrieval communities intend supersede precision recall appraise segmentation algorithms qualitative assessment algorithm well evaluation use new metric demonstrate effectiveness approach two different domains wall street journal article tdt corpus collection newswire article broadcast news transcripts
main application name search name match database name paper discuss different application improve information retrieval name recognition investigate name recognition accuracy effect retrieval performance index search personal name differently non name term context rank retrieval main conclusions name recognition text effective name occur frequently enough variety domains include legal document news databases make recognition worthwhile retrieval performance improve use name search
paper introduce new methods base exponential families model correlations word text speech previous work assume effect word co occurrence statistics constant window several hundred word show influence nonstationary much smaller time scale empirical data draw english japanese text well conversational speech reveal attraction word decay exponentially stylistic syntactic contraints create repulsion word discourage close co occurrence show characteristics well describe simple mixture model base two stage exponential distributions train use algorithm result distance distributions incorporate penalize feature exponential language model
paper report experimental result compare mix initiative system initiative dialog strategy context personal voice email agent independently test effect dialog strategy user expertise users interact either system initiative mix initiative agent perform three successive task identical agents report performance comparisons across agent strategies well task evaluation utilize test paradise evaluation framework discuss performance function derivable experimental data
paper present result empirical investigation temporal reference resolution schedule dialogs algorithm adopt primarily linear recency base approach include model global focus fully automatic system develop evaluate unseen test data good result paper present result intercoder reliability study model temporal reference resolution support linear recency good coverage result system evaluate unseen test data detail analysis dialogs assess viability approach
although minimum distance parse mdp offer theoretically attractive solution problem extragrammaticality often computationally infeasible large scale practical applications paper present alternative approach labor distribute restrictive partial parser repair module though two stage approach grow popularity recent years efficiency do cost require hand cod repair heuristics contrast two stage approach require hand cod knowledge source dedicate repair thus make possible achieve similar run time advantage mdp without lose quality domain independence
paper first propose new statistical parse model generative model lexicalise context free grammar extend model include probabilistic treatment subcategorisation wh movement result wall street journal text show parser perform eight hundred and eighty-one eight hundred and seventy-five constituent precision recall average improvement twenty-three collins ninety-six
paper describe smes information extraction core system real world german text process basic design criterion system provide set basic powerful robust efficient natural language components generic linguistic knowledge source easily customize process different task flexible manner
colloquial english ce find television program typical conversations different text find technical manuals newspapers book phrase tend shorter less sophisticate paper look theoretical implementational issue involve translate ce present fully automatic large scale multilingual natural language process system translation ce input text find commercially transmit close caption television signal simple target sentence approach base whitelock shake bake machine translation paradigm rely heavily lexical resources system currently translate english spanish translation modules brazilian portuguese development
first step empirical work multilingual nlp construct map correspondence texts translations bf bitext map smooth injective map recognizer simr algorithm present generic pattern recognition algorithm particularly well suit map bitext correspondence simr faster significantly accurate algorithms literature algorithm robust enough use noisy texts result ocr input translations literal simr encapsulate language specific heuristics port language pair minimal effort
many multilingual nlp applications need translate word different languages afford computational expense induce apply full translation model applications design fast algorithm estimate partial translation model account translational equivalence word level model precision recall trade directly control via one threshold parameter feature make model suitable applications fully statistical model hide parameters easily condition information extrinsic model provide easy way integrate pre exist knowledge part speech dictionaries word order etc model link word tokens parallel texts well translation model literature unlike translation model automatically produce dictionary size translation lexicons ninety-nine accuracy
automatic segmentation text minimal content bear units unsolved problem even languages like english space word offer easy first approximation approximation good enough machine translation mt many word sequence translate word word paper present efficient automatic method discover sequence word translate unit method proceed compare pair statistical translation model induce parallel texts two languages discover hundreds non compositional compound iteration construct longer compound shorter ones objective evaluation simple machine translation task show method potential improve quality mt output method make assumptions data apply parallel data parallel texts word spell pronunciations
investigate problem determine compact underspecified semantical representation sentence may highly ambiguous due combinatorial explosion naive method build semantics different syntactic read independently prohibitive present method take input syntactic parse forest associate constraint base semantic construction rule directly build pack semantic structure algorithm fully implement run ofn4 logn sentence length grammar meet reasonable normality restrictions
propose system parse translate natural language learn examples use background knowledge parse model choose deterministic shift reduce type parser integrate part speech tag syntactic semantic process apply machine learn techniques system use parse action examples acquire supervision generate parser form decision structure generalization decision tree learn good parse translation decisions system rely heavily context encode currently two hundred and five feature describe morphological syntactical semantical aspects give parse state compare recent probabilistic systems train forty thousand sentence system rely background knowledge deeper analysis radically fewer examples currently two hundred and fifty-six sentence test parser lexically limit sentence wall street journal achieve accuracy rat eight hundred and ninety-eight label precision nine hundred and eighty-four part speech tag five hundred and sixty-three test sentence without cross bracket machine translations thirty-two wall street journal sentence german evaluate ten bilingual volunteer grade twenty-four ten best sixty worst scale grammatical correctness mean preservation
paper develop computational model paraphrase text modification carry reluctantly external constraints length readability otherwise ideal text modifications text necessary ensure conformance constraints problem analogous mathematical optimisation problem textual constraints describe set constraint equations requirement minimal change text express function minimise techniques domain use solve problem work do part computational paraphrase system use xtag system base paper present theoretical computational framework work within reluctant paraphrase paradigm three type textual constraints specify effect paraphrase text describe model incorporate mathematical optimisation techniques outline
text databases available users become larger heterogeneous genre become increasingly important computational linguistics complement topical structural principles classification propose theory genres bundle facets correlate various surface cue argue genre detection base surface cue successful detection base deeper structural properties
present algorithm automatically learn context constraints use statistical decision tree use acquire constraints flexible pos tagger tagger able use information degree n grams automatically learn context constraints linguistically motivate manually write constraints etc source kinds constraints unrestricted language model easily extend improve result tagger test evaluate wsj corpus
order enrich dynamic semantic theories pragmatic capacity combine dynamic nonmonotonic preferential logics modal logic set extend fragment van benthem de rijke dynamic modal logic additional preferential operators underlie static logic enable us define defeasible pragmatic entailments give piece discourse show set use dynamic logical analysis preferential resolutions ambiguous pronouns discourse
one necessary extensions center model mechanism handle pronouns intrasentential antecedents exist center model deal discourse consist simple sentence leave unclear delimit center update utterance units process complex utterances consist multiple clauses paper explore extent straightforward extension exist intersentential center model contribute effect motivate approach break complex sentence hierarchy center update units propose prefer interpretation pronoun local context arbitrarily deep give sentence structure approach substantiate examples naturally occur write discourse
paper describe conversion hide markov model sequential transducer closely approximate behavior stochastic model transformation especially advantageous part speech tag result transducer compose transducers encode correction rule frequent tag errors speed tag also improve describe methods implement successfully test six languages
tailor patient information tpi systems computer program produce personalise heath information material patients tpi systems grow interest natural language generation nlg community many tpi systems also develop medical community usually mail merge technology matter technology use experience show easy field tpi system even show effective clinical trials paper discuss difficulties field tpi systems base experience two tpi systems one generate asthma information booklets one generate smoke cessation letter
present unify account interpretation preferences stress unstressed pronouns discourse central intuition complementary preference hypothesis predict interpretation preference stress pronoun unstressed pronoun discourse position base preference must compute total pragmatics module include commonsense preferences focus constraint rooth theory semantic focus interpret salient subset domain local attentional state discourse context independently motivate purpose center theory
present efficient robust reference resolution algorithm end end state art information extraction system must work considerably impoverish syntactic analysis input sentence consider disadvantage basic setup collect filter order salience remarkably well third person pronouns need semantic discourse information improve treatments expression type
paper describe experience tool development test natural language grammars call gtu german grammatik testumgebumg grammar test environment gtu support four grammar formalisms window orient user interface additionally contain set german test sentence cover various syntactic phenomena well three type german lexicons attach grammar via integrate lexicon interface follow description experience gain use gtu tutor tool students experimental tool cl researchers derive feature necessary future grammar workbench
lexical database tool tailor phonological research describe database field include transcriptions gloss hyperlinks speech file database query express use html form permit regular expression search combination field regular expressions pass directly perl cgi program enable full flexibility perl extend regular expressions regular expression notation extend better support phonological search search minimal pair search result present form html latex table cell either number represent frequency designate subset field table four dimension elegant system specify fragment field use row column label tool offer several advantage traditional methods analysis support quantitative method phonological research ii give universal access set informants iii enable researchers hear original speech data without rely publish transcriptions iv make full power regular expression search available search result full multimedia document v enable early refutation false hypotheses shorten analysis hypothesis test loop life size application african tone language dschang use exemplification throughout paper database contain two thousand, two hundred record approximately fifteen field run pc laptop stand alone web server dschang hyperlexicon already use extensively phonological fieldwork analysis cameroon
note present method interpret tree adjoin languages natural third step hierarchy start regular context free languages central notion account higher order substitution whereas traditional presentations rule systems abstract language families emphasis first order substitution process auxiliary variables replace elements carrier proper algebra concatenations terminal auxiliary category symbols string case lift process level operations define elements carrier algebra view change emphasis provide adequate platform better understand operation adjunction put nutshell adjoin first order second order substitution operation
rogers one thousand, nine hundred and ninety-four owe insight monadic second order predicate logic multiple successors mso well suit many respect realistic formal base syntactic theorize however agreeable formal properties logic come cost mso equivalent class regular tree automata grammars thereby class context free languages paper outline one approach towards solution mso expressivity problem background algebraically refine chomsky hierarchy allow definition several class languages particular whole hierarchy cf cs via regular tree grammars unambiguously derivable alphabets vary complexity plus respective yield function show non context free string languages capture context free mean way approach generalize correspond structure ie non recognizable set structure homomorphism cod context freely since class languages cover fischer one thousand, nine hundred and sixty-eight oi family index languages include attest instance non context freeness natural language exist indirect sure completely general way formally describe natural languages use weak framework like mso
rapid explosion world wide web become increasingly possible easily acquire wide variety information flight schedule yellow page use car price current stock price entertainment event schedule account balance etc would useful speak dialogue interfaces information access task identify portability usability robustness extensibility four primary design objectives systems word objective develop pure portable usable robust extensible system two layer dialogue architecture speak dialogue systems present upper layer domain independent lower layer domain specific implement architecture mix initiative system access flight arrival departure information world wide web
paper address issue automate treebank construction show standard part speech tag techniques extend general problem structural annotation especially determine grammatical function syntactic categories annotation view interactive process manual automatic process alternate efficiency accuracy result present also discuss automation step
increase availability corpora annotate linguistic structure prompt question texts annotate phrase structure two different scheme extent annotations agree structure within text suggest term tree alignment indicate situation two markup scheme choose bracket text elements propose general method determine agreement two analyse describe efficient implementation also modular core implementation reuse regardless format markup use corpora output implementation susanne penn treebank corpora discuss
foundational work generative phonology claim subject reliably discriminate possible non occur word word could english paper examine use probabilistic phonological parser word model experimentally obtain judgements acceptability set nonsense word compare various methods score goodness parse predictor acceptability find probability worst part best score acceptability indicate classical generative phonology optimality theory miss important fact approach recognise mechanism frequency well form part may ameliorate unacceptability low frequency part argue probabilistic generative grammars demonstrably psychologically realistic model phonological competence standard generative phonology optimality theory
give overview multilingual speech synthesis use ipox system first part discuss work progress various languages tashlhit berber urdu dutch second part discuss multilingual phonological grammar adapt particular language set parameters add language specific detail
paper present message planner traumagen draw rhetorical structure discourse theory address problem produce integrate message individual critique design achieve communicative goal traumagen take account purpose message situation message receive social role system
paper treatment czech phonological rule two level morphology approach describe first possible phonological alternations czech list treatment practical application czech morphological lexicon
way discourse feature express connections back previous discourse describe literature term adjoin right frontier discourse structure allow discourse feature express expectations come subsequent discourse characterize expectations distribution text show approach make use substitution well adjoin suitably define right frontier use process expectations constrain discouse process general
good communication vital healthcare among healthcare professionals healthcare professionals patients well write document describe explain information structure databases may easier comprehend edify even convince structure data even present tabular graphic form document may automatically generate structure data use techniques field natural language generation techniques concern content organisation language use document dynamically select depend audience context use generate health education materials explanations critique decision support systems medical report progress note
paper examine demonstrative pronouns use deictics refer interpretation one clauses although usage frown upon style manuals example strunk white one thousand, nine hundred and fifty-nine state pronoun refer complete sense precede sentence clause always carry load may produce imprecise statement nevertheless common write text handle usage pose problem natural language understand systems solution propose base distinguish point refer virtue point argue restrict set discourse segment yield demonstrative pronouns point restrict set nunberg one thousand, nine hundred and seventy-nine call refer function yield refer virtue point
paper consider participles unknown identify unspecified sentence solange stay unknown hotel read equivalent indirect question solange stay hotel know hotel discuss phenomena include disambiguation quantifier scope restriction set determiners allow read question epistemic modifiers analyze drt framework file information state discourse referents propose semantics use predication file discourse referents relate recent developments dynamic modal predicate calculus argue compositional drt semantics must employ semantic type discourse referents oppose type individuals connection develop scope effect epistemic modifiers scope disambiguate effect certain
center formulate model relationship attentional state form refer expressions coherence utterance within discourse segment grosz joshi weinstein one thousand, nine hundred and eighty-six grosz joshi weinstein one thousand, nine hundred and ninety-five chapter argue restriction center operate within discourse segment abandon order integrate center model global discourse structure within segment restriction cause three problems first problem center often continue discourse segment boundaries pronominal refer expressions whose form identical occur within discourse segment second problem recent work show listeners perceive segment boundaries various level granularity center model universal process phenomenon implausible listener use different center algorithmthe third issue even utterances within discourse segment strong contrast utterances whose adjacent utterance within segment hierarchically recent whose adjacent utterance within segment linearly recent chapter argue problems eliminate replace grosz sidner stack model attentional state alternate model cache model show cache model easily integrate center algorithm provide several type data naturally occur discourse support propose integrate model future work provide additional support claim examination larger corpus naturally occur discourse
present variation classic beam thresholding techniques order magnitude faster traditional method performance level also present new thresholding technique global thresholding combine new beam thresholding give additional factor two improvement novel technique multiple pass parse combine others yield yet another fifty improvement use new search algorithm simultaneously optimize thresholding parameters various algorithms
paper address problem derive distance measure parent daughter languages specific relevance historical chinese phonology diachronic relationship languages model probabilistic finite state automaton minimum message length principle employ find complexity structure idea measure representative amount dissimilarity two languages
valiant show boolean matrix multiplication bmm use cfg parse prove dual result cfg parsers run time ofgw3 myeps grammar g string w use multiply time boolean matrices time ofm3 myeps three process also provide formal definition parse motivate informal notion due lang result establish one first limitations general cfg parse fast practical cfg parser would yield fast practical bmm algorithm believe exist
dialogue model learn environment support engineer orient approach towards dialogue model speak language interface major step towards dialogue model know basic units use construct dialogue model possible sequence difference many approach set dialogue act predefined theory manually engineer process learn data available avised speak dialogue system architecture outline approach apply domain appointment schedule even though base word correctness seventy predictability dialogue act dia mole turn comparable human assign dialogue act
compare four similarity base estimation methods back maximum likelihood estimation methods pseudo word sense disambiguation task control unigram bigram frequency similarity base methods perform forty better particular task also conclude events occur train set major impact similarity base estimate
thesis present two similarity base approach sparse data problems first approach build soft hierarchical cluster soft event belong cluster probability hierarchical cluster centroids iteratively split model finer distinctions second approach nearest neighbor approach instead calculate centroid class hierarchical cluster approach essence build cluster around word compare several nearest neighbor approach word sense disambiguation task find whole performance far superior standard methods another set experiment show use estimation techniques base nearest neighbor model enable us achieve perplexity reductions twenty percent standard techniques prediction low frequency events statistically significant speech recognition error rate reduction
address issue associate frequency information lexicalize grammar formalisms use lexicalize tree adjoin grammar representative framework consider systematically number alternative probabilistic frameworks evaluate adequacy theoretical empirical perspective use data exist large treebanks also propose three orthogonal approach back probability estimate cope large number parameters involve
paper present new view explanation base learn ebl natural language parse rather employ ebl specialize parsers infer new ones paper suggest employ ebl learn reduce ambiguity partially present method consist ebl algorithm learn partial parsers parse algorithm combine partial parsers exist full parsers learn partial parsers implementable cascade finite state transducers cfsts recognize combine constituents efficiently prohibit spurious overgeneration parse algorithm combine learn partial parser give full parser role full parser limit combine constituents recognize partial parser recognize unrecognized portion input sentence besides reduction parse space prior disambiguation present method provide way refine exist disambiguation model learn stochastic grammars tree bank exhibit encourage empirical result use pilot implementation parse space reduce substantially minimal loss coverage speedup gain disambiguation model exemplify experiment dop model
result computational complexity exist wide range phrase structure base grammar formalisms apparent lack result dependency base formalisms adapt result complexity id lp grammars dependency framework contrary previous study heavily restrict dependency grammars prove recognition thus parse linguistically adequate dependency grammars np complete
fourteen linguistically motivate numerical indicators evaluate ability categorize verbs either state events value indicator compute automatically across corpus text improve classification performance machine learn techniques employ combine multiple indicators three machine learn methods compare task decision tree induction genetic algorithm log linear regression
paper explore automatic construction multilingual lexical knowledge base preexist lexical resources first set automatic complementary techniques link spanish word collect monolingual bilingual mrds english wordnet synsets describe second show result data provide method combine produce preliminary version spanish wordnet accuracy eighty-five application combinations result increment extract connexions forty without lose accuracy coarse grain class level fine grain synset assignment level confidence ratios use evaluate finally result whole process present
automatic text categorization complex useful task many natural language process applications recent approach text categorization focus algorithms resources involve operation contrast trend present approach base integration widely available resources lexical databases train collections overcome current limitations task approach make use wordnet synonymy information increase evidence bad train categories test direct categorization wordnet base one train algorithm integrate approach latter exhibit better perfomance others incidentally wordnet base approach perfomance comparable train approach one
paper show previously report generation algorithms run problems deal f structure representations generation algorithm suitable type representations present semantic kernel generation skg algorithm skg method process strategy semantic head drive generation shdg algorithm rely assumption possible compute semantic kernel sk non semantic kernel non sk information input structure
one important cause failure speak dialogue systems usually neglect problem word cover system vocabulary vocabulary oov word paper methodology describe detection classification process oov word automatic train timetable information system various extensions effect different modules system report result design appropriate dialogue strategies encourage evaluation result new versions word recogniser linguistic processor
automatic text categorization tc complex useful task many natural language applications usually perform use set manually classify document train collection suggest utilization additional resources like lexical databases increase amount information tc systems make use thus improve performance approach integrate wordnet information two train approach vector space model train approach test rocchio relevance feedback widrow hoff machine learn algorithms result obtain evaluation show integration wordnet clearly outperform train approach integrate technique effectively address classification low frequency categories
paper present new approach measure semantic similarity distance word concepts combine lexical taxonomy structure corpus statistical information semantic distance nod semantic space construct taxonomy better quantify computational evidence derive distributional analysis corpus data specifically propose measure combine approach inherit edge base approach edge count scheme enhance node base approach information content calculation test common data set word pair similarity rat propose approach outperform computational model give highest correlation value eight hundred and twenty-eight benchmark base human similarity judgements whereas upper bind eight hundred and eighty-five observe human subject replicate task
paper introduce objective metric evaluate parse scheme base shannon original work letter sequence extend part speech tag sequence show regular language inadequate model natural language representation use model language slightly higher chomsky hierarchy show entropy parse unparsed sentence measure entropy parse sentence lower indicate structure language capture apply entropy indicator support one particular parse scheme effect top segmentation approach could use decompose parse task computationally tractable subtasks also lend extraction predicate argument structure
argue performance base design natural language grammars associate parsers order meet constraints impose real world nlp approach incorporate declarative procedural knowledge language language use within object orient specification framework discuss several message pass protocols parse provide reason sacrifice completeness parse favor efficiency base preliminary empirical evaluation
type feature structure use extensively specification linguistic information many formalisms subsumption relation order tfss information content prove subsumption acyclic tfss well found whereas presence cycle general tfs subsumption well found show application result parse well foundedness subsumption use guarantee termination grammars line parsable define new version line parsability less strict exist one thus termination guarantee parse larger set grammars
natural language parser successfully implement describe hybrid system neural network operate within rule base framework access via telnet users try text detail contact author test technical manuals parser find subject head subject ninety declarative sentence neural process components belong class generalize single layer network gsln general supervise fee forward network need one layer process data however case data pre process non linear transformation present linearly separable form subsequent process single layer net network offer advantage functional transparency operational speed parser initial stage process map linguistic data onto higher order representation analyse single layer network transformation support information theoretic analysis
work describe design implementation abstract machine amalia linguistic formalism ale base type feature structure formalism one widely accept computational linguistics use design grammars various linguistic theories notably hpsg amalia compose data structure set instructions augment compiler grammatical formalism abstract instructions portable interpreter abstract instructions effect instruction define use low level language execute ordinary hardware advantage abstract machine approach twofold theoretical point view abstract machine give well define operational semantics grammatical formalism ensure grammars specify use system endow well define mean enable example formally verify correctness compiler hpsg give independent definition practical point view amalia first system employ direct compilation scheme unification grammars base type feature structure use amalia result much improve performance exist systems order test machine realistic application develop small scale hpsg base grammar fragment hebrew language use amalia development platform first application hpsg semitic language
contemporary linguistic theories particular hpsg declarative nature specify constraints permissible structure structure compute grammars design theories therefore suitable parse generation however practical implementations theories usually support bidirectional process grammars present grammar development system include compiler grammars parse generation abstract machine instructions interpreter abstract machine language generation compiler invert input grammars design parse form suitable generation compile grammars execute interpreter use one control strategy regardless whether grammar original invert version thus obtain unify efficient platform develop reversible grammars
propose method segmentation expository texts base hierarchical agglomerative cluster method use paragraph basic segment identify hierarchical discourse structure text apply lexical similarity proximity test linear segmentation induce identify structure application two simple rule however hierarchy use also intelligent exploration text propose segmentation algorithm evaluate accept linear segmentation method show comparable result
paper address issue part speech disambiguation use finite state transducers present two main contributions field one use finite state machine part speech tag linguistic statistical information represent term weight transition weight finite state transducers another contribution successful combination techniques linguistic statistical word disambiguation compound notion word class
paper explore morpho syntactic ambiguities french develop strategy part speech disambiguation reflect complexity french inflect language b optimize estimation probabilities c allow user flexibility choose tagset problem extract lexical probabilities limit train corpus statistical model may necessarily represent use particular word particular context highly morphologically inflect language argument particularly serious since word tag large number part speech due lack sufficient train data argue estimate lexical probabilities disambiguate part speech unrestricted texts instead use strength contextual probabilities along feature call genotype set tag associate word use knowledge build part speech tagger combine linguistic statistical approach contextual information disambiguate linguistic rule n gram probabilities part speech estimate order disambiguate remain ambiguous tag
paper propose disambiguate technique call control disjunctions extension call name disjunctions rely relations exist feature value covariation control etc show control disjunctions implement different kind ambiguities consistent homogeneous way describe integration control disjunctions hpsg feature structure representation finally present direct implementation mean delay evaluation develop example within functionnal program paradigm
paper propose implement syllabification ot parser propose several innovations result finite small candidate set candidate set problem handle several move max dep violations hypothesize parser ii candidates encode locally iii eval apply constraint constraint parser propose implement prolog number desirable consequences first run thus provide existence proof syllabification implement ot number desirable consequences well first constraints implement finite state transducers second parser make several interest claim phonological properties call nonrecoverable insertions deletions third implementation suggest particular reformulations benchmark constraints ot arsenal eg complex parse onset nocoda
recently considerable interest use lexically base statistical techniques resolve prepositional phrase attachments knowledge however investigations consider problem attach first pp ie v np pp configuration paper consider one technique successfully apply problem back estimation demonstrate extend deal problem multiple pp attachment multiple pp attachment introduce two relate problems sparser data since multiple pps naturally rarer greater syntactic ambiguity attachment configurations must distinguish present algorithm solve problem use relatively rich data obtain first pp train resolve subsequent pp attachments
goal identify feature predict occurrence placement discourse cue tutorial explanations order aid automatic generation explanations previous attempt devise rule text generation base intuition small number construct examples apply machine learn program c45 induce decision tree cue occurrence placement corpus data cod variety feature previously think affect cue usage experiment enable us identify feature predictive power show machine learn use induce decision tree useful text generation
present result study definite descriptions use write texts aim assess feasibility annotate corpora information definite description interpretation run two experiment subject ask classify use definite descriptions corpus thirty-three newspaper article contain total one thousand, four hundred and twelve definite descriptions measure agreement among annotators class assign definite descriptions well agreement antecedent assign definites annotators classify relate antecedent text interest result study corpus annotation perspective rather low agreement k063 obtain use versions hawkins prince classification scheme better result k076 obtain use simplify scheme propose fraurud include two class first mention subsequent mention agreement antecedents also complete find raise question concern strategy evaluate systems definite description interpretation compare result standardize annotation linguistic point view interest observations great number discourse new definites corpus one experiment fifty definites collection classify discourse new thirty anaphoric eighteen associative bridge presence definites seem require complete disambiguation
paper describe automation new text categorization task categories assign task syntactically semantically contextually complex typically assign fully automatic systems process unseen test data system assign categories probabilistic classifier develop recent method formulate probabilistic model predefined set potential feature paper focus feature selection present number fully automatic feature identify evaluate various approach organize collocational properties feature present result experiment covarying type organization type property find one organization best kinds properties experimental parameter worth investigate nlp systems addition result suggest way take advantage properties low frequency strongly indicative class problems recognize organize various kinds contextual information require perform linguistically complex categorization task rarely systematically investigate nlp
paper address two central problems probabilistic process model parameter estimation incomplete data efficient retrieval probable analyse question answer satisfactorily probabilistic regular context free model address problems expressive probabilistic constraint logic program model present log linear probability model probabilistic constraint logic program top model define algorithm estimate parameters select properties log linear model incomplete data algorithm extension improve iterative scale algorithm della pietra della pietra lafferty one thousand, nine hundred and ninety-five algorithm apply log linear model general accompany suitable approximation methods apply large data space furthermore present approach search probable analyse probabilistic constraint logic program model method apply ambiguity resolution problem natural language process applications
although adequate model human language syntactic analysis semantic interpretation least context free complexity applications speech process speed important finite state model often prefer requirements may reconcile use complex grammar automatically derive finite state approximation use filter guide speech recognition reject many hypotheses early stage process method present calculate finite state approximations context free grammars essentially different algorithm introduce pereira wright one thousand, nine hundred and ninety-one one thousand, nine hundred and ninety-six faster case advantage open end adaptable
introduce novel parser base probabilistic version leave corner parser leave corner strategy attractive rule probabilities condition top goals bottom derivations develop underlie theory explain grammar induce analyze data show leave corner approach provide advantage simple top probabilistic context free grammars parse wall street journal use grammar induce penn treebank also conclude penn treebank provide fairly weak testbed due flatness bracket obvious overgeneration undergeneration induce grammar
describe approach linguistic variation take motorola speech synthesizer pan dialectal pronunciation dictionary describe serve train data neural network base letter sound converter subsequent dictionary retrieval letter sound generation pronunciations submit neural network base postlexical module postlexical module train align dictionary pronunciations hand label narrow phonetic transcriptions architecture permit learn individual postlexical variation retrain speaker whose voice model synthesis learn variation way result greater naturalness synthetic speech produce system
grammar development environments gde analysis generation yet come together despite fact analysis orient gde alep may include possibility sentence generation development techniques kinds resources suggest apparently require practical large scale natural language generation work indeed use standard ie analysis orient gde current project applications targetting generation fluent coherent texts unsatisfactory situation require analysis explanation paper attempt use example extensive gde generation support provide distribute large scale grammar development multilinguality resource maintenance discuss contrast analysis orient approach
paper explain contextual expectations generate use task orient speak language understand system dialogos hard task recognize spontaneous speech telephone may greatly benefit use specific language model recognition callers utterances specific language model mean set language model train contextually appropriate data use different state dialogue basis information send acoustic level dialogue management module paper describe specific language model obtain basis contextual information experimental result report show recognition understand performance improve thank use specific language model
paper focus language model task orient domains present accurate analysis utterances acquire dialogos speak dialogue system dialogos allow access italian railways timetable use telephone public network language model aspects specificity behaviour rare events study technique get language model robust base sentence generate grammars present experimental result show benefit propose technique increment performance language model create use grammars usual ones higher amount train material limit therefore technique give advantage especially development language model new domain
paper describe miscommunication problems deal speak language system dialogos dialogue module system exploit dialogic expectations twofold way model future user utterance might predictions account user next utterance may relate previous ones ongoing interaction pragmatic base expectations analysis start hypothesis occurrence miscommunication concomitant two pragmatic phenomena deviation user expect behaviour generation conversational implicature preliminary evaluation large amount interactions subject dialogos show system performance enhance use predictions pragmatic base expectations
paper first attempt derive improve performance measure language model probability ratio measure prm describe proof concept experiment show prm correlate better recognition accuracy lead better recognition result use optimisation criterion cluster algorithm inspite approximations limitations preliminary work result encourage justify work along line
space run time requirements broad coverage grammars appear many applications unreasonably large relation relative simplicity task hand hand handcraft development application dependent grammars danger duplicate work difficult use contexts application overcome problem present paper procedure automatic extraction application tune consistent subgrammars prove large scale generation grammars procedure implement large scale systemic grammars build formal equivalence systemic grammars type unification base grammars evaluation generation encyclopedia entries describe directions future development applicability extensions discuss
performance pcfgs estimate tree bank sensitive particular way linguistic constructions represent tree tree bank paper present theoretical analysis effect different tree representations pp attachment pcfg model introduce new methodology empirically examine effect use tree transformations show one transformation copy label parent node onto label children improve performance pcfg model term label precision recall hold data seventy-three precision sixty-nine recall eighty seventy-nine respectively also point maximum likelihood parse interest many productions ignore since subsume combinations productions grammar penn ii tree bank grammar almost nine productions subsume way
paper show proof net use formalize notion incomplete dependency use psycholinguistic theories unacceptability center embed constructions theories human language process usually restate term geometrical constraints proof net paper end discussion relationship constraints incremental semantic interpretation
paper introduce non unification base version lfg call r lfg resource base lexical functional grammar combine elements lfg linear logic paper argue resource sensitive account provide simpler treatment many linguistic use non monotonic devices lfg existential constraints constraint equations
one enrich lfg formal machinery linear logic mechanisms need semantic interpretation propose dalrymple et al natural ask whether make exist components lfg redundant dalrymple colleagues note lfg f structure completeness coherence constraints fall product linear logic machinery propose semantic interpretation thus make f structure mechanisms redundant give linear logic machinery something like independently need semantic interpretation seem reasonable explore extent capable handle feature structure constraints well r lfg represent extreme position linguistically require feature structure dependencies capture resource account machinery linear similiar logic independently need semantic interpretation make lfg unification machinery redundant goal show lfg linguistic analyse express clearly perspicuously use smaller set mechanisms r lfg use much larger set unification base mechanisms lfg case show posit extra f structure mechanisms linguistically warrant
paper present method automatic extraction subgrammars control speed natural language generation nlg method base explanation base learn ebl main advantage propose new method nlg complexity grammatical decision make process nlg vastly reduce ebl method support adaption nlg system particular use language
take issue ai formalizations context primarily formalization mccarthy buvac regard context undefined primitive whose formalization many different kinds ai task particular theory context natural language must take special nature natural language account regard context simply undefined primitive show thing coherent theory context simpliciter context pure simple context natural language kind thing context kr natural language context construct speaker interpreter considerable discretion therefore formalization base pre define contexts pre define lift axioms account context use real world language
describe new method summarize similarities differences pair relate document use graph representation text concepts denote word phrase proper name document represent positionally nod graph along edge correspond semantic relations items give perspective term pair document summarize algorithm first use spread activation technique discover document nod semantically relate topic activate graph document match yield graph correspond similarities differences pair render natural language evaluation techniques carry
make interactive guidance mechanism document retrieval systems develop user interface present users visualize map topics stage retrieval process topic word automatically extract frequency analysis strength relationships topic word measure co occurrence major factor affect user impression give topic word graph balance common topic word specific topic word use frequency class topic word extraction make possible select well balance set topic word adjust balance common specific topic word
word sense disambiguation assume word sense within lexicography linguistics literature know slippery entities paper look problems exist account word sense describe various kinds ways word mean deviate core mean analysis present word sense abstractions cluster corpus citations accordance current lexicographic practice corpus citations word sense basic object ontology corpus citations cluster sense accord purpose whoever whatever cluster absence purpose word sense exist word sense disambiguation also need set word sense disambiguate recent work set take general purpose lexical resource assumption lexical resource describe word sense english french nlp applications need disambiguate implication paper contrast word sense exist relative task
lexicon acquisition machine readable dictionaries corpora currently dynamic field research yet often clear lexical information acquire use relate structure mean representations paper look issue relation information extraction hereafter ie one subtask lexical general knowledge require word sense disambiguation wsd analysis base widely use little discuss distinction ie system foreground lexicon contain domain key term map onto database field output formalism background lexicon contain remainder vocabulary foreground lexicon human lexicography require background lexicon automatic acquisition appropriate foreground lexicon wsd occur product find coherent semantic interpretation input wsd techniques discuss recent literature suit background lexicon foreground background distinction develop match possible give state art wsd require high quality ie
word sense disambiguation develop sub area natural language process like parse well define task pre requisite wide range language understand applications first review earlier work show set sense word ever define relative particular human purpose view word sense part linguistic furniture lack theoretical underpinnings investigate whether word sense ambiguity fact problem different varieties nlp application
thesis present statistical language model resolve speech repair intonational boundaries discourse markers rather find best word interpretation acoustic signal redefine speech recognition problem also identify pos tag discourse markers speech repair intonational phrase end major cue determine utterance units add extra elements speech recognition problem actually allow better predict word involve since able make use predictions boundary tone discourse markers speech repair better account word occur next furthermore take advantage acoustic information silence information tend co occur speech repair intonational phrase end current language model regard noise acoustic signal output language model much fuller account speaker turn part speech assign word intonation phrase end discourse markers identify speech repair detect correct fact identification intonational phrase end discourse markers resolution speech repair allow speech recognizer model speaker utterances rather simply word involve thus return meaningful analysis speaker turn later process
methodology base upon recurrence quantification analysis propose study orthographic structure write texts five different orthographic data set 20th century italian poems 20th century american poems contemporary swedish poems correspond italian translations italian speech sample american speech sample subject recurrence quantification analysis procedure find diagnostically useful quantitative assessment order series field physics molecular dynamics physiology general signal process recurrence quantification develop recurrence plot apply analysis nonlinear complex systems physical sciences base computation distance matrix elements order series case letter consituting select speech poetic texts strictly mathematical view result show possibility demonstrate invariance different language exemplars despite apparent low level cod orthography comparison actual texts confirm ability method reveal recurrent structure complexity use poems reference standard judge speech complexity technique exhibit language independence order dependence freedom pure statistical characteristics study sequence well consistency easily identifiable texts study may provide phenomenological markers hide structure cod purely orthographic level
information become available electronically tool find information interest users become increasingly important goal research describe build system generate comprehensible user profile accurately capture user interest minimum user interaction research describe focus importance suitable generalization hierarchy representation learn profile predictively accurate comprehensible experiment evaluate traditional feature base weight term vectors well subject feature correspond categories could draw thesaurus experiment conduct context content base profile system line newspapers world wide web idd news browser demonstrate importance generalization hierarchy promise combine natural language process techniques machine learn ml address information retrieval ir problem